{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-01T07:40:51.180217Z",
          "iopub.status.busy": "2026-02-01T07:40:51.179922Z",
          "iopub.status.idle": "2026-02-01T07:40:53.16231Z",
          "shell.execute_reply": "2026-02-01T07:40:53.16155Z",
          "shell.execute_reply.started": "2026-02-01T07:40:51.18019Z"
        },
        "id": "1Li9Vn9bGo8X",
        "outputId": "4d95bad7-3b8b-45d0-e66e-b3de16c517fa",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "No progress, start fresh.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Iterable, Tuple, Dict, Optional, Callable, Any\n",
        "from heapq import nsmallest\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import random\n",
        "import os, time, json\n",
        "import torch\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from cayleypy_pancake.utils.permutation import parse_permutation, apply_move_copy, apply_moves\n",
        "from cayleypy_pancake.utils.moves import moves_to_str, moves_len\n",
        "from cayleypy_pancake.utils.io import ensure_dir\n",
        "from cayleypy_pancake.utils.time import now_str\n",
        "from cayleypy_pancake.utils.seed import set_seed\n",
        "from cayleypy_pancake.utils.logging import log_print\n",
        "\n",
        "from cayleypy_pancake.search.baseline import pancake_sort_moves\n",
        "from cayleypy_pancake.search.heuristics import breakpoints2, is_solved, gap_h, mix_h, make_h\n",
        "from cayleypy_pancake.search.beam import beam_improve_or_baseline_h\n",
        "\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "OUT_DIR = Path(\"/content/drive/MyDrive/pancake_runs\")\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "PROGRESS_PATH = os.path.join(OUT_DIR, \"submission_progress.csv\")\n",
        "FINAL_PATH = os.path.join(OUT_DIR, \"submission.csv\")\n",
        "BASELINE_PATH = os.path.join(OUT_DIR, \"baseline_submission.csv\")\n",
        "TEST_PATH = os.path.join(OUT_DIR, \"test.csv\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if os.path.exists(PROGRESS_PATH):\n",
        "    prog_df = pd.read_csv(PROGRESS_PATH)\n",
        "    progress_map = dict(zip(prog_df[\"id\"].astype(int).values, prog_df[\"solution\"].values))\n",
        "    print(\"Resume progress:\", len(progress_map))\n",
        "else:\n",
        "    progress_map = {}\n",
        "    print(\"No progress, start fresh.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmDLoHNTBGvz"
      },
      "source": [
        "Данный набор функций реализует базовые утилиты для работы с перестановками и решениями задачи pancake sorting.\n",
        "\n",
        "Функции parse_permutation, moves_to_str и moves_len отвечают за безопасное преобразование данных между форматами. Это позволяет единообразно работать с результатами классических алгоритмов, эвристик и ML-моделей в одном пайплайне.\n",
        "\n",
        "Функция pancake_sort_moves реализует классический жадный алгоритм pancake sorting и используется как корректный базовый ориентир. Алгоритм работает за O(n^2) и гарантированно гарантированно строит допустимую последовательность префиксных разворотов для любой перестановки и служит эталоном для проверки корректности, оценки качества и сравнения более сложных методов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:40:53.967213Z",
          "iopub.status.busy": "2026-02-01T07:40:53.966464Z",
          "iopub.status.idle": "2026-02-01T07:40:53.978594Z",
          "shell.execute_reply": "2026-02-01T07:40:53.977985Z",
          "shell.execute_reply.started": "2026-02-01T07:40:53.967179Z"
        },
        "id": "ffiY8VkzLKK_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def parse_permutation(raw: str) -> List[int]:\n",
        "    if raw is None:\n",
        "        return []\n",
        "    raw = str(raw).strip()\n",
        "    if raw == \"\":\n",
        "        return []\n",
        "    return [int(tok) for tok in raw.split(\",\") if tok.strip() != \"\"]\n",
        "\n",
        "def moves_to_str(moves: List[int]) -> str:\n",
        "    return \".\".join(f\"R{k}\" for k in moves)\n",
        "\n",
        "def moves_len(sol) -> int:\n",
        "    if sol is None or (isinstance(sol, float) and pd.isna(sol)):\n",
        "        return 0\n",
        "    s = str(sol).strip()\n",
        "    if s == \"\":\n",
        "        return 0\n",
        "    return s.count(\".\") + 1\n",
        "\n",
        "def pancake_sort_moves(perm: Iterable[int]) -> List[int]:\n",
        "    a = list(perm)\n",
        "    n = len(a)\n",
        "    if n <= 1:\n",
        "        return []\n",
        "\n",
        "    pos = [0] * n\n",
        "    for i, v in enumerate(a):\n",
        "        pos[v] = i\n",
        "\n",
        "    moves: List[int] = []\n",
        "\n",
        "    def do_flip(k: int) -> None:\n",
        "        if k <= 1:\n",
        "            return\n",
        "        i, j = 0, k - 1\n",
        "        while i < j:\n",
        "            vi, vj = a[i], a[j]\n",
        "            a[i], a[j] = vj, vi\n",
        "            pos[vi], pos[vj] = j, i\n",
        "            i += 1\n",
        "            j -= 1\n",
        "\n",
        "    for target in range(n - 1, 0, -1):\n",
        "        idx = pos[target]\n",
        "        if idx == target:\n",
        "            continue\n",
        "        if idx != 0:\n",
        "            do_flip(idx + 1)\n",
        "            moves.append(idx + 1)\n",
        "        do_flip(target + 1)\n",
        "        moves.append(target + 1)\n",
        "\n",
        "    return moves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txHE6J7BB7R9"
      },
      "source": [
        "Этот блок подготавливает тестовый датасет и извлекает из него базовую структурную информацию — размер перестановки n. Мы явно восстанавливаем длину каждой перестановки из строкового представления, а затем считаем распределение по n, чтобы понимать, с какими размерами входов мы работаем. Это важно для анализа покрытия теста, стратификации результатов и последующего сравнения моделей по сложности входа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "execution": {
          "iopub.execute_input": "2026-02-01T07:40:59.620858Z",
          "iopub.status.busy": "2026-02-01T07:40:59.620439Z",
          "iopub.status.idle": "2026-02-01T07:40:59.743255Z",
          "shell.execute_reply": "2026-02-01T07:40:59.742668Z",
          "shell.execute_reply.started": "2026-02-01T07:40:59.62083Z"
        },
        "id": "CAOoXLRrLDDo",
        "outputId": "554c908d-d721-4f57-c171-0eccb0db97c1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"n_counts\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 5,\n        \"max\": 100,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          75,\n          45,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 5,\n        \"max\": 200,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          200,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "n_counts"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-eb083975-92e8-4ad4-bc2b-12d7e7f158c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>30</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>40</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>45</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>50</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>75</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb083975-92e8-4ad4-bc2b-12d7e7f158c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb083975-92e8-4ad4-bc2b-12d7e7f158c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb083975-92e8-4ad4-bc2b-12d7e7f158c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f044aa01-d5c1-4690-98d6-3c20d3a820e7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('n_counts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f044aa01-d5c1-4690-98d6-3c20d3a820e7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('n_counts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      n  count\n",
              "0     5      5\n",
              "1    12    200\n",
              "2    15    200\n",
              "3    16    200\n",
              "4    20    200\n",
              "5    25    200\n",
              "6    30    200\n",
              "7    35    200\n",
              "8    40    200\n",
              "9    45    200\n",
              "10   50    200\n",
              "11   75    200\n",
              "12  100    200"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "test_df[\"n\"] = test_df[\"permutation\"].apply(\n",
        "    lambda x: len(parse_permutation(x))\n",
        ")\n",
        "\n",
        "n_counts = (\n",
        "    test_df[\"n\"]\n",
        "    .value_counts()\n",
        "    .sort_index()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"index\": \"n\"})\n",
        ")\n",
        "\n",
        "n_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_dLzXGVkg-J"
      },
      "source": [
        "# Heuristic without DL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPpDIRYUTPZ"
      },
      "source": [
        "Этот набор функций реализует эвристики качества состояния для pancake-задачи, быстрые примитивы применения ходов и проверки решения, улучшатель базового решения через beam search с отсечениями, и экспериментальный грид-поиск по гиперпараметрам эвристики и beam search.\n",
        "\n",
        "Основная идея: берём базовое решение (по умолчанию классический pancake sort), используем его длину как верхнюю границу и пытаемся найти более короткий путь, исследуя пространство состояний ограниченным лучом (beam) и эвристическим приоритетом. Затем прогоняем это по множеству тест-кейсов и конфигураций, сохраняя метрики (gain, ok, время) для анализа.\n",
        "\n",
        "breakpoints2 считает число «разрывов» в перестановке: соседние элементы, которые не идут подряд по значению (разность по модулю не равна 1). Дополнительно учитывается штраф, если первый элемент не равен 0, что усиливает давление на «правильный старт». Эта метрика используется как простая эвристика «насколько мы далеко от упорядоченного вида».\n",
        "\n",
        "gap_h считает разрывы в последовательности, включая виртуальные границы -1 слева и n справа. Это стандартная идея для pancake-задачи: корректный порядок соответствует цепочке -1,0,1,...,n, и каждое нарушение смежности увеличивает оценку. В отличие от breakpoints2, здесь учитываются также граничные условия.\n",
        "\n",
        "mix_h комбинирует две эвристики: gap_h как основную и breakpoints2 как добавочный штраф с весом alpha. Такая смесь позволяет регулировать «жёсткость» эвристики, балансируя чувствительность к локальным разрывам и предпочтение правильного префикса. Возвращается вещественное значение, чтобы удобно масштабировать вклад.\n",
        "\n",
        "beam_improve_or_baseline_h пытается улучшить базовое решение ограниченным поиском (beam search) с эвристической оценкой f = g + w*h. Длина базового решения используется как текущая верхняя граница: все пути, которые уже не могут быть лучше, отсекаются. Если улучшение найдено, возвращается более короткий путь, иначе — исходный baseline.\n",
        "\n",
        "Функция выполняет пакетный прогон экспериментов: на наборе кейсов перебирает все комбинации гиперпараметров (alpha, w, beam_width, depth). Для каждого запуска строится решение улучшателем, проверяется корректность и считаются метрики качества относительно baseline. Результаты собираются в таблицу для последующего анализа и выбора конфигурации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:03.7584Z",
          "iopub.status.busy": "2026-02-01T07:41:03.757916Z",
          "iopub.status.idle": "2026-02-01T07:41:03.786011Z",
          "shell.execute_reply": "2026-02-01T07:41:03.785136Z",
          "shell.execute_reply.started": "2026-02-01T07:41:03.758371Z"
        },
        "id": "Kf_qjpl54RtI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def breakpoints2(state: List[int]) -> int:\n",
        "    n = len(state)\n",
        "    b = 0\n",
        "    for i in range(n - 1):\n",
        "        if abs(state[i] - state[i + 1]) != 1:\n",
        "            b += 1\n",
        "    if n > 0 and state[0] != 0:\n",
        "        b += 1\n",
        "    return b\n",
        "\n",
        "def is_solved(state: List[int]) -> bool:\n",
        "    return all(v == i for i, v in enumerate(state))\n",
        "\n",
        "def apply_move_copy(state: List[int], k: int) -> List[int]:\n",
        "    nxt = state[:]\n",
        "    nxt[:k] = reversed(nxt[:k])\n",
        "    return nxt\n",
        "\n",
        "def apply_moves(perm: List[int], moves: List[int]) -> List[int]:\n",
        "    a = perm[:]\n",
        "    for k in moves:\n",
        "        a[:k] = reversed(a[:k])\n",
        "    return a\n",
        "\n",
        "def gap_h(state: List[int]) -> int:\n",
        "    n = len(state)\n",
        "    prev = -1\n",
        "    gaps = 0\n",
        "    for x in state:\n",
        "        if abs(x - prev) != 1:\n",
        "            gaps += 1\n",
        "        prev = x\n",
        "    if abs(n - prev) != 1:\n",
        "        gaps += 1\n",
        "    return gaps\n",
        "\n",
        "def mix_h(state: List[int], alpha: float = 0.5) -> float:\n",
        "    return gap_h(state) + alpha * breakpoints2(state)\n",
        "\n",
        "def make_h(alpha: float) -> Callable[[List[int]], float]:\n",
        "    if alpha == 0.0:\n",
        "        return lambda s: float(gap_h(s))\n",
        "    return lambda s: float(mix_h(s, alpha=alpha))\n",
        "\n",
        "\n",
        "def beam_improve_or_baseline_h(\n",
        "    perm: Iterable[int],\n",
        "    *,\n",
        "    baseline_moves_fn: Callable[[Iterable[int]], List[int]],\n",
        "    h_fn: Callable[[List[int]], float],\n",
        "    beam_width: int = 8,\n",
        "    depth: int = 12,\n",
        "    w: float = 1.0,\n",
        "    log: bool = False,\n",
        "    log_every_layer: int = 1,\n",
        ") -> List[int]:\n",
        "    start = list(perm)\n",
        "\n",
        "    base_moves = baseline_moves_fn(start)\n",
        "    best_len = len(base_moves)\n",
        "    if best_len <= 1:\n",
        "        return base_moves\n",
        "\n",
        "    apply_move = apply_move_copy\n",
        "    solved = is_solved\n",
        "    h_local = h_fn\n",
        "    w_local = w\n",
        "    k_values = range(2, len(start) + 1)\n",
        "\n",
        "    beam: List[Tuple[float, int, List[int], List[int]]] = [\n",
        "        (w_local * float(h_local(start)), 0, start, [])\n",
        "    ]\n",
        "\n",
        "    best_path: Optional[List[int]] = None\n",
        "    best_g: Dict[Tuple[int, ...], int] = {tuple(start): 0}\n",
        "\n",
        "    log_print(log, f\"[beam] start n={len(start)} base_len={best_len} bw={beam_width} depth={depth} w={w}\")\n",
        "\n",
        "    for layer in range(1, depth + 1):\n",
        "        candidates: List[Tuple[float, int, List[int], List[int]]] = []\n",
        "        improved_this_layer = 0\n",
        "        for f, g, state, path in beam:\n",
        "            if g >= best_len:\n",
        "                continue\n",
        "\n",
        "            for k in k_values:\n",
        "                new_g = g + 1\n",
        "                if new_g >= best_len:\n",
        "                    continue\n",
        "\n",
        "                nxt = apply_move(state, k)\n",
        "                key = tuple(nxt)\n",
        "\n",
        "                prevg = best_g.get(key)\n",
        "                if prevg is not None and prevg <= new_g:\n",
        "                    continue\n",
        "                best_g[key] = new_g\n",
        "\n",
        "                if solved(nxt):\n",
        "                    best_len = new_g\n",
        "                    best_path = path + [k]\n",
        "                    improved_this_layer += 1\n",
        "                    continue\n",
        "\n",
        "                h = float(h_local(nxt))\n",
        "                new_f = new_g + w_local * h\n",
        "                if new_f < best_len:\n",
        "                    candidates.append((new_f, new_g, nxt, path + [k]))\n",
        "\n",
        "        if log and (layer % max(1, log_every_layer) == 0):\n",
        "            log_print(\n",
        "                True,\n",
        "                f\"[beam] layer={layer:03d} beam_in={len(beam)} cand={len(candidates)} \"\n",
        "                f\"improved={improved_this_layer} best_len={best_len}\"\n",
        "            )\n",
        "\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        beam = nsmallest(beam_width, candidates, key=lambda x: x[0])\n",
        "        if best_len <= 2:\n",
        "            break\n",
        "\n",
        "    return best_path if best_path is not None else base_moves\n",
        "\n",
        "def select_cases_per_n(\n",
        "    df: pd.DataFrame,\n",
        "    n_list: List[int],\n",
        "    k: int = 5,\n",
        "    seed: int = 42,\n",
        ") -> pd.DataFrame:\n",
        "    rng = random.Random(seed)\n",
        "    rows = []\n",
        "    for n in n_list:\n",
        "        sub = df[df[\"n\"] == n]\n",
        "        if len(sub) < k:\n",
        "            raise ValueError(f\"Not enough samples for n={n}: have {len(sub)}, need {k}\")\n",
        "        idxs = list(sub.index)\n",
        "        rng.shuffle(idxs)\n",
        "        chosen = idxs[:k]\n",
        "        rows.append(df.loc[chosen])\n",
        "    return pd.concat(rows, axis=0).reset_index(drop=True)\n",
        "\n",
        "@dataclass\n",
        "class RunRow:\n",
        "    id: int\n",
        "    n: int\n",
        "    base_len: int\n",
        "    alpha: float\n",
        "    w: float\n",
        "    beam_width: int\n",
        "    depth: int\n",
        "    ok: bool\n",
        "    steps: int\n",
        "    gain: int\n",
        "    time_sec: float\n",
        "\n",
        "\n",
        "def log_print(enabled: bool, msg: str) -> None:\n",
        "    if enabled:\n",
        "        print(msg, flush=True)\n",
        "\n",
        "def run_grid(\n",
        "    mini_df: pd.DataFrame,\n",
        "    *,\n",
        "    alphas: List[float],\n",
        "    ws: List[float],\n",
        "    beam_widths: List[int],\n",
        "    depths: List[int],\n",
        "    baseline_moves_fn: Callable[[Iterable[int]], List[int]] = pancake_sort_moves,\n",
        "    log: bool = True,\n",
        "    log_each: int = 1,\n",
        "    beam_log: bool = False,\n",
        "    beam_log_every_layer: int = 5,\n",
        ") -> pd.DataFrame:\n",
        "    rows: List[dict] = []\n",
        "    total_cfg = len(alphas) * len(ws) * len(beam_widths) * len(depths)\n",
        "    total_cases = len(mini_df)\n",
        "    total_runs = total_cfg * total_cases\n",
        "\n",
        "    log_print(log, f\"[grid] cases={total_cases} cfg_per_case={total_cfg} total_runs={total_runs}\")\n",
        "    parsed: List[Tuple[int, int, List[int], int]] = []\n",
        "    for i in range(total_cases):\n",
        "        row = mini_df.iloc[i]\n",
        "        perm = parse_permutation(row.permutation)\n",
        "        n = len(perm)\n",
        "        base_len = len(baseline_moves_fn(perm))\n",
        "        parsed.append((int(row.id), n, perm, base_len))\n",
        "\n",
        "    run_idx = 0\n",
        "    for case_i, (rid, n, perm, base_len) in enumerate(parsed):\n",
        "        log_print(log, f\"\\n[case {case_i+1}/{total_cases}] id={rid} n={n} base_len={base_len}\")\n",
        "\n",
        "        for cfg_i, (alpha, w, bw, d) in enumerate(itertools.product(alphas, ws, beam_widths, depths), start=1):\n",
        "            run_idx += 1\n",
        "            do_cfg_log = log and (cfg_i % max(1, log_each) == 0)\n",
        "\n",
        "            t0 = time.time()\n",
        "            h_fn = make_h(alpha)\n",
        "            sol = beam_improve_or_baseline_h(\n",
        "                perm,\n",
        "                baseline_moves_fn=baseline_moves_fn,\n",
        "                h_fn=h_fn,\n",
        "                beam_width=bw,\n",
        "                depth=d,\n",
        "                w=w,\n",
        "                log=(beam_log and do_cfg_log),\n",
        "                log_every_layer=beam_log_every_layer,\n",
        "            )\n",
        "            dt = time.time() - t0\n",
        "\n",
        "            ok = (apply_moves(perm, sol) == list(range(n)))\n",
        "            steps = len(sol)\n",
        "            gain = base_len - steps\n",
        "\n",
        "            if do_cfg_log:\n",
        "                log_print(\n",
        "                    True,\n",
        "                    f\"[run {run_idx}/{total_runs}] cfg={cfg_i:03d}/{total_cfg} \"\n",
        "                    f\"alpha={alpha} w={w} bw={bw} depth={d} -> steps={steps} gain={gain} ok={ok} t={dt:.3f}s\"\n",
        "                )\n",
        "\n",
        "            rows.append({\n",
        "                \"id\": rid,\n",
        "                \"n\": n,\n",
        "                \"base_len\": base_len,\n",
        "                \"alpha\": alpha,\n",
        "                \"w\": w,\n",
        "                \"beam_width\": bw,\n",
        "                \"depth\": d,\n",
        "                \"ok\": ok,\n",
        "                \"steps\": steps,\n",
        "                \"gain\": gain,\n",
        "                \"time_sec\": dt,\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptcDMYTeH8uW"
      },
      "source": [
        "Этот блок формирует репрезентативный поднабор тестовых случаев по размерам перестановок и запускает полный грид-эксперимент по улучшению базовых решений. Для каждого выбранного размера n случайно отбираются несколько кейсов, после чего перебираются комбинации параметров эвристики и beam search. Результатом является таблица с метриками качества и времени, пригодная для анализа масштабируемости и подбора оптимальных конфигураций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1rQjSADINDGv",
        "outputId": "1b044952-cefc-4453-9ba8-83d00958bc24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[grid] cases=60 cfg_per_case=81 total_runs=4860\n",
            "\n",
            "[case 1/60] id=71 n=12 base_len=19\n",
            "\n",
            "[case 2/60] id=192 n=12 base_len=9\n",
            "\n",
            "[case 3/60] id=106 n=12 base_len=16\n",
            "\n",
            "[case 4/60] id=198 n=12 base_len=17\n",
            "\n",
            "[case 5/60] id=116 n=12 base_len=18\n",
            "\n",
            "[case 6/60] id=281 n=15 base_len=22\n",
            "\n",
            "[case 7/60] id=299 n=15 base_len=20\n",
            "\n",
            "[case 8/60] id=357 n=15 base_len=22\n",
            "\n",
            "[case 9/60] id=368 n=15 base_len=20\n",
            "\n",
            "[case 10/60] id=333 n=15 base_len=23\n",
            "\n",
            "[case 11/60] id=527 n=16 base_len=20\n",
            "\n",
            "[case 12/60] id=480 n=16 base_len=25\n",
            "\n",
            "[case 13/60] id=459 n=16 base_len=26\n",
            "\n",
            "[case 14/60] id=564 n=16 base_len=26\n",
            "\n",
            "[case 15/60] id=600 n=16 base_len=28\n",
            "\n",
            "[case 16/60] id=707 n=20 base_len=31\n",
            "\n",
            "[case 17/60] id=792 n=20 base_len=29\n",
            "\n",
            "[case 18/60] id=699 n=20 base_len=34\n",
            "\n",
            "[case 19/60] id=660 n=20 base_len=29\n",
            "\n",
            "[case 20/60] id=736 n=20 base_len=27\n",
            "\n",
            "[case 21/60] id=870 n=25 base_len=38\n",
            "\n",
            "[case 22/60] id=961 n=25 base_len=38\n",
            "\n",
            "[case 23/60] id=948 n=25 base_len=46\n",
            "\n",
            "[case 24/60] id=933 n=25 base_len=40\n",
            "\n",
            "[case 25/60] id=903 n=25 base_len=38\n",
            "\n",
            "[case 26/60] id=1195 n=30 base_len=56\n",
            "\n",
            "[case 27/60] id=1033 n=30 base_len=54\n",
            "\n",
            "[case 28/60] id=1151 n=30 base_len=56\n",
            "\n",
            "[case 29/60] id=1042 n=30 base_len=47\n",
            "\n",
            "[case 30/60] id=1113 n=30 base_len=53\n",
            "\n",
            "[case 31/60] id=1402 n=35 base_len=57\n",
            "\n",
            "[case 32/60] id=1221 n=35 base_len=60\n",
            "\n",
            "[case 33/60] id=1277 n=35 base_len=61\n",
            "\n",
            "[case 34/60] id=1371 n=35 base_len=58\n",
            "\n",
            "[case 35/60] id=1259 n=35 base_len=58\n",
            "\n",
            "[case 36/60] id=1509 n=40 base_len=67\n",
            "\n",
            "[case 37/60] id=1529 n=40 base_len=68\n",
            "\n",
            "[case 38/60] id=1560 n=40 base_len=67\n",
            "\n",
            "[case 39/60] id=1516 n=40 base_len=64\n",
            "\n",
            "[case 40/60] id=1468 n=40 base_len=68\n",
            "\n",
            "[case 41/60] id=1803 n=45 base_len=77\n",
            "\n",
            "[case 42/60] id=1719 n=45 base_len=77\n",
            "\n",
            "[case 43/60] id=1790 n=45 base_len=78\n",
            "\n",
            "[case 44/60] id=1666 n=45 base_len=82\n",
            "\n",
            "[case 45/60] id=1762 n=45 base_len=82\n",
            "\n",
            "[case 46/60] id=1992 n=50 base_len=87\n",
            "\n",
            "[case 47/60] id=1921 n=50 base_len=89\n",
            "\n",
            "[case 48/60] id=1947 n=50 base_len=93\n",
            "\n",
            "[case 49/60] id=1973 n=50 base_len=89\n",
            "\n",
            "[case 50/60] id=1848 n=50 base_len=86\n",
            "\n",
            "[case 51/60] id=2078 n=75 base_len=137\n",
            "\n",
            "[case 52/60] id=2006 n=75 base_len=137\n",
            "\n",
            "[case 53/60] id=2145 n=75 base_len=139\n",
            "\n",
            "[case 54/60] id=2126 n=75 base_len=131\n",
            "\n",
            "[case 55/60] id=2186 n=75 base_len=139\n",
            "\n",
            "[case 56/60] id=2297 n=100 base_len=178\n",
            "\n",
            "[case 57/60] id=2227 n=100 base_len=192\n",
            "\n",
            "[case 58/60] id=2216 n=100 base_len=192\n",
            "\n",
            "[case 59/60] id=2301 n=100 base_len=190\n",
            "\n",
            "[case 60/60] id=2234 n=100 base_len=187\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4860,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 681,\n        \"min\": 71,\n        \"max\": 2301,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          71,\n          281,\n          1529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 12,\n        \"max\": 100,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          75,\n          50,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 9,\n        \"max\": 192,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          139,\n          61,\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4082902977995161,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.5,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4082902977995161,\n        \"min\": 0.5,\n        \"max\": 1.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5,\n          1.0,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beam_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          64,\n          128,\n          256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 64,\n        \"max\": 192,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          64,\n          128,\n          192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ok\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"steps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43,\n        \"min\": 8,\n        \"max\": 192,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 91,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.060145457574544,\n        \"min\": 4.076957702636719e-05,\n        \"max\": 146.81782388687134,\n        \"num_unique_values\": 4400,\n        \"samples\": [\n          0.04456377029418945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9af6dd85-c9c5-4d32-91fd-9dac324ff078\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>n</th>\n",
              "      <th>base_len</th>\n",
              "      <th>alpha</th>\n",
              "      <th>w</th>\n",
              "      <th>beam_width</th>\n",
              "      <th>depth</th>\n",
              "      <th>ok</th>\n",
              "      <th>steps</th>\n",
              "      <th>gain</th>\n",
              "      <th>time_sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0.050677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>128</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0.136621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>192</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0.036501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>71</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0.074562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0.080702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9af6dd85-c9c5-4d32-91fd-9dac324ff078')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9af6dd85-c9c5-4d32-91fd-9dac324ff078 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9af6dd85-c9c5-4d32-91fd-9dac324ff078');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   id   n  base_len  alpha    w  beam_width  depth    ok  steps  gain  \\\n",
              "0  71  12        19    0.0  0.5          64     64  True     11     8   \n",
              "1  71  12        19    0.0  0.5          64    128  True     11     8   \n",
              "2  71  12        19    0.0  0.5          64    192  True     11     8   \n",
              "3  71  12        19    0.0  0.5         128     64  True     11     8   \n",
              "4  71  12        19    0.0  0.5         128    128  True     11     8   \n",
              "\n",
              "   time_sec  \n",
              "0  0.050677  \n",
              "1  0.136621  \n",
              "2  0.036501  \n",
              "3  0.074562  \n",
              "4  0.080702  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_list = [12, 15, 16, 20, 25, 30, 35, 40, 45, 50, 75, 100]\n",
        "mini_df = select_cases_per_n(test_df, n_list, k=5, seed=42)\n",
        "\n",
        "alphas = [0.0, 0.5, 1.0]\n",
        "ws = [0.5, 1.0, 1.5]\n",
        "beam_widths = [64, 128, 256]\n",
        "depths = [64, 128, 192]\n",
        "\n",
        "df = run_grid(\n",
        "    mini_df,\n",
        "    alphas=alphas,\n",
        "    ws=ws,\n",
        "    beam_widths=beam_widths,\n",
        "    depths=depths,\n",
        "    log=True,\n",
        "    log_each=100,\n",
        "    beam_log=True,\n",
        "    beam_log_every_layer=5\n",
        ")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B92DtDpnu6y"
      },
      "source": [
        "Во всех конфигурациях beam search успешно находит корректные решения для всех кейсов (solved = 60), а средний выигрыш относительно baseline стабилен и лежит в диапазоне 28-29 шагов. Качество решения растёт с увеличением beam_width, но при этом время выполнения растёт существенно быстрее. Влияние параметров alpha и w на итоговое качество оказывается вторичным. Увеличение глубины поиска (depth) почти не даёт выигрыша, начиная с умеренных значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "ic2hi9VflPAD",
        "outputId": "00b3209f-391f-41d0-afc8-67bf02602cdb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 81,\n  \"fields\": [\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4107919181288746,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.5,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4107919181288746,\n        \"min\": 0.5,\n        \"max\": 1.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5,\n          1.0,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beam_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          256,\n          128,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 64,\n        \"max\": 192,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128,\n          192,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solved\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 60,\n        \"max\": 60,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.265904075027562,\n        \"min\": 0.0,\n        \"max\": 28.583333333333332,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          27.133333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_steps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.265904075027558,\n        \"min\": 38.36666666666667,\n        \"max\": 66.95,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          39.81666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.187344804372477,\n        \"min\": 0.000615545113881429,\n        \"max\": 16.93533452749252,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          5.281863848368327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "summary"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b477d54d-f894-4bee-b551-fa64b1be691a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>w</th>\n",
              "      <th>beam_width</th>\n",
              "      <th>depth</th>\n",
              "      <th>solved</th>\n",
              "      <th>mean_gain</th>\n",
              "      <th>mean_steps</th>\n",
              "      <th>mean_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>38.366667</td>\n",
              "      <td>12.573641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>38.366667</td>\n",
              "      <td>12.693728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.566667</td>\n",
              "      <td>38.383333</td>\n",
              "      <td>12.376708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>256</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.566667</td>\n",
              "      <td>38.383333</td>\n",
              "      <td>12.467067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.550000</td>\n",
              "      <td>38.400000</td>\n",
              "      <td>16.833309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.550000</td>\n",
              "      <td>38.400000</td>\n",
              "      <td>16.935335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.533333</td>\n",
              "      <td>38.416667</td>\n",
              "      <td>16.524541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.533333</td>\n",
              "      <td>38.416667</td>\n",
              "      <td>16.904485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.183333</td>\n",
              "      <td>38.766667</td>\n",
              "      <td>7.376665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.183333</td>\n",
              "      <td>38.766667</td>\n",
              "      <td>7.489081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.166667</td>\n",
              "      <td>38.783333</td>\n",
              "      <td>5.348439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.166667</td>\n",
              "      <td>38.783333</td>\n",
              "      <td>5.421060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.166667</td>\n",
              "      <td>38.783333</td>\n",
              "      <td>7.327492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.166667</td>\n",
              "      <td>38.783333</td>\n",
              "      <td>7.362343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>128</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>28.150000</td>\n",
              "      <td>38.800000</td>\n",
              "      <td>5.333074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>28.150000</td>\n",
              "      <td>38.800000</td>\n",
              "      <td>5.344836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>27.983333</td>\n",
              "      <td>38.966667</td>\n",
              "      <td>2.318383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>64</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>27.983333</td>\n",
              "      <td>38.966667</td>\n",
              "      <td>2.360852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64</td>\n",
              "      <td>192</td>\n",
              "      <td>60</td>\n",
              "      <td>27.966667</td>\n",
              "      <td>38.983333</td>\n",
              "      <td>2.327051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>27.966667</td>\n",
              "      <td>38.983333</td>\n",
              "      <td>2.423247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b477d54d-f894-4bee-b551-fa64b1be691a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b477d54d-f894-4bee-b551-fa64b1be691a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b477d54d-f894-4bee-b551-fa64b1be691a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    alpha    w  beam_width  depth  solved  mean_gain  mean_steps  mean_time\n",
              "7     0.0  0.5         256    128      60  28.583333   38.366667  12.573641\n",
              "8     0.0  0.5         256    192      60  28.583333   38.366667  12.693728\n",
              "16    0.0  1.0         256    128      60  28.566667   38.383333  12.376708\n",
              "17    0.0  1.0         256    192      60  28.566667   38.383333  12.467067\n",
              "34    0.5  0.5         256    128      60  28.550000   38.400000  16.833309\n",
              "35    0.5  0.5         256    192      60  28.550000   38.400000  16.935335\n",
              "61    1.0  0.5         256    128      60  28.533333   38.416667  16.524541\n",
              "62    1.0  0.5         256    192      60  28.533333   38.416667  16.904485\n",
              "31    0.5  0.5         128    128      60  28.183333   38.766667   7.376665\n",
              "32    0.5  0.5         128    192      60  28.183333   38.766667   7.489081\n",
              "5     0.0  0.5         128    192      60  28.166667   38.783333   5.348439\n",
              "4     0.0  0.5         128    128      60  28.166667   38.783333   5.421060\n",
              "58    1.0  0.5         128    128      60  28.166667   38.783333   7.327492\n",
              "59    1.0  0.5         128    192      60  28.166667   38.783333   7.362343\n",
              "14    0.0  1.0         128    192      60  28.150000   38.800000   5.333074\n",
              "13    0.0  1.0         128    128      60  28.150000   38.800000   5.344836\n",
              "1     0.0  0.5          64    128      60  27.983333   38.966667   2.318383\n",
              "2     0.0  0.5          64    192      60  27.983333   38.966667   2.360852\n",
              "11    0.0  1.0          64    192      60  27.966667   38.983333   2.327051\n",
              "10    0.0  1.0          64    128      60  27.966667   38.983333   2.423247"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary = (\n",
        "    df.groupby([\"alpha\",\"w\",\"beam_width\",\"depth\"], as_index=False)\n",
        "      .agg(\n",
        "          solved=(\"ok\",\"sum\"),\n",
        "          mean_gain=(\"gain\",\"mean\"),\n",
        "          mean_steps=(\"steps\",\"mean\"),\n",
        "          mean_time=(\"time_sec\",\"mean\"),\n",
        "      )\n",
        "      .sort_values([\"solved\",\"mean_gain\",\"mean_time\"], ascending=[False, False, True])\n",
        ")\n",
        "\n",
        "summary.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWRrFm3KpGr9"
      },
      "source": [
        "Далее мы фиксируем alpha=0.0 (gap-эвристика) и w=0.5 и создаем сабмит из наилучших результатов трех beam search.\n",
        "\n",
        "1. Лучшее качество: (alpha=0.0, w=0.5, bw=256, depth=128)\n",
        "\n",
        "2. Максимальные beam_depth и beam_width : (alpha=0.0, w=0.5, bw=256, depth=128) (равны по mean_gain)\n",
        "\n",
        "3. Быстрый и экономный: (alpha=0.0, w=0.5, bw=128, depth=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T17:53:06.682998Z",
          "iopub.status.busy": "2026-01-31T17:53:06.682696Z",
          "iopub.status.idle": "2026-01-31T17:53:06.697206Z",
          "shell.execute_reply": "2026-01-31T17:53:06.696627Z",
          "shell.execute_reply.started": "2026-01-31T17:53:06.682973Z"
        },
        "id": "BD-rcUb3ei67",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os, time\n",
        "import pandas as pd\n",
        "\n",
        "def full_eval_top_cfgs(\n",
        "    test_df: pd.DataFrame,\n",
        "    n_list: List[int],\n",
        "    top_cfgs: List[dict],\n",
        "    *,\n",
        "    out_csv_path: str,\n",
        "    baseline_moves_fn=pancake_sort_moves,\n",
        "    log: bool = True,\n",
        "    log_every: int = 50,\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    os.makedirs(os.path.dirname(out_csv_path), exist_ok=True)\n",
        "    sub = test_df[test_df[\"n\"].isin(n_list)].reset_index(drop=True)\n",
        "\n",
        "    done = set()\n",
        "    wrote_header = os.path.exists(out_csv_path)\n",
        "    if wrote_header:\n",
        "        try:\n",
        "            prev = pd.read_csv(out_csv_path, usecols=[\"id\", \"cfg_idx\"])\n",
        "            done = set(zip(prev[\"id\"].astype(int).tolist(), prev[\"cfg_idx\"].astype(int).tolist()))\n",
        "            if log:\n",
        "                print(f\"[resume] found existing file with {len(done)} completed runs\", flush=True)\n",
        "        except Exception as e:\n",
        "            if log:\n",
        "                print(f\"[resume] could not read existing file safely: {e!r} (will append anyway)\", flush=True)\n",
        "\n",
        "    rows_cache = []\n",
        "\n",
        "    t_global0 = time.time()\n",
        "    total_cases = len(sub)\n",
        "    total_runs = total_cases * len(top_cfgs)\n",
        "\n",
        "    run_idx = 0\n",
        "    skipped = 0\n",
        "\n",
        "    for i in range(total_cases):\n",
        "        rid = int(sub.loc[i, \"id\"])\n",
        "        perm = parse_permutation(sub.loc[i, \"permutation\"])\n",
        "        n = len(perm)\n",
        "\n",
        "        base_moves = baseline_moves_fn(perm)\n",
        "        base_len = len(base_moves)\n",
        "\n",
        "        for cfg_j, cfg in enumerate(top_cfgs):\n",
        "            run_idx += 1\n",
        "\n",
        "            if (rid, cfg_j) in done:\n",
        "                skipped += 1\n",
        "                if log and (run_idx % log_every == 0):\n",
        "                    elapsed = time.time() - t_global0\n",
        "                    speed = (run_idx - skipped) / max(1e-9, elapsed)\n",
        "                    log_print(True, f\"[full] {run_idx}/{total_runs} runs | skipped={skipped} | speed={speed:.3f} new_runs/s\")\n",
        "                continue\n",
        "\n",
        "            alpha = float(cfg[\"alpha\"])\n",
        "            w = float(cfg[\"w\"])\n",
        "            bw = int(cfg[\"beam_width\"])\n",
        "            depth = int(cfg[\"depth\"])\n",
        "\n",
        "            t0 = time.time()\n",
        "            status = \"ok\"\n",
        "            err_txt = \"\"\n",
        "\n",
        "            try:\n",
        "                h_fn = make_h(alpha)\n",
        "                moves = beam_improve_or_baseline_h(\n",
        "                    perm,\n",
        "                    baseline_moves_fn=baseline_moves_fn,\n",
        "                    h_fn=h_fn,\n",
        "                    beam_width=bw,\n",
        "                    depth=depth,\n",
        "                    w=w,\n",
        "                    log=False,\n",
        "                )\n",
        "\n",
        "                if apply_moves(perm, moves) != list(range(n)):\n",
        "                    moves = base_moves\n",
        "                    status = \"fallback_baseline\"\n",
        "\n",
        "            except Exception as e:\n",
        "                moves = base_moves\n",
        "                status = \"error_fallback_baseline\"\n",
        "                err_txt = repr(e)\n",
        "\n",
        "            dt = time.time() - t0\n",
        "\n",
        "            steps = len(moves)\n",
        "            gain = base_len - steps\n",
        "            sol_str = moves_to_str(moves)\n",
        "\n",
        "            row = {\n",
        "                \"id\": rid,\n",
        "                \"n\": n,\n",
        "                \"cfg_idx\": cfg_j,\n",
        "                \"alpha\": alpha,\n",
        "                \"w\": w,\n",
        "                \"beam_width\": bw,\n",
        "                \"depth\": depth,\n",
        "                \"base_len\": base_len,\n",
        "                \"ok\": (status == \"ok\"),\n",
        "                \"steps\": steps,\n",
        "                \"gain\": gain,\n",
        "                \"time_sec\": dt,\n",
        "                \"solution\": sol_str,\n",
        "                \"status\": status,\n",
        "                \"error\": err_txt,\n",
        "            }\n",
        "\n",
        "            rows_cache.append(row)\n",
        "            done.add((rid, cfg_j))\n",
        "\n",
        "            if len(rows_cache) >= 200:\n",
        "                pd.DataFrame(rows_cache).to_csv(\n",
        "                    out_csv_path,\n",
        "                    mode=\"a\",\n",
        "                    header=not wrote_header,\n",
        "                    index=False\n",
        "                )\n",
        "                wrote_header = True\n",
        "                rows_cache.clear()\n",
        "\n",
        "            if log and (run_idx % log_every == 0):\n",
        "                elapsed = time.time() - t_global0\n",
        "                new_done = run_idx - skipped\n",
        "                speed = new_done / max(1e-9, elapsed)  # new runs/sec\n",
        "                log_print(\n",
        "                    True,\n",
        "                    f\"[full] {run_idx}/{total_runs} runs | new={new_done} skipped={skipped} | \"\n",
        "                    f\"n={n} cfg={cfg_j} steps={steps} gain={gain} status={status} | {speed:.3f} new_runs/s\"\n",
        "                )\n",
        "\n",
        "    if rows_cache:\n",
        "        pd.DataFrame(rows_cache).to_csv(\n",
        "            out_csv_path,\n",
        "            mode=\"a\",\n",
        "            header=not wrote_header,\n",
        "            index=False\n",
        "        )\n",
        "\n",
        "    return pd.read_csv(out_csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9i3kJ6MvxV5"
      },
      "source": [
        "Выполним полный прогон выбранных конфигураций (top_cfgs) на множестве всех тестовых примеров с размерами из n_list и сохраним результаты в CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_Jm1XnpeqqU"
      },
      "outputs": [],
      "source": [
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "OUT_CSV = f\"{OUT_DIR}/full_eval_top_cfgs_seed42.csv\"\n",
        "n_list = [5, 12, 15, 16, 20, 25, 30, 35, 40, 45, 50, 75, 100]\n",
        "\n",
        "top_cfgs = [\n",
        "    {\"alpha\": 0.0, \"w\": 0.5, \"beam_width\": 128, \"depth\": 128},\n",
        "    {\"alpha\": 0.0, \"w\": 0.5, \"beam_width\": 256, \"depth\": 128},\n",
        "    {\"alpha\": 0.0, \"w\": 0.5, \"beam_width\": 256, \"depth\": 192},\n",
        "]\n",
        "\n",
        "df_full = full_eval_top_cfgs(\n",
        "    test_df, n_list, top_cfgs,\n",
        "    out_csv_path=OUT_CSV,\n",
        "    log=True,\n",
        "    log_every=100,\n",
        ")\n",
        "\n",
        "df_full.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7VCb3j-2M69"
      },
      "source": [
        "Эксперименты показывают, что увеличение ширины луча с 128 до 256 даёт лишь маргинальный прирост качества (≈0.27 шага в среднем), при этом увеличивая время выполнения более чем в два раза. Увеличение глубины поиска с 128 до 192 не оказывает измеримого влияния на качество.\n",
        "\n",
        "Конфигурация beam_width=128, depth=128 выглядит как оптимальный компромисс между качеством и вычислительной стоимостью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "n_XTRCzEfbmI",
        "outputId": "bdd29adc-b49a-414f-d7f4-1dc68b210602"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"summary_full\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"cfg_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beam_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73,\n        \"min\": 128,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 128,\n        \"max\": 192,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solved\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2405,\n        \"max\": 2405,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1584412381144086,\n        \"min\": 27.585446985446985,\n        \"max\": 27.85987525987526,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          27.585446985446985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_steps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1584412381144086,\n        \"min\": 38.11933471933472,\n        \"max\": 38.39376299376299,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          38.39376299376299\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.902221455704867,\n        \"min\": 4.977609740175973,\n        \"max\": 11.74184330367249,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          11.731054908768304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "summary_full"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e1969284-03ac-4b8e-9c84-f7f165f0feca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cfg_idx</th>\n",
              "      <th>alpha</th>\n",
              "      <th>w</th>\n",
              "      <th>beam_width</th>\n",
              "      <th>depth</th>\n",
              "      <th>solved</th>\n",
              "      <th>mean_gain</th>\n",
              "      <th>mean_steps</th>\n",
              "      <th>mean_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>192</td>\n",
              "      <td>2405</td>\n",
              "      <td>27.859875</td>\n",
              "      <td>38.119335</td>\n",
              "      <td>11.731055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>2405</td>\n",
              "      <td>27.859875</td>\n",
              "      <td>38.119335</td>\n",
              "      <td>11.741843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>2405</td>\n",
              "      <td>27.585447</td>\n",
              "      <td>38.393763</td>\n",
              "      <td>4.977610</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1969284-03ac-4b8e-9c84-f7f165f0feca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1969284-03ac-4b8e-9c84-f7f165f0feca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1969284-03ac-4b8e-9c84-f7f165f0feca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ac6dd26e-30c7-4d47-8ba0-fd08fb9de2f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary_full')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ac6dd26e-30c7-4d47-8ba0-fd08fb9de2f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary_full');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   cfg_idx  alpha    w  beam_width  depth  solved  mean_gain  mean_steps  \\\n",
              "2        2    0.0  0.5         256    192    2405  27.859875   38.119335   \n",
              "1        1    0.0  0.5         256    128    2405  27.859875   38.119335   \n",
              "0        0    0.0  0.5         128    128    2405  27.585447   38.393763   \n",
              "\n",
              "   mean_time  \n",
              "2  11.731055  \n",
              "1  11.741843  \n",
              "0   4.977610  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary_full = (\n",
        "    df_full.groupby([\"cfg_idx\",\"alpha\",\"w\",\"beam_width\",\"depth\"], as_index=False)\n",
        "           .agg(\n",
        "               solved=(\"ok\",\"sum\"),\n",
        "               mean_gain=(\"gain\",\"mean\"),\n",
        "               mean_steps=(\"steps\",\"mean\"),\n",
        "               mean_time=(\"time_sec\",\"mean\"),\n",
        "           )\n",
        "           .sort_values([\"solved\",\"mean_gain\",\"mean_time\"], ascending=[False, False, True])\n",
        ")\n",
        "summary_full\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvuoPrzkz3tp"
      },
      "source": [
        "Функция сравнивает качество решений из submission_df с выбранным baseline-алгоритмом на полном test_df. Для каждого примера она считает длину baseline-решения и длину решения из сабмита, накапливая суммарные значения и статистику (сколько улучшили/ухудшили, максимальный выигрыш и т.п.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihHCH2aG1fHh"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Optional\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_submission_vs_baseline(\n",
        "    test_df: pd.DataFrame,\n",
        "    submission_df: pd.DataFrame,\n",
        "    *,\n",
        "    baseline_moves_fn,\n",
        "    log_every: int = 0,\n",
        "    save_detailed_path: Optional[str] = None,\n",
        ") -> Dict:\n",
        "    t0 = time.time()\n",
        "    sub_map = dict(zip(submission_df[\"id\"].astype(int), submission_df[\"solution\"].astype(str)))\n",
        "\n",
        "    sum_base = 0\n",
        "    sum_sub = 0\n",
        "    improved = same = worse = 0\n",
        "    total_gain_pos = 0\n",
        "    max_gain = 0\n",
        "    max_gain_id = None\n",
        "\n",
        "    N = len(test_df)\n",
        "\n",
        "    detailed_rows = [] if save_detailed_path else None\n",
        "\n",
        "    for i, row in enumerate(test_df.itertuples(index=False), start=1):\n",
        "        rid = int(row.id)\n",
        "        perm = parse_permutation(row.permutation)\n",
        "\n",
        "        base = baseline_moves_fn(perm)\n",
        "        lb = len(base)\n",
        "\n",
        "        sol = sub_map.get(rid, \"\")\n",
        "        lz = moves_len(sol)\n",
        "\n",
        "        sum_base += lb\n",
        "        sum_sub += lz\n",
        "\n",
        "        gain = lb - lz\n",
        "        if gain > 0:\n",
        "            improved += 1\n",
        "            total_gain_pos += gain\n",
        "            if gain > max_gain:\n",
        "                max_gain = gain\n",
        "                max_gain_id = rid\n",
        "        elif gain == 0:\n",
        "            same += 1\n",
        "        else:\n",
        "            worse += 1\n",
        "\n",
        "        if detailed_rows is not None:\n",
        "            detailed_rows.append({\n",
        "                \"id\": rid,\n",
        "                \"n\": len(perm),\n",
        "                \"base_len\": lb,\n",
        "                \"sub_len\": lz,\n",
        "                \"gain\": gain,\n",
        "            })\n",
        "\n",
        "        if log_every and (i % log_every == 0 or i == 1 or i == N):\n",
        "            print(f\"[{i:4d}/{N}] base={lb:3d} sub={lz:3d} gain={gain:3d}  elapsed={time.time()-t0:7.1f}s\",\n",
        "                  flush=True)\n",
        "\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    if save_detailed_path:\n",
        "        pd.DataFrame(detailed_rows).to_csv(save_detailed_path, index=False)\n",
        "\n",
        "    return {\n",
        "        \"baseline_total\": sum_base,\n",
        "        \"submission_total\": sum_sub,\n",
        "        \"total_gain\": (sum_base - sum_sub),\n",
        "        \"improved_cases\": improved,\n",
        "        \"same_cases\": same,\n",
        "        \"worse_cases\": worse,\n",
        "        \"avg_gain_when_improved\": (total_gain_pos / improved) if improved else 0.0,\n",
        "        \"max_gain\": max_gain,\n",
        "        \"max_gain_id\": max_gain_id,\n",
        "        \"time_sec\": dt,\n",
        "        \"sec_per_sample\": dt / max(1, N),\n",
        "        \"mean_baseline_len\": sum_base / max(1, N),\n",
        "        \"mean_submission_len\": sum_sub / max(1, N),\n",
        "        \"improved_frac\": improved / max(1, N),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJJt6XGn3TQT"
      },
      "source": [
        "Мы сравнили итоговый submission с baseline-алгоритмом (классический pancake sorting) на всём тестовом наборе из 2405 перестановок. Submission улучшает baseline в 2401 случаях (99.83%), не ухудшая результат ни в одном кейсе; ещё в 4 случаях длины совпадают. Суммарная длина решений снизилась с 158 680 до **91 594** ходов, что даёт общий выигрыш 67 086 ходов и средний выигрыш 27.94 шага на улучшенных примерах. Максимальный выигрыш на одном кейсе составил 92 шага (id=2342)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHGllvbLL8Ya",
        "outputId": "683b2f75-271e-48a8-8110-0f439f78afee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   1/2405] base=  2 sub=  2 gain=  0  elapsed=    0.0s\n",
            "[  50/2405] base= 19 sub=  8 gain= 11  elapsed=    0.0s\n",
            "[ 100/2405] base= 20 sub= 12 gain=  8  elapsed=    0.0s\n",
            "[ 150/2405] base= 16 sub= 11 gain=  5  elapsed=    0.0s\n",
            "[ 200/2405] base= 15 sub= 11 gain=  4  elapsed=    0.0s\n",
            "[ 250/2405] base= 19 sub= 15 gain=  4  elapsed=    0.0s\n",
            "[ 300/2405] base= 20 sub= 14 gain=  6  elapsed=    0.0s\n",
            "[ 350/2405] base= 20 sub= 15 gain=  5  elapsed=    0.0s\n",
            "[ 400/2405] base= 21 sub= 14 gain=  7  elapsed=    0.0s\n",
            "[ 450/2405] base= 21 sub= 13 gain=  8  elapsed=    0.0s\n",
            "[ 500/2405] base= 25 sub= 15 gain= 10  elapsed=    0.0s\n",
            "[ 550/2405] base= 25 sub= 15 gain= 10  elapsed=    0.0s\n",
            "[ 600/2405] base= 21 sub= 12 gain=  9  elapsed=    0.0s\n",
            "[ 650/2405] base= 32 sub= 20 gain= 12  elapsed=    0.0s\n",
            "[ 700/2405] base= 34 sub= 19 gain= 15  elapsed=    0.0s\n",
            "[ 750/2405] base= 32 sub= 19 gain= 13  elapsed=    0.0s\n",
            "[ 800/2405] base= 33 sub= 19 gain= 14  elapsed=    0.0s\n",
            "[ 850/2405] base= 42 sub= 24 gain= 18  elapsed=    0.0s\n",
            "[ 900/2405] base= 38 sub= 24 gain= 14  elapsed=    0.0s\n",
            "[ 950/2405] base= 45 sub= 26 gain= 19  elapsed=    0.0s\n",
            "[1000/2405] base= 43 sub= 23 gain= 20  elapsed=    0.0s\n",
            "[1050/2405] base= 49 sub= 30 gain= 19  elapsed=    0.0s\n",
            "[1100/2405] base= 47 sub= 29 gain= 18  elapsed=    0.1s\n",
            "[1150/2405] base= 53 sub= 30 gain= 23  elapsed=    0.1s\n",
            "[1200/2405] base= 50 sub= 27 gain= 23  elapsed=    0.1s\n",
            "[1250/2405] base= 57 sub= 35 gain= 22  elapsed=    0.1s\n",
            "[1300/2405] base= 55 sub= 33 gain= 22  elapsed=    0.1s\n",
            "[1350/2405] base= 59 sub= 35 gain= 24  elapsed=    0.1s\n",
            "[1400/2405] base= 58 sub= 33 gain= 25  elapsed=    0.1s\n",
            "[1450/2405] base= 66 sub= 40 gain= 26  elapsed=    0.1s\n",
            "[1500/2405] base= 68 sub= 41 gain= 27  elapsed=    0.1s\n",
            "[1550/2405] base= 70 sub= 40 gain= 30  elapsed=    0.1s\n",
            "[1600/2405] base= 61 sub= 38 gain= 23  elapsed=    0.1s\n",
            "[1650/2405] base= 73 sub= 41 gain= 32  elapsed=    0.1s\n",
            "[1700/2405] base= 80 sub= 45 gain= 35  elapsed=    0.1s\n",
            "[1750/2405] base= 79 sub= 45 gain= 34  elapsed=    0.1s\n",
            "[1800/2405] base= 71 sub= 46 gain= 25  elapsed=    0.1s\n",
            "[1850/2405] base= 86 sub= 50 gain= 36  elapsed=    0.1s\n",
            "[1900/2405] base= 89 sub= 49 gain= 40  elapsed=    0.1s\n",
            "[1950/2405] base= 87 sub= 47 gain= 40  elapsed=    0.1s\n",
            "[2000/2405] base= 91 sub= 50 gain= 41  elapsed=    0.2s\n",
            "[2050/2405] base=134 sub= 78 gain= 56  elapsed=    0.2s\n",
            "[2100/2405] base=136 sub= 78 gain= 58  elapsed=    0.2s\n",
            "[2150/2405] base=128 sub= 72 gain= 56  elapsed=    0.2s\n",
            "[2200/2405] base=137 sub= 78 gain= 59  elapsed=    0.2s\n",
            "[2250/2405] base=187 sub=102 gain= 85  elapsed=    0.2s\n",
            "[2300/2405] base=186 sub=104 gain= 82  elapsed=    0.2s\n",
            "[2350/2405] base=185 sub=103 gain= 82  elapsed=    0.3s\n",
            "[2400/2405] base=189 sub=102 gain= 87  elapsed=    0.3s\n",
            "[2405/2405] base=188 sub=104 gain= 84  elapsed=    0.3s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'baseline_total': 158680,\n",
              " 'submission_total': 91594,\n",
              " 'total_gain': 67086,\n",
              " 'improved_cases': 2401,\n",
              " 'same_cases': 4,\n",
              " 'worse_cases': 0,\n",
              " 'avg_gain_when_improved': 27.9408579758434,\n",
              " 'max_gain': 92,\n",
              " 'max_gain_id': 2342,\n",
              " 'time_sec': 0.2909247875213623,\n",
              " 'sec_per_sample': 0.00012096664761803007,\n",
              " 'mean_baseline_len': 65.97920997920998,\n",
              " 'mean_submission_len': 38.08482328482329,\n",
              " 'improved_frac': 0.9983367983367983}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub_df = pd.read_csv(\"/content/drive/MyDrive/pancake_runs/submission_bs.csv\")\n",
        "stats = evaluate_submission_vs_baseline(\n",
        "    test_df=test_df,\n",
        "    submission_df=sub_df,\n",
        "    baseline_moves_fn=pancake_sort_moves,\n",
        "    log_every=50,\n",
        "    save_detailed_path=\"sub_vs_base_details.csv\",\n",
        ")\n",
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAEzh6R22TTg"
      },
      "source": [
        "Агрегация результатов по размерам перестановок показывает, что выигрыш относительно baseline растёт почти линейно с n. При n=12 средний выигрыш составляет около 5 шагов, тогда как при n=100 он превышает 80 шагов. При этом не наблюдается ни одного случая ухудшения решения. Более того, относительное сокращение длины решения увеличивается с ростом n, что указывает на хорошую масштабируемость предложенного апгрейда и его способность эффективно эксплуатировать структуру pancake-графа на больших размерах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "PO729v7a4g4u",
        "outputId": "e563e069-bd82-4728-ebcc-f1657208f8c2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"        \",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 5,\n        \"max\": 100,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          75,\n          45,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.63166992401163,\n        \"min\": 0.2,\n        \"max\": 82.99,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          59.775,\n          32.975,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"improved\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55,\n        \"min\": 1,\n        \"max\": 200,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          200,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"worse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_base\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.77504904416452,\n        \"min\": 3.4,\n        \"max\": 185.73,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          136.195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_sub\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.147214810751066,\n        \"min\": 3.2,\n        \"max\": 102.74,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          76.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6fd815b9-a0b9-4d5c-b380-2a0e9584d058\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>mean_gain</th>\n",
              "      <th>improved</th>\n",
              "      <th>worse</th>\n",
              "      <th>mean_base</th>\n",
              "      <th>mean_sub</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.200</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.400</td>\n",
              "      <td>3.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>4.990</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>15.820</td>\n",
              "      <td>10.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>7.390</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>21.130</td>\n",
              "      <td>13.740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>7.965</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>22.780</td>\n",
              "      <td>14.815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>11.550</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>30.460</td>\n",
              "      <td>18.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>15.740</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>39.615</td>\n",
              "      <td>23.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>30</td>\n",
              "      <td>20.625</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>49.550</td>\n",
              "      <td>28.925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35</td>\n",
              "      <td>24.745</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>58.750</td>\n",
              "      <td>34.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>40</td>\n",
              "      <td>29.235</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>68.470</td>\n",
              "      <td>39.235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>45</td>\n",
              "      <td>32.975</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>77.450</td>\n",
              "      <td>44.475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>50</td>\n",
              "      <td>37.445</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>87.365</td>\n",
              "      <td>49.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>75</td>\n",
              "      <td>59.775</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>136.195</td>\n",
              "      <td>76.420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>82.990</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>185.730</td>\n",
              "      <td>102.740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fd815b9-a0b9-4d5c-b380-2a0e9584d058')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fd815b9-a0b9-4d5c-b380-2a0e9584d058 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fd815b9-a0b9-4d5c-b380-2a0e9584d058');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      n  mean_gain  improved  worse  mean_base  mean_sub\n",
              "0     5      0.200         1      0      3.400     3.200\n",
              "1    12      4.990       200      0     15.820    10.830\n",
              "2    15      7.390       200      0     21.130    13.740\n",
              "3    16      7.965       200      0     22.780    14.815\n",
              "4    20     11.550       200      0     30.460    18.910\n",
              "5    25     15.740       200      0     39.615    23.875\n",
              "6    30     20.625       200      0     49.550    28.925\n",
              "7    35     24.745       200      0     58.750    34.005\n",
              "8    40     29.235       200      0     68.470    39.235\n",
              "9    45     32.975       200      0     77.450    44.475\n",
              "10   50     37.445       200      0     87.365    49.920\n",
              "11   75     59.775       200      0    136.195    76.420\n",
              "12  100     82.990       200      0    185.730   102.740"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "details = pd.read_csv(\"sub_vs_base_details.csv\")\n",
        "(details.groupby(\"n\", as_index=False)\n",
        "        .agg(mean_gain=(\"gain\",\"mean\"),\n",
        "             improved=(\"gain\", lambda x: (x>0).sum()),\n",
        "             worse=(\"gain\", lambda x: (x<0).sum()),\n",
        "             mean_base=(\"base_len\",\"mean\"),\n",
        "             mean_sub=(\"sub_len\",\"mean\"))\n",
        "        .sort_values(\"n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye3GdqjG4KXd"
      },
      "source": [
        "Классический pancake sorting быстро становится неоптимальным при росте n, тогда как ограниченный эвристический поиск находит всё более короткие траектории, причём выигрыш растёт пропорционально размеру задачи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26bKjea54KdE"
      },
      "source": [
        "# ML-heuristic with DL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:33.178123Z",
          "iopub.status.busy": "2026-02-01T07:41:33.177498Z",
          "iopub.status.idle": "2026-02-01T07:41:43.956597Z",
          "shell.execute_reply": "2026-02-01T07:41:43.955827Z",
          "shell.execute_reply.started": "2026-02-01T07:41:33.178092Z"
        },
        "id": "38_wejiyGo8o",
        "outputId": "accbf778-20da-47f9-fa50-f76bd8a7bd8b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/cayleypy/cayleypy.git@e1518b6\n",
            "  Cloning https://github.com/cayleypy/cayleypy.git (to revision e1518b6) to /tmp/pip-req-build-rxi6fpu1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cayleypy/cayleypy.git /tmp/pip-req-build-rxi6fpu1\n",
            "\u001b[33m  WARNING: Did not find branch or tag 'e1518b6', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q e1518b6\n",
            "  Resolved https://github.com/cayleypy/cayleypy.git to commit e1518b6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: cayleypy\n",
            "  Building wheel for cayleypy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cayleypy: filename=cayleypy-0.1.0-py3-none-any.whl size=592103 sha256=ba6530e7983b2908468466a2ec1fce46ee6cd69e33c8f571d908835d23ed90dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cf_l8bti/wheels/bb/02/6c/551e0b1e957367d2581e24443666bf3222295029a6821a4726\n",
            "Successfully built cayleypy\n",
            "Installing collected packages: cayleypy\n",
            "Successfully installed cayleypy-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/cayleypy/cayleypy.git@e1518b6 --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:43.958782Z",
          "iopub.status.busy": "2026-02-01T07:41:43.958511Z",
          "iopub.status.idle": "2026-02-01T07:41:55.919399Z",
          "shell.execute_reply": "2026-02-01T07:41:55.918636Z",
          "shell.execute_reply.started": "2026-02-01T07:41:43.958752Z"
        },
        "id": "hx7pS9aOEO37",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os, time, json, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from heapq import nsmallest\n",
        "from typing import Any, Optional, List, Tuple, Dict, Iterable\n",
        "from copy import deepcopy\n",
        "from itertools import product\n",
        "from cayleypy import PermutationGroups, CayleyGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUsd0Mof47wl"
      },
      "source": [
        "Далее рассмотрим семейство регрессионных моделей.\n",
        "Реализованы три варианта представления входа:\n",
        "1. One-hot MLP (простая базовая)\n",
        "2. One-hot MLP с residual-стеком\n",
        "3. Embedding-версия\n",
        "\n",
        "Embedding-регрессор заменяет one-hot представление на обучаемые эмбеддинги токенов (значений перестановки), что обычно существенно экономит память и ускоряет вычисления при больших n. Дополнительно может добавляться позиционный эмбеддинг, позволяющий модели различать одинаковые значения в разных позициях и лучше реагировать на структуру перестановки. После эмбеддингов последовательность разворачивается в вектор и обрабатывается MLP (как в Pilgrim), включая опциональные residual-блоки.\n",
        "\n",
        " Функция get_model выбирает архитектуру по cfg[\"model_type\"], позволяя переключать модели без изменения остального пайплайна."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:55.92094Z",
          "iopub.status.busy": "2026-02-01T07:41:55.920412Z",
          "iopub.status.idle": "2026-02-01T07:41:55.944925Z",
          "shell.execute_reply": "2026-02-01T07:41:55.944228Z",
          "shell.execute_reply.started": "2026-02-01T07:41:55.920906Z"
        },
        "id": "blp8bfPREgwP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim: int, dropout_rate: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = x + r\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Pilgrim(nn.Module):\n",
        "    \"\"\"\n",
        "    One-hot MLP + optional 2nd layer + residual stack.\n",
        "    Input: z (B,n) int permutation\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Dict[str, Any]):\n",
        "        super().__init__()\n",
        "        self.dtype = torch.float32\n",
        "        self.state_size = int(cfg[\"state_size\"])\n",
        "        self.num_classes = int(cfg[\"num_classes\"])\n",
        "        self.hd1 = int(cfg.get(\"hd1\", 512))\n",
        "        self.hd2 = int(cfg.get(\"hd2\", 256))\n",
        "        self.nrd = int(cfg.get(\"nrd\", 0))\n",
        "        self.dropout_rate = float(cfg.get(\"dropout_rate\", 0.1))\n",
        "        self.z_add = 0\n",
        "\n",
        "        in_dim = self.state_size * self.num_classes\n",
        "        self.input_layer = nn.Linear(in_dim, self.hd1)\n",
        "        self.bn1 = nn.BatchNorm1d(self.hd1)\n",
        "        self.drop1 = nn.Dropout(self.dropout_rate)\n",
        "\n",
        "        if self.hd2 > 0:\n",
        "            self.hidden_layer = nn.Linear(self.hd1, self.hd2)\n",
        "            self.bn2 = nn.BatchNorm1d(self.hd2)\n",
        "            self.drop2 = nn.Dropout(self.dropout_rate)\n",
        "            hid = self.hd2\n",
        "        else:\n",
        "            self.hidden_layer = None\n",
        "            self.bn2 = None\n",
        "            self.drop2 = None\n",
        "            hid = self.hd1\n",
        "\n",
        "        self.residual_blocks = None\n",
        "        if self.nrd > 0:\n",
        "            self.residual_blocks = nn.ModuleList([ResidualBlock(hid, self.dropout_rate) for _ in range(self.nrd)])\n",
        "\n",
        "        self.out = nn.Linear(hid, 1)\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.one_hot((z.long() + self.z_add), num_classes=self.num_classes).view(z.size(0), -1).to(self.dtype)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        if self.hidden_layer is not None:\n",
        "            x = self.hidden_layer(x)\n",
        "            x = self.bn2(x)\n",
        "            x = F.relu(x)\n",
        "            x = self.drop2(x)\n",
        "\n",
        "        if self.residual_blocks is not None:\n",
        "            for blk in self.residual_blocks:\n",
        "                x = blk(x)\n",
        "\n",
        "        return self.out(x).flatten()\n",
        "\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Configurable one-hot MLP.\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Dict[str, Any]):\n",
        "        super().__init__()\n",
        "        self.dtype = torch.float32\n",
        "        self.state_size = int(cfg[\"state_size\"])\n",
        "        self.num_classes = int(cfg[\"num_classes\"])\n",
        "        self.z_add = 0\n",
        "\n",
        "        layers = list(cfg[\"layers\"])\n",
        "        batch_norms = list(cfg.get(\"batch_norms\", [True]*len(layers)))\n",
        "        dropouts = cfg.get(\"dropout_rates\", 0.1)\n",
        "        activations = cfg.get(\"activations\", nn.ReLU())\n",
        "\n",
        "        if not isinstance(dropouts, list):\n",
        "            dropouts = [dropouts]*len(layers)\n",
        "        if not isinstance(activations, list):\n",
        "            activations = [activations]*len(layers)\n",
        "\n",
        "        in_dim = self.state_size * self.num_classes\n",
        "        seq = []\n",
        "        for h, bn, act, dr in zip(layers, batch_norms, activations, dropouts):\n",
        "            seq.append(nn.Linear(in_dim, int(h)))\n",
        "            if bn:\n",
        "                seq.append(nn.BatchNorm1d(int(h)))\n",
        "            seq.append(act)\n",
        "            seq.append(nn.Dropout(float(dr)))\n",
        "            in_dim = int(h)\n",
        "        seq.append(nn.Linear(in_dim, 1))\n",
        "        self.net = nn.Sequential(*seq)\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.one_hot((z.long() + self.z_add), num_classes=self.num_classes).view(z.size(0), -1).to(self.dtype)\n",
        "        return self.net(x).flatten()\n",
        "\n",
        "\n",
        "class EmbMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Embedding-based regressor (recommended).\n",
        "    Input: z (B,n) ints in [0..n-1]\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Dict[str, Any]):\n",
        "        super().__init__()\n",
        "        self.dtype = torch.float32\n",
        "        self.state_size = int(cfg[\"state_size\"])\n",
        "        self.num_classes = int(cfg[\"num_classes\"])\n",
        "        assert self.state_size == self.num_classes, \"For pancakes, state_size==num_classes==n\"\n",
        "        self.z_add = 0\n",
        "\n",
        "        d = int(cfg.get(\"emb_dim\", 32))\n",
        "        self.use_pos_emb = bool(cfg.get(\"use_pos_emb\", True))\n",
        "        dropout = float(cfg.get(\"dropout_rate\", 0.1))\n",
        "\n",
        "        self.token_emb = nn.Embedding(self.num_classes, d)\n",
        "        if self.use_pos_emb:\n",
        "            self.pos_emb = nn.Embedding(self.state_size, d)\n",
        "            self.register_buffer(\"_pos_idx\", torch.arange(self.state_size, dtype=torch.long), persistent=False)\n",
        "\n",
        "        hd1 = int(cfg.get(\"hd1\", 512))\n",
        "        hd2 = int(cfg.get(\"hd2\", 256))\n",
        "        nrd = int(cfg.get(\"nrd\", 0))\n",
        "\n",
        "        in_dim = self.state_size * d\n",
        "        self.fc1 = nn.Linear(in_dim, hd1)\n",
        "        self.bn1 = nn.BatchNorm1d(hd1)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        if hd2 > 0:\n",
        "            self.fc2 = nn.Linear(hd1, hd2)\n",
        "            self.bn2 = nn.BatchNorm1d(hd2)\n",
        "            self.drop2 = nn.Dropout(dropout)\n",
        "            hid = hd2\n",
        "        else:\n",
        "            self.fc2 = None\n",
        "            self.bn2 = None\n",
        "            self.drop2 = None\n",
        "            hid = hd1\n",
        "\n",
        "        self.residual_blocks = None\n",
        "        if nrd > 0:\n",
        "            self.residual_blocks = nn.ModuleList([ResidualBlock(hid, dropout) for _ in range(nrd)])\n",
        "\n",
        "        self.out = nn.Linear(hid, 1)\n",
        "\n",
        "        nn.init.normal_(self.token_emb.weight, mean=0.0, std=0.02)\n",
        "        if self.use_pos_emb:\n",
        "            nn.init.normal_(self.pos_emb.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        z = (z.long() + self.z_add).clamp(min=0, max=self.num_classes-1)\n",
        "        x = self.token_emb(z)  # (B,n,d)\n",
        "        if self.use_pos_emb:\n",
        "            pos = self._pos_idx.to(z.device)\n",
        "            x = x + self.pos_emb(pos)[None, :, :]\n",
        "        x = x.reshape(z.size(0), -1).to(self.dtype)\n",
        "\n",
        "        x = self.fc1(x); x = self.bn1(x); x = F.relu(x); x = self.drop1(x)\n",
        "        if self.fc2 is not None:\n",
        "            x = self.fc2(x); x = self.bn2(x); x = F.relu(x); x = self.drop2(x)\n",
        "        if self.residual_blocks is not None:\n",
        "            for blk in self.residual_blocks:\n",
        "                x = blk(x)\n",
        "        return self.out(x).flatten()\n",
        "\n",
        "\n",
        "def get_model(cfg: Dict[str, Any]) -> nn.Module:\n",
        "    mt = cfg.get(\"model_type\", \"EmbMLP\")\n",
        "    if mt == \"EmbMLP\":\n",
        "        return EmbMLP(cfg)\n",
        "    if mt == \"MLPRes1\":\n",
        "        return Pilgrim(cfg)\n",
        "    if mt == \"MLP\":\n",
        "        return SimpleMLP(cfg)\n",
        "    raise ValueError(f\"Unknown model_type={mt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5avWc9e-7RQB"
      },
      "source": [
        "\n",
        "Зададим вспомогательные утилиты для воспроизводимых экспериментов и удобной организации артефактов. Здесь фиксируется базовая конфигурация обучения (BASE_CFG), предоставляется способ порождать конфиги с переопределениями (make_cfg) и строится сетка архитектурных вариантов для перебора (build_model_grid). Дополнительно формируется читаемое имя эксперимента (exp_name_from), чтобы результаты можно было систематизировать по параметрам модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:55.947001Z",
          "iopub.status.busy": "2026-02-01T07:41:55.946457Z",
          "iopub.status.idle": "2026-02-01T07:41:55.970991Z",
          "shell.execute_reply": "2026-02-01T07:41:55.970442Z",
          "shell.execute_reply.started": "2026-02-01T07:41:55.946977Z"
        },
        "id": "X6LJlNV6E_tB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def ensure_dir(path: str):\n",
        "    if path and not os.path.exists(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def now_str():\n",
        "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "\n",
        "def set_seed(seed: int = 123):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def exp_name_from(cfg: dict, *, n: int, w_gap: float, gap_mode: str):\n",
        "    mt = cfg.get(\"model_type\", \"EmbMLP\")\n",
        "    nrd = int(cfg.get(\"nrd\", 0))\n",
        "    if mt == \"EmbMLP\":\n",
        "        ed = int(cfg.get(\"emb_dim\", -1))\n",
        "        pos = 1 if bool(cfg.get(\"use_pos_emb\", True)) else 0\n",
        "        return f\"n{n}_{mt}_ed{ed}_pos{pos}_nrd{nrd}_wg{w_gap}_{gap_mode}\"\n",
        "    if mt == \"MLPRes1\":\n",
        "        return f\"n{n}_{mt}_nrd{nrd}_wg{w_gap}_{gap_mode}\"\n",
        "    return f\"n{n}_{mt}_wg{w_gap}_{gap_mode}\"\n",
        "\n",
        "BASE_CFG = dict(\n",
        "    rw_width=3000,\n",
        "    rw_mode=\"mix\",\n",
        "    mix_bfs_frac=0.3,\n",
        "    nbt_history_depth=1,\n",
        "    k=4,\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-2,\n",
        "    batch_size=1024,\n",
        "    val_ratio=0.15,\n",
        "    num_epochs=30,\n",
        "    y_transform=\"log1p\",\n",
        "    grad_clip=1.0,\n",
        "    loss_beta=1.0,\n",
        "\n",
        "    stratify_clip=60,\n",
        "    stratify_bin_size=1.0,\n",
        "    sanity_width=2000,\n",
        "    h_batch_size=8192,\n",
        "    eval_log_every=10,\n",
        "\n",
        "    seed=123,\n",
        "    rw_length_add=30,\n",
        "\n",
        "    early_stop_patience=6,\n",
        "    early_stop_min_delta=1e-4,\n",
        "    early_stop_warmup=3,\n",
        "    early_stop_restore_best=True,\n",
        ")\n",
        "\n",
        "def make_cfg(**overrides):\n",
        "    cfg = deepcopy(BASE_CFG)\n",
        "    cfg.update(overrides)\n",
        "    return cfg\n",
        "\n",
        "def build_model_grid(\n",
        "    *,\n",
        "    emb_dims=(32,64),\n",
        "    pos_opts=(True, False),\n",
        "    nrds=(0,2,6),\n",
        "    hd1=512, hd2=256,\n",
        "    dropout_rate=0.1,\n",
        "    include_mlpres1=True,\n",
        "):\n",
        "    grid = []\n",
        "\n",
        "    for ed, pos, nrd in product(emb_dims, pos_opts, nrds):\n",
        "        grid.append(make_cfg(\n",
        "            model_type=\"EmbMLP\",\n",
        "            emb_dim=int(ed),\n",
        "            use_pos_emb=bool(pos),\n",
        "            hd1=hd1, hd2=hd2, nrd=int(nrd),\n",
        "            dropout_rate=float(dropout_rate),\n",
        "        ))\n",
        "\n",
        "    if include_mlpres1:\n",
        "        for nrd in nrds:\n",
        "            grid.append(make_cfg(\n",
        "                model_type=\"MLPRes1\",\n",
        "                hd1=hd1, hd2=hd2, nrd=int(nrd),\n",
        "                dropout_rate=float(dropout_rate),\n",
        "            ))\n",
        "    return grid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjeg1R6R8LXI"
      },
      "source": [
        "Реализуем обучение регрессионной модели на данных, сгенерированных из pancake-графа через случайные обходы (random walks). На каждой эпохе заново генерируется датасет состояний X и целевых значений y, применяется трансформация таргета (например, log1p), после чего данные перемешиваются и делятся на train/val.\n",
        "\n",
        "Обучение идёт на GPU с AdamW, SmoothL1Loss, клиппингом градиента и CosineAnnealingLR. Sanity-check оценивает корреляцию между предсказаниями модели и лог-трансформированным таргетом, сгенерированным в BFS-режиме. Это быстрый индикатор того, что модель “видит сигнал” и не выдаёт константу или шум. Использование @torch.no_grad() делает функцию дешёвой и безопасной для запуска между эпохами/экспериментами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:55.97208Z",
          "iopub.status.busy": "2026-02-01T07:41:55.971788Z",
          "iopub.status.idle": "2026-02-01T07:41:56.003599Z",
          "shell.execute_reply": "2026-02-01T07:41:56.002911Z",
          "shell.execute_reply.started": "2026-02-01T07:41:55.972056Z"
        },
        "id": "B3LJMEqWNDn5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def _y_transform_torch(y: torch.Tensor, mode: str) -> torch.Tensor:\n",
        "    y = y.detach().float().view(-1)\n",
        "    if mode is None or mode == \"none\":\n",
        "        return y\n",
        "    if mode == \"log1p\":\n",
        "        return torch.log1p(y)\n",
        "    if mode == \"norm_max\":\n",
        "        return y / y.max().clamp_min(1.0)\n",
        "    raise ValueError(f\"Unknown y_transform={mode}\")\n",
        "\n",
        "def _make_bins_np(y: torch.Tensor, clip: int = 60, bin_size: float = 1.0) -> np.ndarray:\n",
        "    y_np = y.detach().float().cpu().numpy()\n",
        "    b = np.floor(y_np / float(bin_size)).astype(np.int32)\n",
        "    b = np.clip(b, 0, int(clip))\n",
        "    return b\n",
        "\n",
        "def _gen_walks(cfg, graph, mode: str):\n",
        "    nbt_hist = int(cfg.get(\"nbt_history_depth\", cfg.get(\"history_depth\", 1)))\n",
        "    return graph.random_walks(\n",
        "        width=int(cfg[\"rw_width\"]),\n",
        "        length=int(cfg[\"rw_length\"]),\n",
        "        mode=mode,\n",
        "        nbt_history_depth=nbt_hist,\n",
        "    )\n",
        "\n",
        "def train_model_gpu(cfg, model, graph) -> None:\n",
        "    device = graph.device\n",
        "    model.to(device)\n",
        "\n",
        "    bs = int(cfg[\"batch_size\"])\n",
        "    val_ratio = float(cfg[\"val_ratio\"])\n",
        "    epochs = int(cfg[\"num_epochs\"])\n",
        "\n",
        "    y_mode = cfg.get(\"y_transform\", \"log1p\")\n",
        "    grad_clip = float(cfg.get(\"grad_clip\", 1.0))\n",
        "    weight_decay = float(cfg.get(\"weight_decay\", 1e-2))\n",
        "    loss_beta = float(cfg.get(\"loss_beta\", 1.0))\n",
        "\n",
        "    strat_clip = int(cfg.get(\"stratify_clip\", 60))\n",
        "    strat_bin_size = float(cfg.get(\"stratify_bin_size\", 1.0))\n",
        "\n",
        "    rw_mode = cfg.get(\"rw_mode\", \"nbt\")\n",
        "    mix_bfs_frac = float(cfg.get(\"mix_bfs_frac\", 0.3))\n",
        "    es_patience = int(cfg.get(\"early_stop_patience\", 0))\n",
        "    es_min_delta = float(cfg.get(\"early_stop_min_delta\", 0.0))\n",
        "    es_warmup = int(cfg.get(\"early_stop_warmup\", 0))\n",
        "    es_restore = bool(cfg.get(\"early_stop_restore_best\", True))\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "    bad_epochs = 0\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=float(cfg[\"lr\"]), weight_decay=weight_decay)\n",
        "    loss_fn = torch.nn.SmoothL1Loss(beta=loss_beta)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        if rw_mode == \"mix\":\n",
        "            w_total = int(cfg[\"rw_width\"])\n",
        "            w_bfs = max(1, int(round(w_total * mix_bfs_frac)))\n",
        "            w_nbt = max(1, w_total - w_bfs)\n",
        "\n",
        "            cfg_bfs = dict(cfg); cfg_bfs[\"rw_width\"] = w_bfs\n",
        "            cfg_nbt = dict(cfg); cfg_nbt[\"rw_width\"] = w_nbt\n",
        "\n",
        "            X1, y1 = _gen_walks(cfg_bfs, graph, \"bfs\")\n",
        "            X2, y2 = _gen_walks(cfg_nbt, graph, \"nbt\")\n",
        "\n",
        "            X = torch.cat([X1, X2], dim=0)\n",
        "            y = torch.cat([y1, y2], dim=0)\n",
        "        else:\n",
        "            X, y = _gen_walks(cfg, graph, rw_mode)\n",
        "\n",
        "        X = X.long()\n",
        "        y = y.view(-1)\n",
        "        y_t = _y_transform_torch(y, y_mode)\n",
        "\n",
        "        M = X.size(0)\n",
        "        perm_idx = torch.randperm(M, device=device)\n",
        "        X = X[perm_idx]\n",
        "        y_t = y_t[perm_idx]\n",
        "\n",
        "        try:\n",
        "            bins = _make_bins_np(y_t, clip=strat_clip, bin_size=strat_bin_size)\n",
        "            from sklearn.model_selection import train_test_split\n",
        "            idx = np.arange(M)\n",
        "            idx_tr, idx_va = train_test_split(\n",
        "                idx, test_size=val_ratio, stratify=bins, shuffle=True, random_state=123\n",
        "            )\n",
        "        except Exception:\n",
        "            val_M = int(M * val_ratio)\n",
        "            idx_va = np.arange(val_M)\n",
        "            idx_tr = np.arange(val_M, M)\n",
        "\n",
        "        idx_tr_t = torch.as_tensor(idx_tr, device=device, dtype=torch.long)\n",
        "        idx_va_t = torch.as_tensor(idx_va, device=device, dtype=torch.long)\n",
        "        X_tr, y_tr = X[idx_tr_t], y_t[idx_tr_t]\n",
        "        X_va, y_va = X[idx_va_t], y_t[idx_va_t]\n",
        "\n",
        "        total = 0.0\n",
        "        for i in range(0, X_tr.size(0), bs):\n",
        "            xb = X_tr[i:i+bs]\n",
        "            yb = y_tr[i:i+bs].view(-1)\n",
        "            pred = model(xb).view(-1)\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            opt.step()\n",
        "            total += float(loss.item()) * xb.size(0)\n",
        "        train_loss = total / max(1, X_tr.size(0))\n",
        "\n",
        "        model.eval()\n",
        "        total = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, X_va.size(0), bs):\n",
        "                xb = X_va[i:i+bs]\n",
        "                yb = y_va[i:i+bs].view(-1)\n",
        "                pred = model(xb).view(-1)\n",
        "                loss = loss_fn(pred, yb)\n",
        "                total += float(loss.item()) * xb.size(0)\n",
        "        val_loss = total / max(1, X_va.size(0))\n",
        "\n",
        "        sched.step()\n",
        "        lr_now = opt.param_groups[0][\"lr\"]\n",
        "        print(f\"Epoch {epoch:03d}/{epochs} | lr={lr_now:.2e} | train={train_loss:.5f} | val={val_loss:.5f}\", flush=True)\n",
        "\n",
        "        if es_patience and epoch >= es_warmup:\n",
        "            improved = (best_val - val_loss) > es_min_delta\n",
        "            if improved:\n",
        "                best_val = float(val_loss)\n",
        "                bad_epochs = 0\n",
        "                if es_restore:\n",
        "                    best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            else:\n",
        "                bad_epochs += 1\n",
        "                if bad_epochs >= es_patience:\n",
        "                    print(f\"[early_stop] epoch={epoch} best_val={best_val:.5f} \"\n",
        "                          f\"patience={es_patience} min_delta={es_min_delta}\", flush=True)\n",
        "                    break\n",
        "\n",
        "    if es_patience and es_restore and best_state is not None:\n",
        "        model.load_state_dict(best_state, strict=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sanity_corr_bfs(model, graph, rw_length: int, width: int = 2000, nbt_history_depth: int = 1) -> float:\n",
        "    model.eval()\n",
        "    X_s, y_s = graph.random_walks(width=width, length=rw_length, mode=\"bfs\", nbt_history_depth=nbt_history_depth)\n",
        "    pred = model(X_s.long()).float().view(-1).detach().cpu().numpy()\n",
        "    y_raw = y_s.float().view(-1).detach().cpu().numpy()\n",
        "    y_t = np.log1p(y_raw)\n",
        "    return float(np.corrcoef(pred, y_t)[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iUfA2-0-IVo"
      },
      "source": [
        "Идея: использовать обученную модель как эвристику для поиска. Модель выдаёт оценку “насколько состояние далеко от цели”, и эта оценка используется внутри beam search для ранжирования кандидатов.\n",
        "\n",
        "В отличие от чисто ручной эвристики, здесь ML-оценка считается батчами и комбинируется с лёгкой структурной метрикой gap_h для стабилизации.\n",
        "\n",
        "Функция beam_improve_with_ml пытается улучшить baseline-решение через beam search, используя ML-эвристику h_fn как основное ранжирование кандидатов. Длина baseline (best_len) задаёт верхнюю границу: все пути, которые уже не могут стать лучше baseline, отсекаются. Возвращается улучшенный путь, если найден, иначе — baseline, что гарантирует “не хуже baseline” в нормальном режиме работы\n",
        "\n",
        "Дополнительно предусмотрены утилиты для формирования подвыборок тестовых примеров фиксированного размера n и для оценки выигрыша ML-поиска относительно baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:41:58.84351Z",
          "iopub.status.busy": "2026-02-01T07:41:58.843199Z",
          "iopub.status.idle": "2026-02-01T07:41:58.863696Z",
          "shell.execute_reply": "2026-02-01T07:41:58.863029Z",
          "shell.execute_reply.started": "2026-02-01T07:41:58.843481Z"
        },
        "id": "RxLSwyi9RK7O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class MLHeuristic:\n",
        "    \"\"\"Returns float score per state. Smaller = better.\"\"\"\n",
        "    def __init__(self, model, device, batch_size: int = 8192):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.bs = int(batch_size)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, states):\n",
        "        self.model.eval()\n",
        "        out = np.empty(len(states), dtype=np.float32)\n",
        "        i = 0\n",
        "        while i < len(states):\n",
        "            j = min(i + self.bs, len(states))\n",
        "            x = torch.as_tensor(states[i:j], device=self.device, dtype=torch.long)\n",
        "            y = self.model(x).float().view(-1)\n",
        "            out[i:j] = y.detach().cpu().numpy().astype(np.float32)\n",
        "            i = j\n",
        "        return out\n",
        "\n",
        "def beam_improve_with_ml(\n",
        "    perm,\n",
        "    h_fn,\n",
        "    *,\n",
        "    baseline_moves_fn,\n",
        "    beam_width=256,\n",
        "    depth=192,\n",
        "    w=0.5,\n",
        "    w_gap=0.15,\n",
        "    gap_mode=\"log1p\",\n",
        "    patience=None,\n",
        "):\n",
        "    start = list(perm)\n",
        "    base_moves = baseline_moves_fn(start)\n",
        "    best_len = len(base_moves)\n",
        "    if best_len == 0:\n",
        "        return []\n",
        "\n",
        "    n = len(start)\n",
        "    k_values = range(2, n + 1)\n",
        "\n",
        "    beam = [(0.0, 0, start, [])]  # (f, g, state, path)\n",
        "    best_path = None\n",
        "    best_g = {tuple(start): 0}\n",
        "    no_improve_steps = 0\n",
        "\n",
        "    for step in range(depth):\n",
        "        cand_states = []\n",
        "        cand_meta = []\n",
        "\n",
        "        for f, g, state, path in beam:\n",
        "            if g >= best_len:\n",
        "                continue\n",
        "            for k in k_values:\n",
        "                new_g = g + 1\n",
        "                if new_g >= best_len:\n",
        "                    continue\n",
        "\n",
        "                nxt = apply_move_copy(state, k)\n",
        "                key = tuple(nxt)\n",
        "\n",
        "                prev = best_g.get(key)\n",
        "                if prev is not None and prev <= new_g:\n",
        "                    continue\n",
        "                best_g[key] = new_g\n",
        "\n",
        "                new_path = path + [k]\n",
        "\n",
        "                if is_solved(nxt):\n",
        "                    best_len = new_g\n",
        "                    best_path = new_path\n",
        "                    no_improve_steps = 0\n",
        "                    continue\n",
        "\n",
        "                cand_states.append(nxt)\n",
        "                cand_meta.append((new_g, nxt, new_path))\n",
        "\n",
        "        if not cand_states:\n",
        "            break\n",
        "\n",
        "        h_ml = h_fn(cand_states).astype(np.float32, copy=False)\n",
        "\n",
        "        gvals = np.fromiter((gap_h(s) for s in cand_states), dtype=np.float32, count=len(cand_states))\n",
        "        if gap_mode == \"log1p\":\n",
        "            gvals = np.log1p(gvals)\n",
        "        elif gap_mode == \"norm\":\n",
        "            gvals = gvals / max(1.0, float(n))\n",
        "        elif gap_mode == \"none\":\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\"gap_mode must be: none | log1p | norm\")\n",
        "\n",
        "        h = w * h_ml + w_gap * gvals\n",
        "\n",
        "        candidates = [(new_g + float(hh), new_g, nxt, new_path)\n",
        "                      for (new_g, nxt, new_path), hh in zip(cand_meta, h)]\n",
        "        beam = nsmallest(beam_width, candidates, key=lambda x: x[0])\n",
        "\n",
        "        no_improve_steps += 1\n",
        "        if patience is not None and no_improve_steps >= patience:\n",
        "            break\n",
        "\n",
        "    return best_path if best_path is not None else base_moves\n",
        "\n",
        "def build_rows_for_n(test_df, target_n: int, k: int = 50, seed: int = 42):\n",
        "    if \"n\" not in test_df.columns:\n",
        "        tmp = test_df.copy()\n",
        "        tmp[\"n\"] = tmp[\"permutation\"].apply(lambda x: len(parse_permutation(x)))\n",
        "        sub = tmp[tmp[\"n\"] == target_n].reset_index(drop=True)\n",
        "    else:\n",
        "        sub = test_df[test_df[\"n\"] == target_n].reset_index(drop=True)\n",
        "\n",
        "    if len(sub) == 0:\n",
        "        raise ValueError(f\"No rows with n={target_n}\")\n",
        "\n",
        "    rng = np.random.RandomState(seed)\n",
        "    idx = rng.choice(len(sub), size=min(k, len(sub)), replace=False)\n",
        "\n",
        "    rows = []\n",
        "    for i in idx:\n",
        "        rid = int(sub.loc[i, \"id\"])\n",
        "        perm = parse_permutation(sub.loc[i, \"permutation\"])\n",
        "        rows.append((rid, perm))\n",
        "    return rows\n",
        "\n",
        "def eval_ml_on_rows(\n",
        "    rows,\n",
        "    *,\n",
        "    h_ml,\n",
        "    baseline_moves_fn,\n",
        "    beam_width=256,\n",
        "    depth=192,\n",
        "    w=0.5,\n",
        "    w_gap=0.15,\n",
        "    gap_mode=\"log1p\",\n",
        "    patience=None,\n",
        "    log_every=10,\n",
        "):\n",
        "    t0 = time.time()\n",
        "    sum_base = 0\n",
        "    sum_ml = 0\n",
        "    improved = same = worse = 0\n",
        "    total_gain_pos = 0\n",
        "    max_gain = 0\n",
        "    max_gain_id = None\n",
        "    N = len(rows)\n",
        "\n",
        "    for i, (rid, perm) in enumerate(rows, start=1):\n",
        "        base = baseline_moves_fn(perm)\n",
        "        lb = len(base)\n",
        "\n",
        "        ml_moves = beam_improve_with_ml(\n",
        "            perm, h_fn=h_ml,\n",
        "            baseline_moves_fn=baseline_moves_fn,\n",
        "            beam_width=beam_width, depth=depth, w=w,\n",
        "            w_gap=w_gap, gap_mode=gap_mode,\n",
        "            patience=patience,\n",
        "        )\n",
        "        lm = len(ml_moves)\n",
        "\n",
        "        sum_base += lb\n",
        "        sum_ml += lm\n",
        "\n",
        "        gain = lb - lm\n",
        "        if gain > 0:\n",
        "            improved += 1\n",
        "            total_gain_pos += gain\n",
        "            if gain > max_gain:\n",
        "                max_gain = gain\n",
        "                max_gain_id = rid\n",
        "        elif gain == 0:\n",
        "            same += 1\n",
        "        else:\n",
        "            worse += 1\n",
        "\n",
        "        if log_every and (i % log_every == 0 or i == 1 or i == N):\n",
        "            print(f\"  [{i:4d}/{N}] base={lb:3d} ml={lm:3d} gain={gain:3d}  dt={time.time()-t0:7.1f}s\", flush=True)\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    return {\n",
        "        \"baseline_total\": int(sum_base),\n",
        "        \"ml_total\": int(sum_ml),\n",
        "        \"total_gain\": int(sum_base - sum_ml),\n",
        "        \"improved_cases\": int(improved),\n",
        "        \"same_cases\": int(same),\n",
        "        \"worse_cases\": int(worse),\n",
        "        \"avg_gain_when_improved\": float(total_gain_pos / improved) if improved else 0.0,\n",
        "        \"max_gain\": int(max_gain),\n",
        "        \"max_gain_id\": int(max_gain_id) if max_gain_id is not None else None,\n",
        "        \"time_sec_eval\": float(dt),\n",
        "        \"sec_per_sample_eval\": float(dt / max(1, N)),\n",
        "        \"mean_baseline_len\": float(sum_base / max(1, N)),\n",
        "        \"mean_ml_len\": float(sum_ml / max(1, N)),\n",
        "        \"improved_frac\": float(improved / max(1, N)),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwZdmi66FQcR"
      },
      "source": [
        "Реализуем функцию для проведения экспериментов с прогоном по нескольким размерам n и сетке архитектур model_grid. Для каждого n строится pancake-граф, формируется фиксированный набор тест-кейсов, затем обучается модель на сгенерированных random-walk данных и используется как эвристика внутри beam search.\n",
        "\n",
        "\n",
        "Мы оцениваем модель по конечному выигрышу в длине решения при использовании её как эвристики в beam search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:42:05.570933Z",
          "iopub.status.busy": "2026-02-01T07:42:05.570184Z",
          "iopub.status.idle": "2026-02-01T07:42:05.591271Z",
          "shell.execute_reply": "2026-02-01T07:42:05.59054Z",
          "shell.execute_reply.started": "2026-02-01T07:42:05.570901Z"
        },
        "id": "pyIiUUVHNUky",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def build_pancake_graph(target_n: int, device: str):\n",
        "    central_state = list(range(target_n))\n",
        "    graph = CayleyGraph(\n",
        "        PermutationGroups.pancake(target_n).make_inverse_closed().with_central_state(central_state),\n",
        "        device=device,\n",
        "        dtype=torch.int8,\n",
        "        batch_size=2**16,\n",
        "    )\n",
        "    return graph\n",
        "\n",
        "def run_one_experiment_cached(\n",
        "    *,\n",
        "    rows,\n",
        "    graph,\n",
        "    target_n: int,\n",
        "    cfg: dict,\n",
        "    exp_name: str,\n",
        "    out_dir: str,\n",
        "    baseline_moves_fn,\n",
        "    beam_width=256,\n",
        "    depth=192,\n",
        "    w=0.5,\n",
        "    w_gap=0.15,\n",
        "    gap_mode=\"log1p\",\n",
        "    patience=None,\n",
        "):\n",
        "    set_seed(int(cfg.get(\"seed\", 123)))\n",
        "\n",
        "    CFG = dict(cfg)\n",
        "    CFG[\"n\"] = target_n\n",
        "    CFG[\"num_classes\"] = target_n\n",
        "    CFG[\"state_size\"] = target_n\n",
        "\n",
        "    k = int(CFG.get(\"k\", 4))\n",
        "    rw_length_add = int(CFG.get(\"rw_length_add\", 30))\n",
        "    CFG[\"rw_length\"] = target_n * (target_n + 5) // (4 * (k - 1)) + rw_length_add\n",
        "\n",
        "    model = get_model(CFG).to(graph.device)\n",
        "\n",
        "    print(f\"\\n[{now_str()}] EXP={exp_name} | model={CFG.get('model_type')} n={target_n} \"\n",
        "          f\"| epochs={CFG['num_epochs']} rw_width={CFG['rw_width']} rw_mode={CFG.get('rw_mode')}\", flush=True)\n",
        "\n",
        "    t_train0 = time.time()\n",
        "    train_model_gpu(CFG, model, graph)\n",
        "    train_time = time.time() - t_train0\n",
        "\n",
        "    try:\n",
        "        corr = sanity_corr_bfs(\n",
        "            model, graph,\n",
        "            rw_length=CFG[\"rw_length\"],\n",
        "            width=int(CFG.get(\"sanity_width\", 2000)),\n",
        "            nbt_history_depth=int(CFG.get(\"nbt_history_depth\", 1)),\n",
        "        )\n",
        "    except Exception as e:\n",
        "        corr = float(\"nan\")\n",
        "        print(\"[sanity] failed:\", repr(e), flush=True)\n",
        "\n",
        "    h_ml = MLHeuristic(model, device=graph.device, batch_size=int(CFG.get(\"h_batch_size\", 8192)))\n",
        "\n",
        "    eval_stats = eval_ml_on_rows(\n",
        "        rows,\n",
        "        h_ml=h_ml,\n",
        "        baseline_moves_fn=baseline_moves_fn,\n",
        "        beam_width=beam_width, depth=depth, w=w,\n",
        "        w_gap=w_gap, gap_mode=gap_mode,\n",
        "        patience=patience,\n",
        "        log_every=int(CFG.get(\"eval_log_every\", 10)),\n",
        "    )\n",
        "\n",
        "    res = {\n",
        "        \"exp_name\": exp_name,\n",
        "        \"timestamp\": now_str(),\n",
        "        \"target_n\": int(target_n),\n",
        "        \"rows_k\": int(len(rows)),\n",
        "\n",
        "        \"model_type\": str(CFG.get(\"model_type\")),\n",
        "        \"emb_dim\": int(CFG[\"emb_dim\"]) if CFG.get(\"model_type\") == \"EmbMLP\" else None,\n",
        "        \"use_pos_emb\": bool(CFG.get(\"use_pos_emb\", True)) if CFG.get(\"model_type\") == \"EmbMLP\" else None,\n",
        "        \"hd1\": int(CFG.get(\"hd1\", 0)),\n",
        "        \"hd2\": int(CFG.get(\"hd2\", 0)),\n",
        "        \"nrd\": int(CFG.get(\"nrd\", 0)),\n",
        "        \"dropout_rate\": float(CFG.get(\"dropout_rate\", 0.0)),\n",
        "\n",
        "        \"rw_width\": int(CFG.get(\"rw_width\", 0)),\n",
        "        \"rw_length\": int(CFG.get(\"rw_length\", 0)),\n",
        "        \"rw_mode\": str(CFG.get(\"rw_mode\", \"\")),\n",
        "        \"mix_bfs_frac\": float(CFG.get(\"mix_bfs_frac\", 0.0)),\n",
        "        \"nbt_history_depth\": int(CFG.get(\"nbt_history_depth\", 1)),\n",
        "        \"lr\": float(CFG.get(\"lr\", 0.0)),\n",
        "        \"weight_decay\": float(CFG.get(\"weight_decay\", 0.0)),\n",
        "        \"batch_size\": int(CFG.get(\"batch_size\", 0)),\n",
        "        \"val_ratio\": float(CFG.get(\"val_ratio\", 0.0)),\n",
        "        \"num_epochs\": int(CFG.get(\"num_epochs\", 0)),\n",
        "        \"y_transform\": str(CFG.get(\"y_transform\", \"\")),\n",
        "        \"loss_beta\": float(CFG.get(\"loss_beta\", 1.0)),\n",
        "        \"grad_clip\": float(CFG.get(\"grad_clip\", 0.0)),\n",
        "\n",
        "        \"beam_width\": int(beam_width),\n",
        "        \"depth\": int(depth),\n",
        "        \"w\": float(w),\n",
        "        \"w_gap\": float(w_gap),\n",
        "        \"gap_mode\": str(gap_mode),\n",
        "        \"patience\": patience if patience is None else int(patience),\n",
        "\n",
        "        \"train_time_sec\": float(train_time),\n",
        "        \"sanity_corr\": float(corr),\n",
        "        **eval_stats,\n",
        "    }\n",
        "\n",
        "    ensure_dir(out_dir)\n",
        "    with open(os.path.join(out_dir, f\"{exp_name}.json\"), \"w\") as f:\n",
        "        json.dump(res, f, indent=2)\n",
        "\n",
        "    del model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return res\n",
        "\n",
        "def run_sweep_n_list(\n",
        "    *,\n",
        "    test_df: pd.DataFrame,\n",
        "    n_list: list[int],\n",
        "    rows_k: int = 50,\n",
        "    rows_seed: int = 42,\n",
        "    model_grid: list[dict],\n",
        "    w_gap: float = 0.15,\n",
        "    gap_mode: str = \"log1p\",\n",
        "    results_csv: str = \"ml_sweep/results_nlist.csv\",\n",
        "    out_json_dir: str = \"ml_sweep/json\",\n",
        "    device: str | None = None,\n",
        "    beam_width: int = 256,\n",
        "    depth: int = 192,\n",
        "    w: float = 0.5,\n",
        "):\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    ensure_dir(out_json_dir)\n",
        "    ensure_dir(os.path.dirname(results_csv))\n",
        "\n",
        "    done = set()\n",
        "    if os.path.exists(results_csv):\n",
        "        prev = pd.read_csv(results_csv, usecols=[\"exp_name\"])\n",
        "        done = set(prev[\"exp_name\"].astype(str))\n",
        "        print(f\"[resume] {len(done)} experiments already done\", flush=True)\n",
        "\n",
        "    rows_cache = {n: build_rows_for_n(test_df, n, k=rows_k, seed=rows_seed) for n in n_list}\n",
        "    graph_cache = {n: build_pancake_graph(n, device=device) for n in n_list}\n",
        "\n",
        "    total = len(n_list) * len(model_grid)\n",
        "    run_i = 0\n",
        "\n",
        "    try:\n",
        "        for n in n_list:\n",
        "            print(f\"\\n########## TARGET_N = {n} ##########\", flush=True)\n",
        "            graph = graph_cache[n]\n",
        "            rows = rows_cache[n]\n",
        "\n",
        "            best_gain = -10**9\n",
        "            best_name = None\n",
        "\n",
        "            for cfg in model_grid:\n",
        "                run_i += 1\n",
        "                exp_name = exp_name_from(cfg, n=n, w_gap=w_gap, gap_mode=gap_mode)\n",
        "\n",
        "                if exp_name in done:\n",
        "                    print(f\"[skip] {run_i}/{total} {exp_name}\", flush=True)\n",
        "                    continue\n",
        "\n",
        "                print(f\"\\n===== [{run_i}/{total}] {exp_name} =====\", flush=True)\n",
        "\n",
        "                res = run_one_experiment_cached(\n",
        "                    rows=rows,\n",
        "                    graph=graph,\n",
        "                    target_n=n,\n",
        "                    cfg=cfg,\n",
        "                    exp_name=exp_name,\n",
        "                    out_dir=out_json_dir,\n",
        "                    baseline_moves_fn=pancake_sort_moves,\n",
        "                    beam_width=beam_width,\n",
        "                    depth=depth,\n",
        "                    w=w,\n",
        "                    w_gap=w_gap,\n",
        "                    gap_mode=gap_mode,\n",
        "                    patience=None,\n",
        "                )\n",
        "\n",
        "                df1 = pd.DataFrame([res])\n",
        "                header = not os.path.exists(results_csv)\n",
        "                df1.to_csv(results_csv, mode=\"a\", header=header, index=False)\n",
        "\n",
        "                done.add(exp_name)\n",
        "\n",
        "                if res[\"total_gain\"] > best_gain:\n",
        "                    best_gain = res[\"total_gain\"]\n",
        "                    best_name = exp_name\n",
        "\n",
        "                print(f\"[best@n={n}] total_gain={best_gain} ({best_name})\", flush=True)\n",
        "\n",
        "    finally:\n",
        "        for g in graph_cache.values():\n",
        "            try:\n",
        "                g.free_memory()\n",
        "            except Exception:\n",
        "                pass\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return pd.read_csv(results_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxY2RGmlKXhY"
      },
      "source": [
        "Зададим список n, на которых будет проводиться ML-оценка. Эти значения представляют малый, средний и более сложный режимы, позволяя увидеть, как масштабирование влияет на качество эвристики.\n",
        "\n",
        "Для каждого n сравниваются разные архитектуры (embedding-модели и one-hot MLP) по их способности улучшать baseline-решение в beam search. Варьируем размер эмбеддингов, наличие позициционных эмбеддингов и количество residual блоков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "id": "-HXXlIDFNXOX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "n_list = [20, 30, 50]\n",
        "\n",
        "model_grid = build_model_grid(\n",
        "    emb_dims=(32, 64),\n",
        "    pos_opts=(True, False),\n",
        "    nrds=(0, 2, 6),\n",
        "    include_mlpres1=True,\n",
        ")\n",
        "\n",
        "df = run_sweep_n_list(\n",
        "    test_df=test_df,\n",
        "    n_list=n_list,\n",
        "    rows_k=20,\n",
        "    rows_seed=42,\n",
        "    model_grid=model_grid,\n",
        "    w_gap=0.15,\n",
        "    gap_mode=\"log1p\",\n",
        "    results_csv=\"ml_sweep/result_n20_30_50.csv\",\n",
        "    out_json_dir=\"ml_sweep/json\",\n",
        "    beam_width=256,\n",
        "    depth=192,\n",
        "    w=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P72y6RNiNv-M"
      },
      "source": [
        "Представление перестановки через embedding элементов (и опционально позиций) существенно лучше one-hot кодирования для этой задачи.\n",
        "\n",
        "Positional embedding не обязателен на малых n. Увеличение nrd с 2 до 6 не даёт выигрыша, но увеличивает время обучения. emb_dim=64 слегка лучше 32, но разница минимальна.\n",
        "\n",
        "при росте n модель начинает выигрывать от информации о позиции элемента, а не только от его значения.\n",
        "\n",
        "На больших n требуется большая глубина модели (nrd=6), emb_dim=32 оказывается лучше 64 (интересный эффект регуляризации). Positional embedding уже не критичен, а иногда даже ухудшает результат. Цена выигрыша - очень серьёзное время поиска."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "execution": {
          "iopub.execute_input": "2026-01-31T16:57:52.978099Z",
          "iopub.status.busy": "2026-01-31T16:57:52.977539Z",
          "iopub.status.idle": "2026-01-31T16:57:52.999306Z",
          "shell.execute_reply": "2026-01-31T16:57:52.998654Z",
          "shell.execute_reply.started": "2026-01-31T16:57:52.978072Z"
        },
        "id": "u0mXysENNbgV",
        "outputId": "cfff5601-b604-4015-d4fc-fcb8045f200d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(best_per_n[[\\\"target_n\\\",\\\"exp_name\\\",\\\"model_type\\\",\\\"emb_dim\\\",\\\"use_pos_emb\\\",\\\"nrd\\\",\\\"total_gain\\\",\\\"mean_ml_len\\\",\\\"sanity_corr\\\",\\\"train_time_sec\\\",\\\"time_sec_eval\\\"]])\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"target_n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 20,\n        \"max\": 50,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          20,\n          30,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"n30_EmbMLP_ed32_pos0_nrd2_wg0.15_log1p\",\n          \"n50_EmbMLP_ed32_pos1_nrd6_wg0.15_log1p\",\n          \"n20_EmbMLP_ed64_pos0_nrd6_wg0.15_log1p\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"EmbMLP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emb_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.22696169078752,\n        \"min\": 32.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"use_pos_emb\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nrd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73,\n        \"min\": 227,\n        \"max\": 418,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_ml_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.927475154852342,\n        \"min\": 18.7,\n        \"max\": 70.7,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          69.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sanity_corr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015106138664329001,\n        \"min\": 0.9227236086767816,\n        \"max\": 0.9609331978919192,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9490922442051728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.2933158738192,\n        \"min\": 34.66778111457825,\n        \"max\": 244.2353782653809,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          61.26426792144776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_sec_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144.40769585714915,\n        \"min\": 17.33446717262268,\n        \"max\": 344.516238451004,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          57.14235258102417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-af0af8aa-9946-4f52-995d-d07057be3201\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_n</th>\n",
              "      <th>exp_name</th>\n",
              "      <th>model_type</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>use_pos_emb</th>\n",
              "      <th>nrd</th>\n",
              "      <th>total_gain</th>\n",
              "      <th>mean_ml_len</th>\n",
              "      <th>sanity_corr</th>\n",
              "      <th>train_time_sec</th>\n",
              "      <th>time_sec_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20</td>\n",
              "      <td>n20_EmbMLP_ed64_pos0_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>229</td>\n",
              "      <td>18.70</td>\n",
              "      <td>0.924308</td>\n",
              "      <td>53.385489</td>\n",
              "      <td>18.869771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20</td>\n",
              "      <td>n20_EmbMLP_ed64_pos0_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>229</td>\n",
              "      <td>18.70</td>\n",
              "      <td>0.923873</td>\n",
              "      <td>34.667781</td>\n",
              "      <td>17.854649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20</td>\n",
              "      <td>n20_EmbMLP_ed64_pos1_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>228</td>\n",
              "      <td>18.75</td>\n",
              "      <td>0.927537</td>\n",
              "      <td>35.715142</td>\n",
              "      <td>18.047640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>n20_EmbMLP_ed32_pos0_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>228</td>\n",
              "      <td>18.75</td>\n",
              "      <td>0.922724</td>\n",
              "      <td>34.754986</td>\n",
              "      <td>17.334467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20</td>\n",
              "      <td>n20_EmbMLP_ed64_pos1_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>227</td>\n",
              "      <td>18.80</td>\n",
              "      <td>0.924568</td>\n",
              "      <td>54.465402</td>\n",
              "      <td>18.901072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>30</td>\n",
              "      <td>n30_EmbMLP_ed64_pos1_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>386</td>\n",
              "      <td>29.90</td>\n",
              "      <td>0.953272</td>\n",
              "      <td>64.946194</td>\n",
              "      <td>56.314097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>30</td>\n",
              "      <td>n30_EmbMLP_ed64_pos0_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>374</td>\n",
              "      <td>30.50</td>\n",
              "      <td>0.950571</td>\n",
              "      <td>63.166497</td>\n",
              "      <td>58.021820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>30</td>\n",
              "      <td>n30_EmbMLP_ed64_pos1_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>369</td>\n",
              "      <td>30.75</td>\n",
              "      <td>0.948167</td>\n",
              "      <td>95.269771</td>\n",
              "      <td>61.951936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>30</td>\n",
              "      <td>n30_EmbMLP_ed32_pos1_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>368</td>\n",
              "      <td>30.80</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>63.761750</td>\n",
              "      <td>57.413650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>30</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>367</td>\n",
              "      <td>30.85</td>\n",
              "      <td>0.949092</td>\n",
              "      <td>61.264268</td>\n",
              "      <td>57.142353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>50</td>\n",
              "      <td>n50_EmbMLP_ed32_pos0_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>418</td>\n",
              "      <td>66.05</td>\n",
              "      <td>0.956801</td>\n",
              "      <td>234.323520</td>\n",
              "      <td>316.788768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>50</td>\n",
              "      <td>n50_EmbMLP_ed32_pos1_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>409</td>\n",
              "      <td>66.50</td>\n",
              "      <td>0.958630</td>\n",
              "      <td>235.827484</td>\n",
              "      <td>321.089032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>50</td>\n",
              "      <td>n50_EmbMLP_ed64_pos1_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>355</td>\n",
              "      <td>69.20</td>\n",
              "      <td>0.960933</td>\n",
              "      <td>244.235378</td>\n",
              "      <td>344.516238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>50</td>\n",
              "      <td>n50_EmbMLP_ed64_pos0_nrd6_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>353</td>\n",
              "      <td>69.30</td>\n",
              "      <td>0.958660</td>\n",
              "      <td>241.075927</td>\n",
              "      <td>343.075050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>50</td>\n",
              "      <td>n50_EmbMLP_ed32_pos1_nrd2_wg0.15_log1p</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>325</td>\n",
              "      <td>70.70</td>\n",
              "      <td>0.959160</td>\n",
              "      <td>167.817786</td>\n",
              "      <td>333.373814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af0af8aa-9946-4f52-995d-d07057be3201')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af0af8aa-9946-4f52-995d-d07057be3201 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af0af8aa-9946-4f52-995d-d07057be3201');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    target_n                                exp_name model_type  emb_dim  \\\n",
              "11        20  n20_EmbMLP_ed64_pos0_nrd6_wg0.15_log1p     EmbMLP     64.0   \n",
              "10        20  n20_EmbMLP_ed64_pos0_nrd2_wg0.15_log1p     EmbMLP     64.0   \n",
              "7         20  n20_EmbMLP_ed64_pos1_nrd2_wg0.15_log1p     EmbMLP     64.0   \n",
              "4         20  n20_EmbMLP_ed32_pos0_nrd2_wg0.15_log1p     EmbMLP     32.0   \n",
              "8         20  n20_EmbMLP_ed64_pos1_nrd6_wg0.15_log1p     EmbMLP     64.0   \n",
              "22        30  n30_EmbMLP_ed64_pos1_nrd2_wg0.15_log1p     EmbMLP     64.0   \n",
              "25        30  n30_EmbMLP_ed64_pos0_nrd2_wg0.15_log1p     EmbMLP     64.0   \n",
              "23        30  n30_EmbMLP_ed64_pos1_nrd6_wg0.15_log1p     EmbMLP     64.0   \n",
              "16        30  n30_EmbMLP_ed32_pos1_nrd2_wg0.15_log1p     EmbMLP     32.0   \n",
              "19        30  n30_EmbMLP_ed32_pos0_nrd2_wg0.15_log1p     EmbMLP     32.0   \n",
              "35        50  n50_EmbMLP_ed32_pos0_nrd6_wg0.15_log1p     EmbMLP     32.0   \n",
              "32        50  n50_EmbMLP_ed32_pos1_nrd6_wg0.15_log1p     EmbMLP     32.0   \n",
              "38        50  n50_EmbMLP_ed64_pos1_nrd6_wg0.15_log1p     EmbMLP     64.0   \n",
              "41        50  n50_EmbMLP_ed64_pos0_nrd6_wg0.15_log1p     EmbMLP     64.0   \n",
              "31        50  n50_EmbMLP_ed32_pos1_nrd2_wg0.15_log1p     EmbMLP     32.0   \n",
              "\n",
              "   use_pos_emb  nrd  total_gain  mean_ml_len  sanity_corr  train_time_sec  \\\n",
              "11       False    6         229        18.70     0.924308       53.385489   \n",
              "10       False    2         229        18.70     0.923873       34.667781   \n",
              "7         True    2         228        18.75     0.927537       35.715142   \n",
              "4        False    2         228        18.75     0.922724       34.754986   \n",
              "8         True    6         227        18.80     0.924568       54.465402   \n",
              "22        True    2         386        29.90     0.953272       64.946194   \n",
              "25       False    2         374        30.50     0.950571       63.166497   \n",
              "23        True    6         369        30.75     0.948167       95.269771   \n",
              "16        True    2         368        30.80     0.948684       63.761750   \n",
              "19       False    2         367        30.85     0.949092       61.264268   \n",
              "35       False    6         418        66.05     0.956801      234.323520   \n",
              "32        True    6         409        66.50     0.958630      235.827484   \n",
              "38        True    6         355        69.20     0.960933      244.235378   \n",
              "41       False    6         353        69.30     0.958660      241.075927   \n",
              "31        True    2         325        70.70     0.959160      167.817786   \n",
              "\n",
              "    time_sec_eval  \n",
              "11      18.869771  \n",
              "10      17.854649  \n",
              "7       18.047640  \n",
              "4       17.334467  \n",
              "8       18.901072  \n",
              "22      56.314097  \n",
              "25      58.021820  \n",
              "23      61.951936  \n",
              "16      57.413650  \n",
              "19      57.142353  \n",
              "35     316.788768  \n",
              "32     321.089032  \n",
              "38     344.516238  \n",
              "41     343.075050  \n",
              "31     333.373814  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/pancake_runs/result_n20_30_50.csv\")\n",
        "\n",
        "best_per_n = (\n",
        "    df.sort_values([\"target_n\", \"total_gain\", \"sanity_corr\"], ascending=[True, False, False])\n",
        "      .groupby(\"target_n\", as_index=False)\n",
        "      .head(5)\n",
        ")\n",
        "display(best_per_n[[\"target_n\",\"exp_name\",\"model_type\",\"emb_dim\",\"use_pos_emb\",\"nrd\",\"total_gain\",\"mean_ml_len\",\"sanity_corr\",\"train_time_sec\",\"time_sec_eval\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBMXDQPP1Xf"
      },
      "source": [
        "One-hot MLP существенно уступает embedding-подходу для задачи pancake-графа, даже при увеличении глубины.\n",
        "Однако глубина (residual stack)также критична для качества ML-эвристики.\n",
        "\n",
        "emb_dim=32 стабильно лучше, чем 64.\n",
        "Более компактное представление элемента оказывается эффективнее для эвристического поиска.\n",
        "\n",
        "positional embedding не является определяющим фактором"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "execution": {
          "iopub.execute_input": "2026-01-31T16:58:00.138492Z",
          "iopub.status.busy": "2026-01-31T16:58:00.138161Z",
          "iopub.status.idle": "2026-01-31T16:58:00.159601Z",
          "shell.execute_reply": "2026-01-31T16:58:00.158792Z",
          "shell.execute_reply.started": "2026-01-31T16:58:00.138456Z"
        },
        "id": "b4LyykkbJtw5",
        "outputId": "a0042f8a-ce19-4bf2-aa5d-3f5ab4ca0fa9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(agg\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"model_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"MLPRes1\",\n          \"EmbMLP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emb_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.711454971746992,\n        \"min\": 32.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          64.0,\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"use_pos_emb\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nrd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_gain_sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 225,\n        \"min\": 348,\n        \"max\": 997,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          596,\n          516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_ml_len_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7603638093721687,\n        \"min\": 38.81666666666666,\n        \"max\": 49.63333333333333,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          45.5,\n          46.833333333333336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sanity_corr_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0087391725616498,\n        \"min\": 0.919035641712207,\n        \"max\": 0.9459669815868968,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9261828343601649,\n          0.9315206726561973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bb07da7c-eb1d-4d97-bf0c-e7830f7dc265\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_type</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>use_pos_emb</th>\n",
              "      <th>nrd</th>\n",
              "      <th>total_gain_sum</th>\n",
              "      <th>mean_ml_len_mean</th>\n",
              "      <th>sanity_corr_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>997</td>\n",
              "      <td>38.816667</td>\n",
              "      <td>0.939317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>978</td>\n",
              "      <td>39.133333</td>\n",
              "      <td>0.938082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>951</td>\n",
              "      <td>39.583333</td>\n",
              "      <td>0.944556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>948</td>\n",
              "      <td>39.633333</td>\n",
              "      <td>0.944285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>918</td>\n",
              "      <td>40.133333</td>\n",
              "      <td>0.941958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>900</td>\n",
              "      <td>40.433333</td>\n",
              "      <td>0.942980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>886</td>\n",
              "      <td>40.666667</td>\n",
              "      <td>0.943780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>861</td>\n",
              "      <td>41.083333</td>\n",
              "      <td>0.945967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>MLPRes1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>686</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.920993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>MLPRes1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>596</td>\n",
              "      <td>45.500000</td>\n",
              "      <td>0.926183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>559</td>\n",
              "      <td>46.116667</td>\n",
              "      <td>0.938493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>46.833333</td>\n",
              "      <td>0.931521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>494</td>\n",
              "      <td>47.200000</td>\n",
              "      <td>0.931021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>64.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>443</td>\n",
              "      <td>48.050000</td>\n",
              "      <td>0.933238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>MLPRes1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>348</td>\n",
              "      <td>49.633333</td>\n",
              "      <td>0.919036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb07da7c-eb1d-4d97-bf0c-e7830f7dc265')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb07da7c-eb1d-4d97-bf0c-e7830f7dc265 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb07da7c-eb1d-4d97-bf0c-e7830f7dc265');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   model_type  emb_dim use_pos_emb  nrd  total_gain_sum  mean_ml_len_mean  \\\n",
              "2      EmbMLP     32.0       False    6             997         38.816667   \n",
              "5      EmbMLP     32.0        True    6             978         39.133333   \n",
              "11     EmbMLP     64.0        True    6             951         39.583333   \n",
              "8      EmbMLP     64.0       False    6             948         39.633333   \n",
              "4      EmbMLP     32.0        True    2             918         40.133333   \n",
              "1      EmbMLP     32.0       False    2             900         40.433333   \n",
              "7      EmbMLP     64.0       False    2             886         40.666667   \n",
              "10     EmbMLP     64.0        True    2             861         41.083333   \n",
              "14    MLPRes1      NaN         NaN    6             686         44.000000   \n",
              "13    MLPRes1      NaN         NaN    2             596         45.500000   \n",
              "9      EmbMLP     64.0        True    0             559         46.116667   \n",
              "0      EmbMLP     32.0       False    0             516         46.833333   \n",
              "3      EmbMLP     32.0        True    0             494         47.200000   \n",
              "6      EmbMLP     64.0       False    0             443         48.050000   \n",
              "12    MLPRes1      NaN         NaN    0             348         49.633333   \n",
              "\n",
              "    sanity_corr_mean  \n",
              "2           0.939317  \n",
              "5           0.938082  \n",
              "11          0.944556  \n",
              "8           0.944285  \n",
              "4           0.941958  \n",
              "1           0.942980  \n",
              "7           0.943780  \n",
              "10          0.945967  \n",
              "14          0.920993  \n",
              "13          0.926183  \n",
              "9           0.938493  \n",
              "0           0.931521  \n",
              "3           0.931021  \n",
              "6           0.933238  \n",
              "12          0.919036  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "agg = (\n",
        "    df.groupby([\"model_type\",\"emb_dim\",\"use_pos_emb\",\"nrd\"], dropna=False, as_index=False)\n",
        "      .agg(total_gain_sum=(\"total_gain\",\"sum\"),\n",
        "           mean_ml_len_mean=(\"mean_ml_len\",\"mean\"),\n",
        "           sanity_corr_mean=(\"sanity_corr\",\"mean\"))\n",
        "      .sort_values([\"total_gain_sum\",\"sanity_corr_mean\"], ascending=[False, False])\n",
        ")\n",
        "display(agg.head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8etd1iqUz-c"
      },
      "source": [
        "Лучшей архитектурой в среднем по всем протестированным размерам задач является:\n",
        "\n",
        "**EmbMLP с emb_dim = 32 и nrd = 6**\n",
        "\n",
        "При этом использование positional embedding остаётся опциональным.\n",
        "\n",
        "Эта модель демонстрирует оптимальный баланс между выразительностью, обобщающей способностью и практической эффективностью в задаче эвристического поиска в pancake-графе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wWdeD12VRPJ"
      },
      "source": [
        "Приведенная ниже функция формирует строковый идентификатор эксперимента на основе конфигурации модели, размера задачи n и параметров эвристического поиска. Для embedding-моделей в имя включаются размер эмбеддинга, наличие positional embedding и глубина residual-стека, а для остальных моделей — только тип и глубина.\n",
        "\n",
        "Дополнительно кодируются параметры генерации данных (rw_width, mix_bfs_frac), обучения (learning rate, weight decay, число эпох) и параметры эвристики (w_gap, gap_mode), что гарантирует уникальность и воспроизводимость экспериментов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T18:09:13.810283Z",
          "iopub.status.busy": "2026-01-31T18:09:13.80961Z",
          "iopub.status.idle": "2026-01-31T18:09:13.815885Z",
          "shell.execute_reply": "2026-01-31T18:09:13.815195Z",
          "shell.execute_reply.started": "2026-01-31T18:09:13.810256Z"
        },
        "id": "WjvygbKzUVyy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def exp_name_from(cfg: dict, *, n: int, w_gap: float, gap_mode: str) -> str:\n",
        "\n",
        "    mt = cfg.get(\"model_type\", \"EmbMLP\")\n",
        "\n",
        "    if mt == \"EmbMLP\":\n",
        "        ed  = cfg.get(\"emb_dim\", 0)\n",
        "        pos = int(bool(cfg.get(\"use_pos_emb\", True)))\n",
        "        nrd = int(cfg.get(\"nrd\", 0))\n",
        "        tag = f\"{mt}_ed{ed}_pos{pos}_nrd{nrd}\"\n",
        "    else:\n",
        "        nrd = int(cfg.get(\"nrd\", 0))\n",
        "        tag = f\"{mt}_nrd{nrd}\"\n",
        "\n",
        "    rw = int(cfg.get(\"rw_width\", 0))\n",
        "    mf = cfg.get(\"mix_bfs_frac\", None)\n",
        "    mf_tag = f\"_mix{float(mf):.2f}\" if mf is not None else \"\"\n",
        "    lr = cfg.get(\"lr\", None)\n",
        "    wd = cfg.get(\"weight_decay\", None)\n",
        "    ep = int(cfg.get(\"num_epochs\", 0))\n",
        "\n",
        "    return f\"n{n}_{tag}_rw{rw}{mf_tag}_lr{lr}_wd{wd}_ep{ep}_wg{w_gap}_{gap_mode}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYoDSYAAgEvF"
      },
      "source": [
        "Для более тонкой настройки мы фиксируем лучшую по прошлым экспериментам архитектуру (EmbMLP с emb_dim=32 и nrd=6) и перебираем только параметры обучения и генерации данных, чтобы улучшить качество ML-эвристики. Перебор запускается на одном выбранном размере n (здесь n=30) как компромиссе между информативностью и вычислительной стоимостью.\n",
        "\n",
        "В этом режиме различия между конфигурациями обучения наиболее отчётливо проявляются в итоговом выигрыше поиска, при этом вычислительная стоимость остаётся приемлемой.\n",
        "\n",
        "Рассматриваются следующие параметры:\n",
        "rw_width (регулирует объём сгенерированных данных на эпоху), mix_frac_grid (доля BFS-примеров в смешанном датасете), а lr и weight_decay (поведение оптимизатора и регуляризацию)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "zp0wRdjpJtw7",
        "outputId": "bc45f076-e7d0-4e6d-9baf-2ff92d6fe0ac",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training configs: 36\n",
            "[resume] 3 experiments already done\n",
            "\n",
            "########## TARGET_N = 30 ##########\n",
            "\n",
            "===== [1/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 16:52:31] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.40582 | val=0.16431\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.17577 | val=0.14244\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.13400 | val=0.10224\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.10600 | val=0.07638\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.08999 | val=0.06478\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.07892 | val=0.05690\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.06621 | val=0.05368\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.06195 | val=0.04514\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.06069 | val=0.04640\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.05650 | val=0.04236\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.05341 | val=0.04456\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04973 | val=0.03849\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04951 | val=0.03759\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04821 | val=0.03649\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04801 | val=0.03787\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.04396 | val=0.03422\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04479 | val=0.03484\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.04496 | val=0.03746\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.04297 | val=0.03387\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.04306 | val=0.03412\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.04420 | val=0.03581\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.04545 | val=0.03629\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.04367 | val=0.03557\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.04316 | val=0.03612\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.04236 | val=0.03367\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03963 | val=0.03252\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.04122 | val=0.03349\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.04146 | val=0.03466\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03880 | val=0.03215\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.04039 | val=0.03469\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03950 | val=0.03307\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03955 | val=0.03352\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.04052 | val=0.03446\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03827 | val=0.03260\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03893 | val=0.03423\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.04055 | val=0.03607\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.04049 | val=0.03564\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03905 | val=0.03490\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.04225 | val=0.03826\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.04111 | val=0.03764\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 34 gain= 14  dt=   34.9s\n",
            "  [  20/20] base= 46 ml= 33 gain= 13  dt=   73.0s\n",
            "[best@n=30] total_gain=332 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [2/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 16:55:22] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.40614 | val=0.17239\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.17710 | val=0.15230\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.13662 | val=0.10235\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.10773 | val=0.08082\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.09057 | val=0.06695\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.07948 | val=0.05678\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.06687 | val=0.05365\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.06244 | val=0.04733\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.06099 | val=0.04736\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.05693 | val=0.04291\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.05350 | val=0.04437\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04999 | val=0.03970\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.05006 | val=0.03797\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04854 | val=0.03671\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04837 | val=0.03823\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.04420 | val=0.03496\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04505 | val=0.03506\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.04526 | val=0.03816\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.04280 | val=0.03399\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.04308 | val=0.03344\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.04423 | val=0.03537\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.04547 | val=0.03634\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.04370 | val=0.03529\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.04333 | val=0.03606\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.04250 | val=0.03367\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03996 | val=0.03276\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.04118 | val=0.03345\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.04155 | val=0.03497\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03908 | val=0.03285\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.04052 | val=0.03440\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03956 | val=0.03310\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.04020 | val=0.03445\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.04063 | val=0.03492\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03848 | val=0.03301\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03969 | val=0.03511\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.04094 | val=0.03653\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.04095 | val=0.03623\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03947 | val=0.03551\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.04309 | val=0.03889\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.04168 | val=0.03841\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 36 gain= 12  dt=   36.0s\n",
            "  [  20/20] base= 46 ml= 31 gain= 15  dt=   72.2s\n",
            "[best@n=30] total_gain=339 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [3/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 16:58:11] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.30348 | val=0.14284\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.13564 | val=0.08178\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.08717 | val=0.05631\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.07232 | val=0.04838\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.06270 | val=0.04740\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.05789 | val=0.04353\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.05030 | val=0.04308\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04752 | val=0.03638\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04878 | val=0.04032\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.04557 | val=0.03944\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.04434 | val=0.03610\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.04144 | val=0.03280\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.04145 | val=0.03428\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.04037 | val=0.03095\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03927 | val=0.03051\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03663 | val=0.02993\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03747 | val=0.02920\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03774 | val=0.03057\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03585 | val=0.02727\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03604 | val=0.02746\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03705 | val=0.02888\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03859 | val=0.03065\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03751 | val=0.02897\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03669 | val=0.02889\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03601 | val=0.02844\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03408 | val=0.02754\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03447 | val=0.02739\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03550 | val=0.03034\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03322 | val=0.02795\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03414 | val=0.02885\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03407 | val=0.02865\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03463 | val=0.03026\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03521 | val=0.03020\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03300 | val=0.02861\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03412 | val=0.03066\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03579 | val=0.03237\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03574 | val=0.03174\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03394 | val=0.03081\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03740 | val=0.03454\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03640 | val=0.03448\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   33.2s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   67.8s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [4/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:00:56] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.30389 | val=0.14238\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.13547 | val=0.08382\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.08950 | val=0.06302\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.07458 | val=0.05120\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.06417 | val=0.04714\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.05831 | val=0.04163\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.05075 | val=0.04280\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04798 | val=0.03802\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04908 | val=0.03841\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.04574 | val=0.03520\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.04475 | val=0.03562\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.04136 | val=0.03209\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.04098 | val=0.03442\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.04041 | val=0.03106\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03916 | val=0.03033\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03680 | val=0.02993\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03767 | val=0.02937\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03787 | val=0.03075\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03657 | val=0.02768\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03613 | val=0.02756\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03730 | val=0.02863\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03860 | val=0.03035\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03777 | val=0.02922\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03682 | val=0.02921\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03632 | val=0.02910\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03404 | val=0.02772\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03469 | val=0.02818\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03548 | val=0.03042\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03350 | val=0.02799\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03442 | val=0.02955\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03392 | val=0.02924\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03481 | val=0.03070\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03546 | val=0.03109\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03321 | val=0.02907\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03439 | val=0.03096\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03592 | val=0.03251\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03553 | val=0.03185\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03398 | val=0.03108\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03740 | val=0.03480\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03669 | val=0.03470\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.1s\n",
            "  [  10/20] base= 48 ml= 33 gain= 15  dt=   33.4s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   68.6s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [5/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:03:42] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.41412 | val=0.17100\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.17762 | val=0.15201\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.13946 | val=0.10125\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.10968 | val=0.07787\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.08869 | val=0.06653\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.07638 | val=0.05579\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.06993 | val=0.05603\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.06417 | val=0.04834\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.05938 | val=0.04859\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.05504 | val=0.04474\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.05169 | val=0.03882\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.05208 | val=0.04025\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.05059 | val=0.03884\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04856 | val=0.03725\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04592 | val=0.03464\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.04620 | val=0.03586\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04573 | val=0.03872\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.04294 | val=0.03397\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.04148 | val=0.03299\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.04269 | val=0.03441\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.04141 | val=0.03296\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.04303 | val=0.03369\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.04002 | val=0.03122\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03972 | val=0.03271\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03995 | val=0.03335\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03993 | val=0.03190\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.04127 | val=0.03439\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.04114 | val=0.03475\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.04050 | val=0.03459\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.04055 | val=0.03448\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.04082 | val=0.03528\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03888 | val=0.03291\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03922 | val=0.03396\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03690 | val=0.03222\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.04269 | val=0.03767\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03957 | val=0.03509\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.04031 | val=0.03706\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03864 | val=0.03524\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.04033 | val=0.03750\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03880 | val=0.03672\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 34 gain= 14  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 29 gain= 17  dt=   72.4s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [6/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:06:32] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.41493 | val=0.17210\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.17803 | val=0.15479\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.14015 | val=0.10155\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.11028 | val=0.07938\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.08889 | val=0.06764\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.07703 | val=0.05644\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.07040 | val=0.05268\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.06470 | val=0.04851\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.05999 | val=0.04819\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.05561 | val=0.04378\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.05197 | val=0.03902\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.05244 | val=0.04050\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.05060 | val=0.03920\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04829 | val=0.03746\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04586 | val=0.03474\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.04589 | val=0.03548\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04573 | val=0.03802\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.04297 | val=0.03391\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.04151 | val=0.03289\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.04266 | val=0.03433\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.04131 | val=0.03335\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.04283 | val=0.03327\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03971 | val=0.03223\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03972 | val=0.03191\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03975 | val=0.03259\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03969 | val=0.03195\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.04135 | val=0.03453\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.04102 | val=0.03456\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.04051 | val=0.03440\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.04050 | val=0.03416\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.04077 | val=0.03522\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03887 | val=0.03307\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03905 | val=0.03368\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03683 | val=0.03236\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.04246 | val=0.03754\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03943 | val=0.03509\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.04008 | val=0.03671\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03866 | val=0.03516\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.04011 | val=0.03746\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03871 | val=0.03653\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 35 gain= 13  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 29 gain= 17  dt=   71.0s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [7/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:09:21] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.30811 | val=0.13917\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.13336 | val=0.08653\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.08865 | val=0.06098\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.07131 | val=0.05281\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.06198 | val=0.04784\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.05623 | val=0.04032\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.05194 | val=0.04070\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04937 | val=0.03626\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04561 | val=0.03635\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.04299 | val=0.03543\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.04086 | val=0.03138\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.04186 | val=0.03461\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.04146 | val=0.03323\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03996 | val=0.03181\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03755 | val=0.02946\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03907 | val=0.03058\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03953 | val=0.03283\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03609 | val=0.02894\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03529 | val=0.02899\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03681 | val=0.03104\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03582 | val=0.02958\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03702 | val=0.02914\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03495 | val=0.02923\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03473 | val=0.02879\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03478 | val=0.02892\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03474 | val=0.02866\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03687 | val=0.03125\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03766 | val=0.03229\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03646 | val=0.03078\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03625 | val=0.03120\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03637 | val=0.03130\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03553 | val=0.03103\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03563 | val=0.03216\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03364 | val=0.03057\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03848 | val=0.03497\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03632 | val=0.03324\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03694 | val=0.03521\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03540 | val=0.03311\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03682 | val=0.03530\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03566 | val=0.03465\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.1s\n",
            "  [  10/20] base= 48 ml= 34 gain= 14  dt=   34.4s\n",
            "  [  20/20] base= 46 ml= 31 gain= 15  dt=   69.6s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [8/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:12:10] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.30844 | val=0.14259\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.13316 | val=0.08713\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.08773 | val=0.05923\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.06929 | val=0.05660\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.05935 | val=0.04434\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.05439 | val=0.04033\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.05089 | val=0.03669\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04785 | val=0.03601\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04478 | val=0.03758\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.04255 | val=0.03371\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.04027 | val=0.03074\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.04108 | val=0.03337\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.04070 | val=0.03226\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03955 | val=0.03157\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03737 | val=0.02951\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03832 | val=0.03042\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03913 | val=0.03190\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03548 | val=0.02860\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03493 | val=0.02827\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03640 | val=0.03025\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03572 | val=0.02956\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03709 | val=0.02990\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03486 | val=0.02923\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03448 | val=0.02824\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03457 | val=0.02833\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03438 | val=0.02821\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03659 | val=0.03122\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03760 | val=0.03228\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03629 | val=0.03080\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03616 | val=0.03162\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03627 | val=0.03145\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03515 | val=0.03028\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03537 | val=0.03177\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03351 | val=0.03030\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03859 | val=0.03495\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03614 | val=0.03313\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03673 | val=0.03507\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03527 | val=0.03296\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03670 | val=0.03539\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03551 | val=0.03475\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.1s\n",
            "  [  10/20] base= 48 ml= 36 gain= 12  dt=   35.9s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   71.0s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [9/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:14:59] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.40559 | val=0.16111\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.18086 | val=0.14642\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.14683 | val=0.10611\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.11213 | val=0.07960\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.09015 | val=0.06497\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.07832 | val=0.05956\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.06764 | val=0.05025\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.06228 | val=0.04978\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.05928 | val=0.04509\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.05761 | val=0.04533\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.05281 | val=0.03975\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.05061 | val=0.03963\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.05124 | val=0.04156\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04715 | val=0.03807\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04791 | val=0.03770\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.04772 | val=0.03721\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04544 | val=0.03534\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.04531 | val=0.03612\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.04402 | val=0.03455\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.04499 | val=0.03612\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.04363 | val=0.03537\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.04080 | val=0.03267\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.04212 | val=0.03460\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.04016 | val=0.03278\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03946 | val=0.03246\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03979 | val=0.03286\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03942 | val=0.03264\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.04065 | val=0.03343\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.04008 | val=0.03289\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03923 | val=0.03327\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03940 | val=0.03355\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03999 | val=0.03477\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.04033 | val=0.03440\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03914 | val=0.03371\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03972 | val=0.03482\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.04034 | val=0.03502\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.04220 | val=0.03737\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03980 | val=0.03567\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03912 | val=0.03535\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.04266 | val=0.03786\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 34 gain= 14  dt=   35.4s\n",
            "  [  20/20] base= 46 ml= 29 gain= 17  dt=   70.9s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [10/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:17:49] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.40547 | val=0.16494\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.18021 | val=0.14724\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.14555 | val=0.10897\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.11173 | val=0.07939\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.09048 | val=0.06586\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.07910 | val=0.06005\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.06842 | val=0.05187\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.06302 | val=0.05284\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.06045 | val=0.04609\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.05825 | val=0.04468\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.05330 | val=0.04084\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.05077 | val=0.04041\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.05166 | val=0.04068\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04714 | val=0.03731\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04786 | val=0.03696\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.04741 | val=0.03767\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04532 | val=0.03573\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.04510 | val=0.03547\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.04363 | val=0.03427\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.04443 | val=0.03433\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.04304 | val=0.03513\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.04045 | val=0.03197\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.04176 | val=0.03340\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03986 | val=0.03267\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03910 | val=0.03237\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03919 | val=0.03258\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03904 | val=0.03251\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.04014 | val=0.03291\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03989 | val=0.03307\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03902 | val=0.03287\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03895 | val=0.03269\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03951 | val=0.03423\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03986 | val=0.03362\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03879 | val=0.03327\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03927 | val=0.03435\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03992 | val=0.03460\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.04192 | val=0.03699\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03982 | val=0.03552\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03888 | val=0.03509\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.04210 | val=0.03733\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.5s\n",
            "  [  10/20] base= 48 ml= 35 gain= 13  dt=   36.0s\n",
            "  [  20/20] base= 46 ml= 30 gain= 16  dt=   73.2s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [11/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:20:42] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.30216 | val=0.14471\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.13712 | val=0.08834\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.09210 | val=0.05995\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.07094 | val=0.04761\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.06009 | val=0.04203\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.05475 | val=0.04094\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04982 | val=0.04087\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04706 | val=0.03616\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04743 | val=0.03849\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.04551 | val=0.03560\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.04177 | val=0.03384\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.04044 | val=0.03200\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.04106 | val=0.03320\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03839 | val=0.03130\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03979 | val=0.03041\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03897 | val=0.03083\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03786 | val=0.03036\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03757 | val=0.02956\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03695 | val=0.02948\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03698 | val=0.02930\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03644 | val=0.02983\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03468 | val=0.02803\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03594 | val=0.02911\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03466 | val=0.02847\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03371 | val=0.02825\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03464 | val=0.02826\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03412 | val=0.02883\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03464 | val=0.02787\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03447 | val=0.02909\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03402 | val=0.02870\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03410 | val=0.02892\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03516 | val=0.03105\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03512 | val=0.03031\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03524 | val=0.03080\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03505 | val=0.03122\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03515 | val=0.03101\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03738 | val=0.03371\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03599 | val=0.03264\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03505 | val=0.03214\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03769 | val=0.03434\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.9s\n",
            "  [  10/20] base= 48 ml= 33 gain= 15  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.5s\n",
            "[best@n=30] total_gain=375 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [12/36] n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:23:31] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=2000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.30269 | val=0.14021\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.13710 | val=0.08684\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.09132 | val=0.06020\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.07072 | val=0.04861\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.06007 | val=0.04187\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.05480 | val=0.04073\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.05047 | val=0.04047\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04754 | val=0.03743\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04740 | val=0.03749\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.04587 | val=0.03513\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.04220 | val=0.03483\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.04080 | val=0.03234\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.04146 | val=0.03271\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03865 | val=0.03089\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03985 | val=0.03019\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03915 | val=0.03159\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03758 | val=0.03058\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03738 | val=0.02947\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03686 | val=0.02890\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03698 | val=0.02909\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03661 | val=0.03066\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03455 | val=0.02711\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03566 | val=0.02860\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03438 | val=0.02817\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03350 | val=0.02804\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03424 | val=0.02777\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03377 | val=0.02805\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03413 | val=0.02750\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03406 | val=0.02861\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03362 | val=0.02828\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03381 | val=0.02822\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03472 | val=0.03059\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03436 | val=0.02969\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03441 | val=0.02986\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03461 | val=0.03063\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03497 | val=0.03079\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03656 | val=0.03302\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03555 | val=0.03225\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03437 | val=0.03158\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03722 | val=0.03404\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.8s\n",
            "  [  10/20] base= 48 ml= 33 gain= 15  dt=   33.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   69.6s\n",
            "[best@n=30] total_gain=380 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [13/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:26:19] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.32498 | val=0.14986\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.14634 | val=0.10193\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.10248 | val=0.07241\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.07835 | val=0.05696\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.06453 | val=0.04705\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.06060 | val=0.04710\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.05381 | val=0.04102\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04988 | val=0.03853\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04759 | val=0.03645\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.04582 | val=0.03583\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.04508 | val=0.03615\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04354 | val=0.03498\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04293 | val=0.03540\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04122 | val=0.03363\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04037 | val=0.03225\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03854 | val=0.03159\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03836 | val=0.03161\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03898 | val=0.03171\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03760 | val=0.03086\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03614 | val=0.02994\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03621 | val=0.03082\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03470 | val=0.02835\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03503 | val=0.02995\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03297 | val=0.02758\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03511 | val=0.03024\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03470 | val=0.03005\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03569 | val=0.03199\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03432 | val=0.03027\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03606 | val=0.03256\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03433 | val=0.03041\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03422 | val=0.02960\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03479 | val=0.03106\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03436 | val=0.03101\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03351 | val=0.03014\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03455 | val=0.03094\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03227 | val=0.02909\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03480 | val=0.03132\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03326 | val=0.03026\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03489 | val=0.03185\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03565 | val=0.03290\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.7s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   35.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.9s\n",
            "[best@n=30] total_gain=380 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [14/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:29:53] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.32491 | val=0.14964\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.14726 | val=0.10294\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.10313 | val=0.07526\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.07872 | val=0.06235\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.06479 | val=0.04874\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.06077 | val=0.04476\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.05388 | val=0.04040\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04991 | val=0.03806\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04784 | val=0.03729\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.04561 | val=0.03649\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.04490 | val=0.03616\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04345 | val=0.03619\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04277 | val=0.03523\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04099 | val=0.03343\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04006 | val=0.03224\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03850 | val=0.03208\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03823 | val=0.03221\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03871 | val=0.03099\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03746 | val=0.03008\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03633 | val=0.03086\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03611 | val=0.03042\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03470 | val=0.02924\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03499 | val=0.03017\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03309 | val=0.02806\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03527 | val=0.03132\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03484 | val=0.03064\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03577 | val=0.03233\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03429 | val=0.03040\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03603 | val=0.03251\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03427 | val=0.03035\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03434 | val=0.03000\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03485 | val=0.03115\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03446 | val=0.03128\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03358 | val=0.03044\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03461 | val=0.03110\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03228 | val=0.02942\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03484 | val=0.03165\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03326 | val=0.03040\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03502 | val=0.03219\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03577 | val=0.03310\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 33 gain= 15  dt=   36.2s\n",
            "  [  20/20] base= 46 ml= 27 gain= 19  dt=   71.9s\n",
            "[best@n=30] total_gain=380 (n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [15/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:33:26] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.24422 | val=0.10403\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.09446 | val=0.05994\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.06657 | val=0.04815\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.05471 | val=0.04200\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04889 | val=0.03857\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04722 | val=0.03636\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04440 | val=0.03386\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04158 | val=0.03264\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03950 | val=0.03184\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03801 | val=0.02943\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03731 | val=0.02981\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03596 | val=0.02986\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03621 | val=0.02909\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03500 | val=0.03058\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03438 | val=0.02772\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03436 | val=0.02912\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03336 | val=0.02900\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03383 | val=0.02760\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03356 | val=0.02845\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03289 | val=0.02798\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03332 | val=0.02957\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03181 | val=0.02860\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03269 | val=0.02765\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03033 | val=0.02572\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03251 | val=0.02818\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03213 | val=0.02889\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03293 | val=0.02968\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03224 | val=0.02959\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03342 | val=0.03034\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03185 | val=0.02864\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03178 | val=0.02807\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03279 | val=0.02954\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03239 | val=0.02984\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03159 | val=0.02951\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03254 | val=0.02990\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03022 | val=0.02840\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03296 | val=0.03086\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03112 | val=0.02943\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03333 | val=0.03141\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03391 | val=0.03233\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.5s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.2s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   69.9s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [16/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:36:57] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.24338 | val=0.10303\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.09351 | val=0.06798\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.06710 | val=0.04587\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.05537 | val=0.04318\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04919 | val=0.03859\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04801 | val=0.03873\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04483 | val=0.03450\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04178 | val=0.03304\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04003 | val=0.03245\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03861 | val=0.03013\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03764 | val=0.03043\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03646 | val=0.02908\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03628 | val=0.02856\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03505 | val=0.02947\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03448 | val=0.02762\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03373 | val=0.02769\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03321 | val=0.02752\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03329 | val=0.02679\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03307 | val=0.02705\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03246 | val=0.02731\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03283 | val=0.02825\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03171 | val=0.02782\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03223 | val=0.02838\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.02998 | val=0.02576\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03205 | val=0.02793\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03168 | val=0.02862\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03244 | val=0.02864\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03199 | val=0.02962\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03333 | val=0.03053\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03183 | val=0.02853\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03161 | val=0.02815\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03268 | val=0.02969\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03243 | val=0.02988\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03161 | val=0.02948\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03244 | val=0.02991\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03008 | val=0.02832\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03274 | val=0.03076\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03111 | val=0.02942\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03307 | val=0.03115\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03375 | val=0.03217\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    3.0s\n",
            "  [  10/20] base= 48 ml= 33 gain= 15  dt=   36.0s\n",
            "  [  20/20] base= 46 ml= 27 gain= 19  dt=   72.2s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [17/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:40:32] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.33267 | val=0.15420\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.14789 | val=0.09894\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.09912 | val=0.06780\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.07639 | val=0.05409\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.06596 | val=0.04844\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.05876 | val=0.04414\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.05438 | val=0.04179\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.05026 | val=0.03902\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04862 | val=0.03760\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.04645 | val=0.03554\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.04491 | val=0.03598\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04449 | val=0.03514\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04402 | val=0.03510\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04168 | val=0.03281\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04086 | val=0.03491\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03923 | val=0.03115\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03782 | val=0.02977\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03905 | val=0.03236\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03730 | val=0.03021\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03829 | val=0.03235\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03744 | val=0.03063\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03663 | val=0.03177\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03730 | val=0.03124\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03503 | val=0.02948\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03568 | val=0.03099\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03645 | val=0.03227\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03588 | val=0.03131\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03632 | val=0.03139\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03570 | val=0.03197\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03580 | val=0.03157\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03576 | val=0.03198\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03567 | val=0.03253\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03530 | val=0.03178\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03555 | val=0.03164\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03439 | val=0.03066\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03561 | val=0.03246\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03438 | val=0.03127\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03727 | val=0.03395\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03658 | val=0.03360\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03536 | val=0.03269\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   34.2s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   71.3s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [18/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:44:07] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.33298 | val=0.15562\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.14969 | val=0.10188\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.10211 | val=0.06986\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.07774 | val=0.05529\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.06665 | val=0.04879\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.05908 | val=0.04435\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.05467 | val=0.04135\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.05041 | val=0.03771\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04866 | val=0.03777\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.04616 | val=0.03555\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.04471 | val=0.03553\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04401 | val=0.03483\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04368 | val=0.03496\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04131 | val=0.03298\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.04024 | val=0.03444\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03904 | val=0.03199\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03766 | val=0.02947\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03903 | val=0.03204\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03698 | val=0.02975\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03832 | val=0.03254\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03736 | val=0.03048\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03684 | val=0.03255\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03706 | val=0.03121\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03494 | val=0.02972\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03553 | val=0.03040\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03653 | val=0.03240\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03582 | val=0.03055\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03646 | val=0.03117\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03557 | val=0.03186\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03583 | val=0.03177\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03594 | val=0.03227\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03539 | val=0.03215\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03510 | val=0.03115\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03540 | val=0.03130\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03452 | val=0.03070\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03551 | val=0.03239\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03429 | val=0.03111\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03721 | val=0.03375\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03642 | val=0.03340\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03534 | val=0.03270\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.2s\n",
            "  [  20/20] base= 46 ml= 29 gain= 17  dt=   72.8s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [19/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:47:44] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.25126 | val=0.10897\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.09444 | val=0.05716\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.06555 | val=0.04409\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.05521 | val=0.03971\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04930 | val=0.04028\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04664 | val=0.03817\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04447 | val=0.03617\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04151 | val=0.03633\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04047 | val=0.03231\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03853 | val=0.02992\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03744 | val=0.02926\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03765 | val=0.03270\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03711 | val=0.02928\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03580 | val=0.02908\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03479 | val=0.02943\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03386 | val=0.02807\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03350 | val=0.02905\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03481 | val=0.02929\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03254 | val=0.02789\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03419 | val=0.03063\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03379 | val=0.02839\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03332 | val=0.02999\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03375 | val=0.02887\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03142 | val=0.02685\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03215 | val=0.02787\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03299 | val=0.02907\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03215 | val=0.02840\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03315 | val=0.02910\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03236 | val=0.02903\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03239 | val=0.02937\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03299 | val=0.03013\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03224 | val=0.02999\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03254 | val=0.02980\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03226 | val=0.02965\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03155 | val=0.02915\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03284 | val=0.03103\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03111 | val=0.02908\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03421 | val=0.03219\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03323 | val=0.03147\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03248 | val=0.03125\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.9s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   34.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   71.5s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [20/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:51:19] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.24886 | val=0.10177\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.09341 | val=0.06124\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.06493 | val=0.04327\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.05477 | val=0.04045\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04949 | val=0.03931\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04734 | val=0.03866\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04509 | val=0.03504\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04239 | val=0.03353\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04109 | val=0.03289\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03886 | val=0.03048\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03781 | val=0.03017\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03776 | val=0.03143\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03757 | val=0.03019\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03595 | val=0.02872\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03506 | val=0.02853\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03386 | val=0.02870\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03380 | val=0.02923\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03466 | val=0.02949\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03269 | val=0.02809\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03422 | val=0.03035\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03382 | val=0.02894\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03323 | val=0.02931\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03388 | val=0.02989\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03150 | val=0.02705\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03206 | val=0.02789\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03307 | val=0.02894\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03216 | val=0.02801\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03344 | val=0.02976\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03221 | val=0.02910\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03263 | val=0.02965\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03320 | val=0.03064\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03257 | val=0.03033\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03228 | val=0.02951\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03201 | val=0.02948\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03184 | val=0.02954\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03281 | val=0.03113\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03121 | val=0.02949\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03454 | val=0.03266\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03384 | val=0.03221\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03263 | val=0.03131\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   33.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.1s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [21/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:54:52] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.33320 | val=0.15527\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.15184 | val=0.10619\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.10881 | val=0.07802\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.08199 | val=0.06192\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.06935 | val=0.05417\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.05783 | val=0.04505\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.05558 | val=0.04241\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.05151 | val=0.04073\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04947 | val=0.03827\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.04526 | val=0.03657\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.04587 | val=0.03713\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04394 | val=0.03526\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04384 | val=0.03489\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04122 | val=0.03455\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03953 | val=0.03153\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03889 | val=0.03114\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03975 | val=0.03200\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03776 | val=0.03111\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03769 | val=0.03041\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03731 | val=0.03112\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03651 | val=0.03095\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03685 | val=0.03131\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03820 | val=0.03246\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03602 | val=0.03035\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03589 | val=0.03060\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03495 | val=0.03017\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03536 | val=0.03089\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03505 | val=0.03078\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03564 | val=0.03154\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03464 | val=0.03063\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03543 | val=0.03176\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03451 | val=0.03098\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03337 | val=0.02954\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03405 | val=0.03069\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03694 | val=0.03294\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03523 | val=0.03154\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03545 | val=0.03221\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03609 | val=0.03276\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03451 | val=0.03140\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03532 | val=0.03237\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.2s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.7s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   72.2s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [22/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 17:58:28] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.33318 | val=0.15590\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.15036 | val=0.10351\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.10657 | val=0.07568\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.08141 | val=0.06174\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.06937 | val=0.05542\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.05805 | val=0.04475\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.05535 | val=0.04263\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.05155 | val=0.04127\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04963 | val=0.03861\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.04571 | val=0.03633\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.04606 | val=0.03749\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.04406 | val=0.03702\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.04383 | val=0.03472\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.04157 | val=0.03416\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03969 | val=0.03190\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03912 | val=0.03168\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.04012 | val=0.03235\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03792 | val=0.03143\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03809 | val=0.03047\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03761 | val=0.03062\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03688 | val=0.03166\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03726 | val=0.03211\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03846 | val=0.03263\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03645 | val=0.03016\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03622 | val=0.03182\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03522 | val=0.03038\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03564 | val=0.03065\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03532 | val=0.03114\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03589 | val=0.03210\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03486 | val=0.03119\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03563 | val=0.03215\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03472 | val=0.03151\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03365 | val=0.02981\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03437 | val=0.03087\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03709 | val=0.03323\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03537 | val=0.03170\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03557 | val=0.03254\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03625 | val=0.03286\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03465 | val=0.03150\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03541 | val=0.03244\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.8s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   72.1s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [23/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:02:04] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.25450 | val=0.11578\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.09772 | val=0.05814\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.06968 | val=0.04958\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.05775 | val=0.04415\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.05194 | val=0.04136\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04598 | val=0.03624\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04458 | val=0.03516\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04316 | val=0.03611\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04156 | val=0.03222\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03841 | val=0.03184\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03872 | val=0.03246\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03686 | val=0.03036\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03680 | val=0.02936\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03549 | val=0.02901\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03405 | val=0.02718\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03371 | val=0.02692\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03488 | val=0.02868\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03328 | val=0.02882\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03293 | val=0.02732\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03338 | val=0.02960\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03261 | val=0.02819\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03195 | val=0.02850\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03390 | val=0.02854\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03201 | val=0.02696\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03114 | val=0.02649\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03098 | val=0.02627\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03154 | val=0.02786\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03103 | val=0.02702\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03137 | val=0.02958\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03109 | val=0.02855\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03131 | val=0.03006\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03107 | val=0.02933\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03030 | val=0.02782\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03074 | val=0.02863\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03352 | val=0.03142\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03182 | val=0.02988\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03171 | val=0.02999\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03256 | val=0.03066\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03127 | val=0.02968\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03231 | val=0.03114\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 34 gain= 14  dt=   34.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.3s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [24/36] n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:05:36] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=3000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.25465 | val=0.11506\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.09833 | val=0.05899\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.06960 | val=0.04798\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.05671 | val=0.04165\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.05143 | val=0.04059\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04511 | val=0.03530\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.04401 | val=0.03428\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.04240 | val=0.03340\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.04086 | val=0.03154\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03781 | val=0.02974\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03801 | val=0.03097\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03642 | val=0.03060\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03653 | val=0.02956\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03492 | val=0.02968\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03355 | val=0.02625\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03334 | val=0.02625\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03449 | val=0.02851\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03283 | val=0.02759\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03267 | val=0.02745\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03319 | val=0.02913\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03234 | val=0.02849\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03172 | val=0.02697\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03379 | val=0.02863\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03174 | val=0.02719\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03097 | val=0.02619\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03091 | val=0.02626\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03154 | val=0.02786\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03093 | val=0.02714\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03131 | val=0.02870\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03107 | val=0.02844\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03107 | val=0.02951\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03108 | val=0.02891\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03033 | val=0.02764\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03069 | val=0.02866\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03345 | val=0.03105\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03166 | val=0.02952\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03162 | val=0.02969\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03261 | val=0.03039\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03116 | val=0.02943\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03239 | val=0.03099\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 33 gain= 15  dt=   35.2s\n",
            "  [  20/20] base= 46 ml= 27 gain= 19  dt=   69.9s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [25/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:09:09] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.26018 | val=0.13079\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.10564 | val=0.07645\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.07277 | val=0.05354\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.05774 | val=0.04783\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.05117 | val=0.04226\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.04923 | val=0.04186\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.04351 | val=0.03672\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04187 | val=0.03532\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.03922 | val=0.03520\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.03876 | val=0.03197\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.03711 | val=0.03318\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.03693 | val=0.03158\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.03597 | val=0.03099\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.03487 | val=0.03230\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03464 | val=0.03000\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03351 | val=0.02988\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03526 | val=0.03274\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03387 | val=0.02970\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03267 | val=0.03010\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03309 | val=0.03231\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03285 | val=0.02982\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03278 | val=0.02977\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03278 | val=0.02981\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03264 | val=0.02931\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03249 | val=0.03004\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03171 | val=0.02893\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03314 | val=0.03120\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03263 | val=0.03050\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03236 | val=0.03138\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03294 | val=0.03166\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03275 | val=0.03099\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03255 | val=0.03117\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03298 | val=0.03162\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03300 | val=0.03163\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03208 | val=0.03108\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03411 | val=0.03360\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03264 | val=0.03199\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03243 | val=0.03132\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03273 | val=0.03191\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03297 | val=0.03206\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.9s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   34.2s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.3s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [26/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:14:04] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.25962 | val=0.12656\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.10465 | val=0.07668\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.07257 | val=0.05798\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.05758 | val=0.05014\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.05100 | val=0.04412\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.04935 | val=0.04298\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.04370 | val=0.03622\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04192 | val=0.03498\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.03934 | val=0.03478\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.03893 | val=0.03245\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.03716 | val=0.03354\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.03706 | val=0.03268\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.03610 | val=0.03194\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.03491 | val=0.03259\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03465 | val=0.03145\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03358 | val=0.02940\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03524 | val=0.03342\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03390 | val=0.03018\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03278 | val=0.02941\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03319 | val=0.03166\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03286 | val=0.02938\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03276 | val=0.02989\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03284 | val=0.03050\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03274 | val=0.02999\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03252 | val=0.03034\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03184 | val=0.02909\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03325 | val=0.03126\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03274 | val=0.03058\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03249 | val=0.03148\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03307 | val=0.03192\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03293 | val=0.03139\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03267 | val=0.03166\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03319 | val=0.03212\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03333 | val=0.03218\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03228 | val=0.03182\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03426 | val=0.03371\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03276 | val=0.03248\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03267 | val=0.03176\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03288 | val=0.03245\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03319 | val=0.03244\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.0s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.3s\n",
            "[best@n=30] total_gain=386 (n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [27/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:18:57] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.19051 | val=0.07458\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.07094 | val=0.05489\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.05370 | val=0.04062\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.04544 | val=0.03694\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04151 | val=0.03538\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04067 | val=0.03365\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.03728 | val=0.03098\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.03641 | val=0.03239\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03478 | val=0.02954\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03514 | val=0.03048\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03414 | val=0.02975\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03416 | val=0.02919\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03344 | val=0.02993\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03218 | val=0.03024\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03220 | val=0.02914\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03124 | val=0.02666\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03243 | val=0.03245\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03137 | val=0.02798\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03037 | val=0.02751\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03050 | val=0.02945\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03061 | val=0.02900\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03049 | val=0.02920\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03072 | val=0.02997\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03039 | val=0.02813\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.02994 | val=0.02911\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.02987 | val=0.02738\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03086 | val=0.02934\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03040 | val=0.02829\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03019 | val=0.02883\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03099 | val=0.03012\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03066 | val=0.02966\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03021 | val=0.02960\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03079 | val=0.03012\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03105 | val=0.03021\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03016 | val=0.02989\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03162 | val=0.03133\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03128 | val=0.03141\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03026 | val=0.03021\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03057 | val=0.03097\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03095 | val=0.03123\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    3.2s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   34.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   69.2s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [28/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:23:51] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.19050 | val=0.07396\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.07087 | val=0.05639\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.05368 | val=0.04264\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.04583 | val=0.03847\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04175 | val=0.03445\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04122 | val=0.03566\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.03738 | val=0.03111\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.03673 | val=0.03225\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03459 | val=0.02942\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03539 | val=0.03116\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03426 | val=0.03082\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03452 | val=0.03049\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03409 | val=0.03042\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03305 | val=0.03251\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03297 | val=0.02970\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03229 | val=0.02901\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03333 | val=0.03174\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03237 | val=0.02871\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03134 | val=0.02867\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03134 | val=0.03071\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03122 | val=0.02922\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03053 | val=0.02839\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03093 | val=0.03030\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03064 | val=0.02809\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03030 | val=0.02931\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03005 | val=0.02715\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03062 | val=0.02898\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03057 | val=0.02836\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03053 | val=0.02884\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03073 | val=0.02916\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03116 | val=0.02965\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03046 | val=0.02935\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03104 | val=0.03011\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03081 | val=0.02954\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03016 | val=0.02931\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03194 | val=0.03153\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03093 | val=0.03058\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03072 | val=0.03019\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03059 | val=0.03039\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03097 | val=0.03060\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.6s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   33.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   68.9s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [29/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:28:40] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.26402 | val=0.13282\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.10721 | val=0.06672\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.07282 | val=0.05449\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.05827 | val=0.04332\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.05135 | val=0.04142\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.04548 | val=0.03664\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.04351 | val=0.03520\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04131 | val=0.03312\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.03953 | val=0.03253\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.03803 | val=0.03036\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.03756 | val=0.03423\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.03712 | val=0.03077\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.03585 | val=0.03127\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.03652 | val=0.03082\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03379 | val=0.02874\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03388 | val=0.03037\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03370 | val=0.02914\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03359 | val=0.03078\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03264 | val=0.02878\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03342 | val=0.02987\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03219 | val=0.02913\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03036 | val=0.02848\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03200 | val=0.02848\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03146 | val=0.02882\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03090 | val=0.02721\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03207 | val=0.02898\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03167 | val=0.02934\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03259 | val=0.03048\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03179 | val=0.02986\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03212 | val=0.03012\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03078 | val=0.02904\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03167 | val=0.03035\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03170 | val=0.03027\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03061 | val=0.02886\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03211 | val=0.03084\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03193 | val=0.03135\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03209 | val=0.03102\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03282 | val=0.03168\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03073 | val=0.02939\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03264 | val=0.03189\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   34.5s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.2s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [30/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:33:34] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.26397 | val=0.13084\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.10689 | val=0.06593\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.07263 | val=0.05218\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.05837 | val=0.04313\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.05164 | val=0.04140\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.04559 | val=0.03689\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.04386 | val=0.03508\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04161 | val=0.03310\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.03979 | val=0.03217\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.03822 | val=0.03060\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.03753 | val=0.03369\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.03706 | val=0.03061\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.03595 | val=0.03125\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.03648 | val=0.03230\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03397 | val=0.02901\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03404 | val=0.03097\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03405 | val=0.03053\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03393 | val=0.03116\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03306 | val=0.02958\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03404 | val=0.03028\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03264 | val=0.02961\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03106 | val=0.02941\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03280 | val=0.02934\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03212 | val=0.02934\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03140 | val=0.02751\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03270 | val=0.02972\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03216 | val=0.03026\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03281 | val=0.03050\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03219 | val=0.03045\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03265 | val=0.03099\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03123 | val=0.02974\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03194 | val=0.03092\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03177 | val=0.03029\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03090 | val=0.02941\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03249 | val=0.03140\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03225 | val=0.03174\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03242 | val=0.03131\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03309 | val=0.03188\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03111 | val=0.02980\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03278 | val=0.03184\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   35.6s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.2s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [31/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:38:27] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.19364 | val=0.07186\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.07173 | val=0.04820\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.05465 | val=0.04069\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.04696 | val=0.03754\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04268 | val=0.03362\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.03907 | val=0.03108\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.03751 | val=0.02943\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.03659 | val=0.03082\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03576 | val=0.02989\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03427 | val=0.02844\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03438 | val=0.02955\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03414 | val=0.02880\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03349 | val=0.02857\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03364 | val=0.02821\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03100 | val=0.02716\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03159 | val=0.02840\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03147 | val=0.02809\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03190 | val=0.03011\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03087 | val=0.02729\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03197 | val=0.02925\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03092 | val=0.02909\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.02895 | val=0.02859\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03063 | val=0.02922\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03007 | val=0.02888\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.02984 | val=0.02777\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03085 | val=0.02959\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03061 | val=0.02925\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03147 | val=0.02988\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03064 | val=0.02941\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03087 | val=0.03064\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.02979 | val=0.02868\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03068 | val=0.03043\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03071 | val=0.03018\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.02964 | val=0.02880\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03132 | val=0.03078\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03089 | val=0.03128\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03135 | val=0.03141\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03214 | val=0.03203\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.02976 | val=0.02958\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03193 | val=0.03230\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.6s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   35.2s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.6s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [32/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:43:23] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.19307 | val=0.07027\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.07120 | val=0.04809\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.05424 | val=0.04073\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.04672 | val=0.03895\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04260 | val=0.03347\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.03851 | val=0.03095\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.03706 | val=0.02927\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.03616 | val=0.02942\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03545 | val=0.02919\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03396 | val=0.02807\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03360 | val=0.02848\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03367 | val=0.03077\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03310 | val=0.02860\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03353 | val=0.02938\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03084 | val=0.02571\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03151 | val=0.02776\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03150 | val=0.02817\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03169 | val=0.02968\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03086 | val=0.02771\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03185 | val=0.03024\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03075 | val=0.02949\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.02895 | val=0.02914\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03038 | val=0.02962\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03007 | val=0.02926\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.02970 | val=0.02810\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03084 | val=0.03019\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03053 | val=0.02891\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.03149 | val=0.03039\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03066 | val=0.02991\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03084 | val=0.03036\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.02981 | val=0.02875\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03063 | val=0.03051\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03077 | val=0.03069\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.02963 | val=0.02906\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03127 | val=0.03123\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03088 | val=0.03141\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03118 | val=0.03168\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03206 | val=0.03212\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.02991 | val=0.02994\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03191 | val=0.03256\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   69.8s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [33/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:48:18] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.26551 | val=0.12786\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.10791 | val=0.07229\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.07207 | val=0.05664\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.05702 | val=0.04419\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.05191 | val=0.04330\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.04761 | val=0.03811\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.04428 | val=0.03584\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04077 | val=0.03313\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04026 | val=0.03321\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.03962 | val=0.03375\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.03789 | val=0.03138\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.03776 | val=0.03190\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.03593 | val=0.02963\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.03578 | val=0.02944\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03423 | val=0.02880\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03424 | val=0.02907\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03444 | val=0.02967\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03339 | val=0.02899\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03256 | val=0.02894\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03299 | val=0.03207\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03290 | val=0.02921\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03173 | val=0.02962\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03222 | val=0.02914\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03171 | val=0.02937\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03201 | val=0.03016\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03239 | val=0.03052\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03112 | val=0.02888\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03031 | val=0.02791\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03214 | val=0.03031\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03148 | val=0.02963\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03111 | val=0.02910\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03229 | val=0.03058\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03247 | val=0.03065\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03291 | val=0.03115\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03116 | val=0.02992\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03239 | val=0.03117\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03151 | val=0.03073\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03168 | val=0.03057\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03245 | val=0.03122\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03214 | val=0.03122\n",
            "  [   1/20] base= 38 ml= 24 gain= 14  dt=    2.4s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   34.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.6s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [34/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0001_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:53:16] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0001_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=9.98e-05 | train=0.26485 | val=0.12549\n",
            "Epoch 001/40 | lr=9.94e-05 | train=0.10664 | val=0.07420\n",
            "Epoch 002/40 | lr=9.86e-05 | train=0.07165 | val=0.05563\n",
            "Epoch 003/40 | lr=9.76e-05 | train=0.05732 | val=0.04487\n",
            "Epoch 004/40 | lr=9.62e-05 | train=0.05211 | val=0.04153\n",
            "Epoch 005/40 | lr=9.46e-05 | train=0.04778 | val=0.03849\n",
            "Epoch 006/40 | lr=9.26e-05 | train=0.04454 | val=0.03647\n",
            "Epoch 007/40 | lr=9.05e-05 | train=0.04125 | val=0.03360\n",
            "Epoch 008/40 | lr=8.80e-05 | train=0.04042 | val=0.03288\n",
            "Epoch 009/40 | lr=8.54e-05 | train=0.03974 | val=0.03302\n",
            "Epoch 010/40 | lr=8.25e-05 | train=0.03783 | val=0.03187\n",
            "Epoch 011/40 | lr=7.94e-05 | train=0.03772 | val=0.03122\n",
            "Epoch 012/40 | lr=7.61e-05 | train=0.03570 | val=0.02951\n",
            "Epoch 013/40 | lr=7.27e-05 | train=0.03577 | val=0.02939\n",
            "Epoch 014/40 | lr=6.91e-05 | train=0.03440 | val=0.02891\n",
            "Epoch 015/40 | lr=6.55e-05 | train=0.03476 | val=0.02942\n",
            "Epoch 016/40 | lr=6.17e-05 | train=0.03458 | val=0.02998\n",
            "Epoch 017/40 | lr=5.78e-05 | train=0.03401 | val=0.02944\n",
            "Epoch 018/40 | lr=5.39e-05 | train=0.03292 | val=0.03164\n",
            "Epoch 019/40 | lr=5.00e-05 | train=0.03352 | val=0.03123\n",
            "Epoch 020/40 | lr=4.61e-05 | train=0.03332 | val=0.02935\n",
            "Epoch 021/40 | lr=4.22e-05 | train=0.03202 | val=0.02886\n",
            "Epoch 022/40 | lr=3.83e-05 | train=0.03236 | val=0.02948\n",
            "Epoch 023/40 | lr=3.45e-05 | train=0.03186 | val=0.02909\n",
            "Epoch 024/40 | lr=3.09e-05 | train=0.03219 | val=0.02991\n",
            "Epoch 025/40 | lr=2.73e-05 | train=0.03236 | val=0.02971\n",
            "Epoch 026/40 | lr=2.39e-05 | train=0.03136 | val=0.02873\n",
            "Epoch 027/40 | lr=2.06e-05 | train=0.03042 | val=0.02757\n",
            "Epoch 028/40 | lr=1.75e-05 | train=0.03215 | val=0.03011\n",
            "Epoch 029/40 | lr=1.46e-05 | train=0.03157 | val=0.02955\n",
            "Epoch 030/40 | lr=1.20e-05 | train=0.03108 | val=0.02916\n",
            "Epoch 031/40 | lr=9.55e-06 | train=0.03219 | val=0.03022\n",
            "Epoch 032/40 | lr=7.37e-06 | train=0.03238 | val=0.03034\n",
            "Epoch 033/40 | lr=5.45e-06 | train=0.03279 | val=0.03093\n",
            "Epoch 034/40 | lr=3.81e-06 | train=0.03119 | val=0.02986\n",
            "Epoch 035/40 | lr=2.45e-06 | train=0.03231 | val=0.03107\n",
            "Epoch 036/40 | lr=1.38e-06 | train=0.03152 | val=0.03063\n",
            "Epoch 037/40 | lr=6.16e-07 | train=0.03168 | val=0.03055\n",
            "Epoch 038/40 | lr=1.54e-07 | train=0.03232 | val=0.03123\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03201 | val=0.03113\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.4s\n",
            "  [  10/20] base= 48 ml= 31 gain= 17  dt=   35.1s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   70.8s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [35/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0002_wd0.005_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 18:58:12] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0002_wd0.005_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.19586 | val=0.08433\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.07105 | val=0.05547\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.05364 | val=0.04229\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.04699 | val=0.03779\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04412 | val=0.03585\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04126 | val=0.03322\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.03940 | val=0.03264\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.03632 | val=0.03012\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03643 | val=0.03188\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03527 | val=0.02941\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03404 | val=0.03112\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03424 | val=0.02870\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03245 | val=0.02756\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03255 | val=0.02984\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03214 | val=0.02730\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03181 | val=0.02805\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03217 | val=0.02872\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03127 | val=0.02813\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03076 | val=0.02729\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03124 | val=0.02897\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03141 | val=0.02822\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03029 | val=0.02737\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03068 | val=0.02815\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03052 | val=0.02805\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03080 | val=0.02938\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03102 | val=0.02984\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03013 | val=0.02909\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.02930 | val=0.02862\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03104 | val=0.03070\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03046 | val=0.02955\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03002 | val=0.02961\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03116 | val=0.03050\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03123 | val=0.03046\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03159 | val=0.03078\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03037 | val=0.02995\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03136 | val=0.03113\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03069 | val=0.03088\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03069 | val=0.03066\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03152 | val=0.03162\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03119 | val=0.03132\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.0s\n",
            "  [  10/20] base= 48 ml= 32 gain= 16  dt=   33.7s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   69.3s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n",
            "\n",
            "===== [36/36] n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p =====\n",
            "\n",
            "[2026-02-04 19:03:07] EXP=n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0002_wd0.01_ep40_wg0.15_log1p | model=EmbMLP n=30 | epochs=40 rw_width=5000 rw_mode=mix\n",
            "Epoch 000/40 | lr=2.00e-04 | train=0.19582 | val=0.07474\n",
            "Epoch 001/40 | lr=1.99e-04 | train=0.07065 | val=0.04973\n",
            "Epoch 002/40 | lr=1.97e-04 | train=0.05316 | val=0.04100\n",
            "Epoch 003/40 | lr=1.95e-04 | train=0.04624 | val=0.03539\n",
            "Epoch 004/40 | lr=1.92e-04 | train=0.04340 | val=0.03504\n",
            "Epoch 005/40 | lr=1.89e-04 | train=0.04037 | val=0.03248\n",
            "Epoch 006/40 | lr=1.85e-04 | train=0.03889 | val=0.03235\n",
            "Epoch 007/40 | lr=1.81e-04 | train=0.03593 | val=0.03090\n",
            "Epoch 008/40 | lr=1.76e-04 | train=0.03599 | val=0.03051\n",
            "Epoch 009/40 | lr=1.71e-04 | train=0.03528 | val=0.03062\n",
            "Epoch 010/40 | lr=1.65e-04 | train=0.03392 | val=0.03179\n",
            "Epoch 011/40 | lr=1.59e-04 | train=0.03444 | val=0.02942\n",
            "Epoch 012/40 | lr=1.52e-04 | train=0.03244 | val=0.02721\n",
            "Epoch 013/40 | lr=1.45e-04 | train=0.03273 | val=0.02780\n",
            "Epoch 014/40 | lr=1.38e-04 | train=0.03199 | val=0.02691\n",
            "Epoch 015/40 | lr=1.31e-04 | train=0.03187 | val=0.02837\n",
            "Epoch 016/40 | lr=1.23e-04 | train=0.03223 | val=0.02841\n",
            "Epoch 017/40 | lr=1.16e-04 | train=0.03130 | val=0.02713\n",
            "Epoch 018/40 | lr=1.08e-04 | train=0.03127 | val=0.02741\n",
            "Epoch 019/40 | lr=1.00e-04 | train=0.03130 | val=0.02821\n",
            "Epoch 020/40 | lr=9.22e-05 | train=0.03148 | val=0.02774\n",
            "Epoch 021/40 | lr=8.44e-05 | train=0.03024 | val=0.02754\n",
            "Epoch 022/40 | lr=7.67e-05 | train=0.03070 | val=0.02828\n",
            "Epoch 023/40 | lr=6.91e-05 | train=0.03059 | val=0.02781\n",
            "Epoch 024/40 | lr=6.17e-05 | train=0.03084 | val=0.02870\n",
            "Epoch 025/40 | lr=5.46e-05 | train=0.03103 | val=0.03017\n",
            "Epoch 026/40 | lr=4.78e-05 | train=0.03002 | val=0.02873\n",
            "Epoch 027/40 | lr=4.12e-05 | train=0.02925 | val=0.02812\n",
            "Epoch 028/40 | lr=3.51e-05 | train=0.03109 | val=0.03085\n",
            "Epoch 029/40 | lr=2.93e-05 | train=0.03058 | val=0.02948\n",
            "Epoch 030/40 | lr=2.40e-05 | train=0.03018 | val=0.03003\n",
            "Epoch 031/40 | lr=1.91e-05 | train=0.03115 | val=0.03052\n",
            "Epoch 032/40 | lr=1.47e-05 | train=0.03126 | val=0.03055\n",
            "Epoch 033/40 | lr=1.09e-05 | train=0.03175 | val=0.03098\n",
            "Epoch 034/40 | lr=7.61e-06 | train=0.03039 | val=0.02972\n",
            "Epoch 035/40 | lr=4.89e-06 | train=0.03129 | val=0.03105\n",
            "Epoch 036/40 | lr=2.76e-06 | train=0.03065 | val=0.03077\n",
            "Epoch 037/40 | lr=1.23e-06 | train=0.03058 | val=0.03072\n",
            "Epoch 038/40 | lr=3.08e-07 | train=0.03158 | val=0.03169\n",
            "Epoch 039/40 | lr=0.00e+00 | train=0.03132 | val=0.03156\n",
            "  [   1/20] base= 38 ml= 23 gain= 15  dt=    2.3s\n",
            "  [  10/20] base= 48 ml= 30 gain= 18  dt=   35.0s\n",
            "  [  20/20] base= 46 ml= 28 gain= 18  dt=   69.4s\n",
            "[best@n=30] total_gain=392 (n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.005_ep40_wg0.15_log1p)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3ed9df66-9dc3-4254-8b6c-022369d10fcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exp_name</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>target_n</th>\n",
              "      <th>rows_k</th>\n",
              "      <th>model_type</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>use_pos_emb</th>\n",
              "      <th>hd1</th>\n",
              "      <th>hd2</th>\n",
              "      <th>nrd</th>\n",
              "      <th>...</th>\n",
              "      <th>same_cases</th>\n",
              "      <th>worse_cases</th>\n",
              "      <th>avg_gain_when_improved</th>\n",
              "      <th>max_gain</th>\n",
              "      <th>max_gain_id</th>\n",
              "      <th>time_sec_eval</th>\n",
              "      <th>sec_per_sample_eval</th>\n",
              "      <th>mean_baseline_len</th>\n",
              "      <th>mean_ml_len</th>\n",
              "      <th>improved_frac</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...</td>\n",
              "      <td>2026-02-04 18:48:18</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32</td>\n",
              "      <td>False</td>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.6</td>\n",
              "      <td>28</td>\n",
              "      <td>1157</td>\n",
              "      <td>69.792297</td>\n",
              "      <td>3.489615</td>\n",
              "      <td>49.2</td>\n",
              "      <td>29.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...</td>\n",
              "      <td>2026-02-04 18:23:51</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32</td>\n",
              "      <td>False</td>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.6</td>\n",
              "      <td>28</td>\n",
              "      <td>1157</td>\n",
              "      <td>69.195672</td>\n",
              "      <td>3.459784</td>\n",
              "      <td>49.2</td>\n",
              "      <td>29.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...</td>\n",
              "      <td>2026-02-04 19:03:07</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32</td>\n",
              "      <td>False</td>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.5</td>\n",
              "      <td>28</td>\n",
              "      <td>1157</td>\n",
              "      <td>69.276130</td>\n",
              "      <td>3.463806</td>\n",
              "      <td>49.2</td>\n",
              "      <td>29.7</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...</td>\n",
              "      <td>2026-02-04 18:58:12</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32</td>\n",
              "      <td>False</td>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>27</td>\n",
              "      <td>1157</td>\n",
              "      <td>70.756788</td>\n",
              "      <td>3.537839</td>\n",
              "      <td>49.2</td>\n",
              "      <td>29.8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...</td>\n",
              "      <td>2026-02-04 18:28:40</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>EmbMLP</td>\n",
              "      <td>32</td>\n",
              "      <td>False</td>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>27</td>\n",
              "      <td>1157</td>\n",
              "      <td>68.937713</td>\n",
              "      <td>3.446886</td>\n",
              "      <td>49.2</td>\n",
              "      <td>29.8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ed9df66-9dc3-4254-8b6c-022369d10fcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ed9df66-9dc3-4254-8b6c-022369d10fcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ed9df66-9dc3-4254-8b6c-022369d10fcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             exp_name            timestamp  \\\n",
              "34  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...  2026-02-04 18:48:18   \n",
              "29  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...  2026-02-04 18:23:51   \n",
              "37  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...  2026-02-04 19:03:07   \n",
              "36  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...  2026-02-04 18:58:12   \n",
              "30  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...  2026-02-04 18:28:40   \n",
              "\n",
              "    target_n  rows_k model_type  emb_dim  use_pos_emb  hd1  hd2  nrd  ...  \\\n",
              "34        30      20     EmbMLP       32        False  512  256    6  ...   \n",
              "29        30      20     EmbMLP       32        False  512  256    6  ...   \n",
              "37        30      20     EmbMLP       32        False  512  256    6  ...   \n",
              "36        30      20     EmbMLP       32        False  512  256    6  ...   \n",
              "30        30      20     EmbMLP       32        False  512  256    6  ...   \n",
              "\n",
              "    same_cases  worse_cases  avg_gain_when_improved max_gain  max_gain_id  \\\n",
              "34           0            0                    19.6       28         1157   \n",
              "29           0            0                    19.6       28         1157   \n",
              "37           0            0                    19.5       28         1157   \n",
              "36           0            0                    19.4       27         1157   \n",
              "30           0            0                    19.4       27         1157   \n",
              "\n",
              "    time_sec_eval  sec_per_sample_eval  mean_baseline_len  mean_ml_len  \\\n",
              "34      69.792297             3.489615               49.2         29.6   \n",
              "29      69.195672             3.459784               49.2         29.6   \n",
              "37      69.276130             3.463806               49.2         29.7   \n",
              "36      70.756788             3.537839               49.2         29.8   \n",
              "30      68.937713             3.446886               49.2         29.8   \n",
              "\n",
              "    improved_frac  \n",
              "34            1.0  \n",
              "29            1.0  \n",
              "37            1.0  \n",
              "36            1.0  \n",
              "30            1.0  \n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEADER_ARCH = dict(\n",
        "    model_type=\"EmbMLP\",\n",
        "    emb_dim=32,\n",
        "    use_pos_emb=False,\n",
        "    hd1=512, hd2=256, nrd=6,\n",
        "    dropout_rate=0.1,\n",
        ")\n",
        "\n",
        "TRAIN_BASE = dict(\n",
        "    rw_mode=\"mix\",\n",
        "    nbt_history_depth=1,\n",
        "    k=4,\n",
        "    rw_length_add=30,\n",
        "\n",
        "    y_transform=\"log1p\",\n",
        "    loss_beta=1.0,\n",
        "    grad_clip=1.0,\n",
        "\n",
        "    batch_size=1024,\n",
        "    val_ratio=0.15,\n",
        "\n",
        "    stratify_clip=60,\n",
        "    stratify_bin_size=1.0,\n",
        "\n",
        "    sanity_width=1200,\n",
        "    h_batch_size=8192,\n",
        "    eval_log_every=10,\n",
        "\n",
        "    seed=123,\n",
        ")\n",
        "\n",
        "rw_width_grid    = [2000, 3000, 5000]\n",
        "mix_frac_grid    = [0.15, 0.30, 0.50]\n",
        "lr_grid          = [1e-4, 2e-4]\n",
        "weight_decay_grid= [5e-3, 1e-2]\n",
        "\n",
        "epochs_grid      = [40]\n",
        "model_grid = []\n",
        "for rw, mf, lr, wd, ep in product(rw_width_grid, mix_frac_grid, lr_grid, weight_decay_grid, epochs_grid):\n",
        "    cfg = {}\n",
        "    cfg.update(LEADER_ARCH)\n",
        "    cfg.update(TRAIN_BASE)\n",
        "    cfg.update(dict(\n",
        "        rw_width=int(rw),\n",
        "        mix_bfs_frac=float(mf),\n",
        "        lr=float(lr),\n",
        "        weight_decay=float(wd),\n",
        "        num_epochs=int(ep),\n",
        "    ))\n",
        "    model_grid.append(cfg)\n",
        "\n",
        "print(\"Total training configs:\", len(model_grid))\n",
        "\n",
        "BEAM_BW = 256\n",
        "BEAM_DEPTH = 192\n",
        "BEAM_W = 0.5\n",
        "N_LIST = [30]\n",
        "ROWS_K = 20\n",
        "ROWS_SEED = 42\n",
        "\n",
        "OUT_JSON_DIR = \"leader_tune/json\"\n",
        "RESULTS_CSV  = \"leader_tune/results_train.csv\"\n",
        "\n",
        "df_train = run_sweep_n_list(\n",
        "    test_df=test_df,\n",
        "    n_list=N_LIST,\n",
        "    rows_k=ROWS_K,\n",
        "    rows_seed=ROWS_SEED,\n",
        "    model_grid=model_grid,\n",
        "    w_gap=0.15,\n",
        "    gap_mode=\"log1p\",\n",
        "    results_csv=RESULTS_CSV,\n",
        "    out_json_dir=OUT_JSON_DIR,\n",
        "    device=None,   # auto cuda/cpu\n",
        "    beam_width=BEAM_BW,\n",
        "    depth=BEAM_DEPTH,\n",
        "    w=BEAM_W,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHg5MfjnNRQE"
      },
      "source": [
        "При фиксированной архитектуре EmbMLP (emb_dim=32, nrd=6) наибольшее влияние на качество эвристики оказывают параметры генерации обучающих данных.\n",
        "Увеличение ширины случайных обходов улучшает итоговый выигрыш.\n",
        "\n",
        "Оптимальным оказался режим смешивания BFS и NBT с долей BFS около 30%, а также более агрессивные параметры оптимизации (lr=2e-4, weight decay=1e-2).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lLK6KEtpzDvf",
        "outputId": "f48aba99-f65c-420d-ac98-17f5e5ad8a04"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(best_per_n[[\\\"total_gain\\\",\\\"exp_name\\\",\\\"rw_width\\\", \\\"lr\\\",\\\"weight_decay\\\",\\\"mix_bfs_frac\\\",\\\"sanity_corr\\\",\\\"train_time_sec\\\",\\\"time_sec_eval\\\"]])\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"total_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 332,\n        \"max\": 392,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          382,\n          375,\n          381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0001_wd0.005_ep40_wg0.15_log1p\",\n          \"n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0001_wd0.01_ep40_wg0.15_log1p\",\n          \"n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0002_wd0.01_ep40_wg0.15_log1p\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rw_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1266,\n        \"min\": 2000,\n        \"max\": 5000,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5000,\n          3000,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.063696835418334e-05,\n        \"min\": 0.0001,\n        \"max\": 0.0002,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0001,\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025318484177091678,\n        \"min\": 0.005,\n        \"max\": 0.01,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.005,\n          0.01\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mix_bfs_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14662188004694943,\n        \"min\": 0.15,\n        \"max\": 0.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3,\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sanity_corr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004946575428336908,\n        \"min\": 0.9420850534039964,\n        \"max\": 0.9584884616703188,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.9434993101305762,\n          0.9420850534039964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.81862692100651,\n        \"min\": 96.351571559906,\n        \"max\": 266.65034437179565,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          98.44443154335022,\n          96.81210803985596\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_sec_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5702835142663374,\n        \"min\": 66.74521613121033,\n        \"max\": 73.2407660484314,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          70.87382483482361,\n          72.2129852771759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-777efed4-4b60-495d-9077-54e582dcd164\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_gain</th>\n",
              "      <th>exp_name</th>\n",
              "      <th>rw_width</th>\n",
              "      <th>lr</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>mix_bfs_frac</th>\n",
              "      <th>sanity_corr</th>\n",
              "      <th>train_time_sec</th>\n",
              "      <th>time_sec_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>392</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.955797</td>\n",
              "      <td>225.533947</td>\n",
              "      <td>69.792297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>392</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.949510</td>\n",
              "      <td>223.916882</td>\n",
              "      <td>69.195672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>390</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.958488</td>\n",
              "      <td>225.368810</td>\n",
              "      <td>69.276130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>388</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.958075</td>\n",
              "      <td>224.477674</td>\n",
              "      <td>70.756788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>388</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.950487</td>\n",
              "      <td>219.868918</td>\n",
              "      <td>68.937713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>387</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.958318</td>\n",
              "      <td>222.863929</td>\n",
              "      <td>69.362046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>386</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.955731</td>\n",
              "      <td>143.221617</td>\n",
              "      <td>70.109416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>386</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.955653</td>\n",
              "      <td>142.869051</td>\n",
              "      <td>69.949446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>386</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.954151</td>\n",
              "      <td>140.495360</td>\n",
              "      <td>69.854921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>385</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.958345</td>\n",
              "      <td>226.512267</td>\n",
              "      <td>70.597412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>385</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.956773</td>\n",
              "      <td>142.427863</td>\n",
              "      <td>71.460593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>385</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.955439</td>\n",
              "      <td>223.828448</td>\n",
              "      <td>70.559920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>385</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.954951</td>\n",
              "      <td>240.620785</td>\n",
              "      <td>66.745216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>384</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.954412</td>\n",
              "      <td>142.406991</td>\n",
              "      <td>72.203826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>384</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.954342</td>\n",
              "      <td>223.082573</td>\n",
              "      <td>70.154971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>384</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.948737</td>\n",
              "      <td>223.408644</td>\n",
              "      <td>70.333268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>383</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.955412</td>\n",
              "      <td>222.420219</td>\n",
              "      <td>70.220215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>382</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.956410</td>\n",
              "      <td>266.650344</td>\n",
              "      <td>67.317574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>382</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.956195</td>\n",
              "      <td>261.262161</td>\n",
              "      <td>67.222188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>381</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.955647</td>\n",
              "      <td>140.878021</td>\n",
              "      <td>70.271837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>380</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.948891</td>\n",
              "      <td>97.944359</td>\n",
              "      <td>69.646181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>379</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.948211</td>\n",
              "      <td>222.678590</td>\n",
              "      <td>70.327513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>377</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.953344</td>\n",
              "      <td>143.804133</td>\n",
              "      <td>71.310156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>375</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.953038</td>\n",
              "      <td>141.962792</td>\n",
              "      <td>70.859987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>375</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.946437</td>\n",
              "      <td>96.351572</td>\n",
              "      <td>67.844867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>373</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.952868</td>\n",
              "      <td>140.480612</td>\n",
              "      <td>71.912912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>372</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.953710</td>\n",
              "      <td>143.186393</td>\n",
              "      <td>72.778827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>371</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.952453</td>\n",
              "      <td>142.767457</td>\n",
              "      <td>72.232244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>371</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.946298</td>\n",
              "      <td>96.982626</td>\n",
              "      <td>68.604952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>370</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.947512</td>\n",
              "      <td>98.060155</td>\n",
              "      <td>70.452921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>369</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.952311</td>\n",
              "      <td>143.271553</td>\n",
              "      <td>72.070110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>365</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.947999</td>\n",
              "      <td>98.261933</td>\n",
              "      <td>69.583323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>357</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.947503</td>\n",
              "      <td>98.302942</td>\n",
              "      <td>71.021186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>355</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.943499</td>\n",
              "      <td>98.444432</td>\n",
              "      <td>70.873825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>347</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.945068</td>\n",
              "      <td>97.349261</td>\n",
              "      <td>71.023747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>346</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.943173</td>\n",
              "      <td>99.001317</td>\n",
              "      <td>73.240766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>339</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.942085</td>\n",
              "      <td>96.812108</td>\n",
              "      <td>72.212985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>338</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.944616</td>\n",
              "      <td>97.195984</td>\n",
              "      <td>72.432586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332</td>\n",
              "      <td>n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.942430</td>\n",
              "      <td>96.873495</td>\n",
              "      <td>72.961329</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-777efed4-4b60-495d-9077-54e582dcd164')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-777efed4-4b60-495d-9077-54e582dcd164 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-777efed4-4b60-495d-9077-54e582dcd164');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    total_gain                                           exp_name  rw_width  \\\n",
              "34         392  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...      5000   \n",
              "29         392  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...      5000   \n",
              "37         390  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...      5000   \n",
              "36         388  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...      5000   \n",
              "30         388  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...      5000   \n",
              "38         387  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...      5000   \n",
              "22         386  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...      3000   \n",
              "26         386  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...      3000   \n",
              "17         386  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...      3000   \n",
              "35         385  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.50_lr0.0...      5000   \n",
              "21         385  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...      3000   \n",
              "33         385  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...      5000   \n",
              "2          385  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "18         384  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...      3000   \n",
              "32         384  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...      5000   \n",
              "27         384  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...      5000   \n",
              "31         383  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.30_lr0.0...      5000   \n",
              "0          382  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "1          382  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "25         381  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...      3000   \n",
              "14         380  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...      2000   \n",
              "28         379  n30_EmbMLP_ed32_pos0_nrd6_rw5000_mix0.15_lr0.0...      5000   \n",
              "19         377  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...      3000   \n",
              "15         375  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...      3000   \n",
              "5          375  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "16         373  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.15_lr0.0...      3000   \n",
              "20         372  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.30_lr0.0...      3000   \n",
              "23         371  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...      3000   \n",
              "6          371  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "13         370  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...      2000   \n",
              "24         369  n30_EmbMLP_ed32_pos0_nrd6_rw3000_mix0.50_lr0.0...      3000   \n",
              "9          365  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...      2000   \n",
              "10         357  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...      2000   \n",
              "11         355  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...      2000   \n",
              "8          347  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...      2000   \n",
              "12         346  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.50_lr0.0...      2000   \n",
              "4          339  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "7          338  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.30_lr0.0...      2000   \n",
              "3          332  n30_EmbMLP_ed32_pos0_nrd6_rw2000_mix0.15_lr0.0...      2000   \n",
              "\n",
              "        lr  weight_decay  mix_bfs_frac  sanity_corr  train_time_sec  \\\n",
              "34  0.0002         0.010          0.30     0.955797      225.533947   \n",
              "29  0.0002         0.005          0.15     0.949510      223.916882   \n",
              "37  0.0002         0.005          0.50     0.958488      225.368810   \n",
              "36  0.0001         0.010          0.50     0.958075      224.477674   \n",
              "30  0.0002         0.010          0.15     0.950487      219.868918   \n",
              "38  0.0002         0.010          0.50     0.958318      222.863929   \n",
              "22  0.0002         0.010          0.30     0.955731      143.221617   \n",
              "26  0.0002         0.010          0.50     0.955653      142.869051   \n",
              "17  0.0002         0.005          0.15     0.954151      140.495360   \n",
              "35  0.0001         0.005          0.50     0.958345      226.512267   \n",
              "21  0.0002         0.005          0.30     0.956773      142.427863   \n",
              "33  0.0002         0.005          0.30     0.955439      223.828448   \n",
              "2   0.0002         0.005          0.15     0.954951      240.620785   \n",
              "18  0.0002         0.010          0.15     0.954412      142.406991   \n",
              "32  0.0001         0.010          0.30     0.954342      223.082573   \n",
              "27  0.0001         0.005          0.15     0.948737      223.408644   \n",
              "31  0.0001         0.005          0.30     0.955412      222.420219   \n",
              "0   0.0001         0.005          0.15     0.956410      266.650344   \n",
              "1   0.0001         0.010          0.15     0.956195      261.262161   \n",
              "25  0.0002         0.005          0.50     0.955647      140.878021   \n",
              "14  0.0002         0.010          0.50     0.948891       97.944359   \n",
              "28  0.0001         0.010          0.15     0.948211      222.678590   \n",
              "19  0.0001         0.005          0.30     0.953344      143.804133   \n",
              "15  0.0001         0.005          0.15     0.953038      141.962792   \n",
              "5   0.0002         0.005          0.15     0.946437       96.351572   \n",
              "16  0.0001         0.010          0.15     0.952868      140.480612   \n",
              "20  0.0001         0.010          0.30     0.953710      143.186393   \n",
              "23  0.0001         0.005          0.50     0.952453      142.767457   \n",
              "6   0.0002         0.010          0.15     0.946298       96.982626   \n",
              "13  0.0002         0.005          0.50     0.947512       98.060155   \n",
              "24  0.0001         0.010          0.50     0.952311      143.271553   \n",
              "9   0.0002         0.005          0.30     0.947999       98.261933   \n",
              "10  0.0002         0.010          0.30     0.947503       98.302942   \n",
              "11  0.0001         0.005          0.50     0.943499       98.444432   \n",
              "8   0.0001         0.010          0.30     0.945068       97.349261   \n",
              "12  0.0001         0.010          0.50     0.943173       99.001317   \n",
              "4   0.0001         0.010          0.15     0.942085       96.812108   \n",
              "7   0.0001         0.005          0.30     0.944616       97.195984   \n",
              "3   0.0001         0.005          0.15     0.942430       96.873495   \n",
              "\n",
              "    time_sec_eval  \n",
              "34      69.792297  \n",
              "29      69.195672  \n",
              "37      69.276130  \n",
              "36      70.756788  \n",
              "30      68.937713  \n",
              "38      69.362046  \n",
              "22      70.109416  \n",
              "26      69.949446  \n",
              "17      69.854921  \n",
              "35      70.597412  \n",
              "21      71.460593  \n",
              "33      70.559920  \n",
              "2       66.745216  \n",
              "18      72.203826  \n",
              "32      70.154971  \n",
              "27      70.333268  \n",
              "31      70.220215  \n",
              "0       67.317574  \n",
              "1       67.222188  \n",
              "25      70.271837  \n",
              "14      69.646181  \n",
              "28      70.327513  \n",
              "19      71.310156  \n",
              "15      70.859987  \n",
              "5       67.844867  \n",
              "16      71.912912  \n",
              "20      72.778827  \n",
              "23      72.232244  \n",
              "6       68.604952  \n",
              "13      70.452921  \n",
              "24      72.070110  \n",
              "9       69.583323  \n",
              "10      71.021186  \n",
              "11      70.873825  \n",
              "8       71.023747  \n",
              "12      73.240766  \n",
              "4       72.212985  \n",
              "7       72.432586  \n",
              "3       72.961329  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_gain = (\n",
        "    df_train.sort_values([\"total_gain\",\"sanity_corr\"], ascending=[True,False,False]).groupby(\"total_gain\").head(39)\n",
        ")\n",
        "display(best_gain[[\"total_gain\",\"exp_name\",\"rw_width\", \"lr\",\"weight_decay\",\"mix_bfs_frac\",\"sanity_corr\",\"train_time_sec\",\"time_sec_eval\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx9JIZmBOvuc"
      },
      "source": [
        "Рассчитаем и сохраним базовое решение(baseline) для всех тестовых перестановок, а также реализуем механизм продолжения работы через файл прогресса. Если прогресс уже существует, код подхватывает ранее посчитанные ответы и не пересчитывает их заново. Если прогресса нет, строится baseline_map для всех id в test_df и сохраняется на диск, чтобы дальше отталкиваться от него при улучшениях."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-01T07:43:40.890381Z",
          "iopub.status.busy": "2026-02-01T07:43:40.889612Z",
          "iopub.status.idle": "2026-02-01T07:43:41.176949Z",
          "shell.execute_reply": "2026-02-01T07:43:41.176237Z",
          "shell.execute_reply.started": "2026-02-01T07:43:40.890337Z"
        },
        "id": "4ATj2rofJtw8",
        "outputId": "d4f9b91f-568c-46e4-e7e5-ac70eed3d20e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No progress, start fresh.\n",
            "  baseline [2000/2405] dt=0.1s\n",
            "  baseline [2405/2405] dt=0.2s\n",
            "Saved baseline: /content/drive/MyDrive/pancake_runs/baseline_submission.csv\n"
          ]
        }
      ],
      "source": [
        "baseline_moves_fn = pancake_sort_moves\n",
        "\n",
        "def _save_progress(progress_map: dict, path: str):\n",
        "    df = pd.DataFrame(list(progress_map.items()), columns=[\"id\", \"solution\"]).sort_values(\"id\")\n",
        "    df.to_csv(path, index=False)\n",
        "if os.path.exists(PROGRESS_PATH):\n",
        "    prog_df = pd.read_csv(PROGRESS_PATH)\n",
        "    progress_map = dict(zip(prog_df[\"id\"].astype(int).values, prog_df[\"solution\"].values))\n",
        "    print(\"Resume progress:\", len(progress_map))\n",
        "else:\n",
        "    progress_map = {}\n",
        "    print(\"No progress, start fresh.\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    baseline_map = {}\n",
        "    for i in range(len(test_df)):\n",
        "        pid = int(test_df.loc[i, \"id\"])\n",
        "        perm = parse_permutation(test_df.loc[i, \"permutation\"])\n",
        "        moves = baseline_moves_fn(perm)\n",
        "        baseline_map[pid] = moves_to_str(moves)\n",
        "        if (i + 1) % 2000 == 0 or (i + 1) == len(test_df):\n",
        "            print(f\"  baseline [{i+1}/{len(test_df)}] dt={time.time()-t0:.1f}s\", flush=True)\n",
        "    _save_progress(baseline_map, BASELINE_PATH)\n",
        "    print(\"Saved baseline:\", BASELINE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WEQzItCPMpe"
      },
      "source": [
        "Зафиксируем \"финальную\" конфигурацию пайплайна: параметры beam search и параметры обучения/использования ML-эвристики, выбранные по результатам тюнинга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:44:15.913548Z",
          "iopub.status.busy": "2026-02-01T07:44:15.91326Z",
          "iopub.status.idle": "2026-02-01T07:44:15.918615Z",
          "shell.execute_reply": "2026-02-01T07:44:15.918057Z",
          "shell.execute_reply.started": "2026-02-01T07:44:15.913525Z"
        },
        "id": "weNdFXrJJtw8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "BEAM_WIDTH = 256\n",
        "DEPTH = 192\n",
        "W = 0.5\n",
        "W_GAP = 0.15\n",
        "GAP_MODE = \"log1p\"\n",
        "H_BATCH = 8192\n",
        "\n",
        "LEADER_CFG = dict(\n",
        "    model_type=\"EmbMLP\",\n",
        "    emb_dim=32,\n",
        "    use_pos_emb=False,\n",
        "    hd1=512, hd2=256, nrd=6, dropout_rate=0.1,\n",
        "\n",
        "    rw_width=5000,\n",
        "    rw_mode=\"mix\",\n",
        "    mix_bfs_frac=0.30,\n",
        "    nbt_history_depth=1,\n",
        "\n",
        "    lr=2e-4,\n",
        "    weight_decay=1e-2,\n",
        "    batch_size=1024,\n",
        "    val_ratio=0.15,\n",
        "    num_epochs=30,\n",
        "\n",
        "    y_transform=\"log1p\",\n",
        "    grad_clip=1.0,\n",
        "    loss_beta=1.0,\n",
        "\n",
        "    sanity_width=2000,\n",
        "    h_batch_size=H_BATCH,\n",
        "    eval_log_every=200,\n",
        "    seed=123,\n",
        "\n",
        "    stratify_clip=60,\n",
        "    stratify_bin_size=1.0,\n",
        "    k=4,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzdZMU0VP5Z4"
      },
      "source": [
        "Реализуем финальный прогон: для каждого размера n из списка мы обучаем отдельную ML-эвристику на соответствующем pancake-графе, затем применяем её к всем тестовым кейсам этого размера и улучшаем baseline-решение через beam search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-01T07:51:36.528798Z",
          "iopub.status.busy": "2026-02-01T07:51:36.528496Z"
        },
        "id": "SIUchWjpJtw9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "flush_every = 200\n",
        "t_global = time.time()\n",
        "\n",
        "done_cnt = 0\n",
        "improved_cnt = 0\n",
        "\n",
        "for n in n_list:\n",
        "    print(\"\\n========== TARGET n =\", n, \"==========\", flush=True)\n",
        "\n",
        "    graph = build_pancake_graph(n, device=device)\n",
        "    CFG = dict(LEADER_CFG)\n",
        "    CFG[\"n\"] = n\n",
        "    CFG[\"num_classes\"] = n\n",
        "    CFG[\"state_size\"] = n\n",
        "\n",
        "    k = int(CFG.get(\"k\", 4))\n",
        "    rw_length_add = int(CFG.get(\"rw_length_add\", 30))\n",
        "    CFG[\"rw_length\"] = n * (n + 5) // (4 * (k - 1)) + rw_length_add\n",
        "\n",
        "    model = get_model(CFG).to(graph.device)\n",
        "\n",
        "    print(f\"[{now_str()}] train model for n={n} | epochs={CFG['num_epochs']} rw_width={CFG['rw_width']} mix={CFG['mix_bfs_frac']}\", flush=True)\n",
        "    t_train0 = time.time()\n",
        "    train_model_gpu(CFG, model, graph)\n",
        "    print(f\"train_time={time.time()-t_train0:.1f}s\", flush=True)\n",
        "\n",
        "    h_ml = MLHeuristic(model, device=graph.device, batch_size=H_BATCH)\n",
        "\n",
        "    sub = test_df[test_df[\"n\"] == n][[\"id\", \"permutation\"]].reset_index(drop=True)\n",
        "    total_n = len(sub)\n",
        "    print(\"cases:\", total_n, flush=True)\n",
        "\n",
        "    t0 = time.time()\n",
        "    for i in range(total_n):\n",
        "        pid = int(sub.loc[i, \"id\"])\n",
        "        base_str = baseline_map.get(pid, \"\")\n",
        "        if base_str == \"\":\n",
        "            perm0 = parse_permutation(sub.loc[i, \"permutation\"])\n",
        "            base_str = moves_to_str(baseline_moves_fn(perm0))\n",
        "            baseline_map[pid] = base_str\n",
        "\n",
        "        perm = parse_permutation(sub.loc[i, \"permutation\"])\n",
        "\n",
        "        base_len = moves_len(base_str)\n",
        "\n",
        "        moves = beam_improve_with_ml(\n",
        "            perm,\n",
        "            h_fn=h_ml,\n",
        "            baseline_moves_fn=baseline_moves_fn,\n",
        "            beam_width=BEAM_WIDTH,\n",
        "            depth=DEPTH,\n",
        "            w=W,\n",
        "            w_gap=W_GAP,\n",
        "            gap_mode=GAP_MODE,\n",
        "            patience=None\n",
        "        )\n",
        "        new_str = moves_to_str(moves)\n",
        "        new_len = len(moves)\n",
        "\n",
        "        if new_len < base_len:\n",
        "            progress_map[pid] = new_str\n",
        "            improved_cnt += 1\n",
        "        else:\n",
        "            progress_map[pid] = base_str\n",
        "\n",
        "        done_cnt += 1\n",
        "\n",
        "        if (i + 1) % flush_every == 0 or (i + 1) == total_n:\n",
        "            _save_progress(progress_map, PROGRESS_PATH)\n",
        "            dt = time.time() - t0\n",
        "            print(f\"  [{i+1:5d}/{total_n}] improved={improved_cnt} done_total={done_cnt} \"\n",
        "                  f\"dt_n={dt:6.1f}s dt_all={time.time()-t_global:7.1f}s\", flush=True)\n",
        "    try:\n",
        "        graph.free_memory()\n",
        "    except Exception:\n",
        "        pass\n",
        "    del model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "final_df = pd.DataFrame(list(progress_map.items()), columns=[\"id\", \"solution\"]).sort_values(\"id\").reset_index(drop=True)\n",
        "final_df.to_csv(FINAL_PATH, index=False)\n",
        "print(\"\\nSaved:\", FINAL_PATH, \"rows=\", len(final_df))\n",
        "print(\"Progress saved:\", PROGRESS_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wobXhdBlTKc7"
      },
      "source": [
        "Для задач малого и среднего размера (n < 75) beam search с обученной ML-эвристикой достигает того же качества решений, что и beam search с простой gap-эвристикой. На больших n поиск не увенчался успехом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_igXWNNQjNz",
        "outputId": "facd3e93-854d-459e-bd12-4dc30cee7411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   1/2405] base=  2 sub=  2 gain=  0  elapsed=    0.0s\n",
            "[  50/2405] base= 19 sub=  8 gain= 11  elapsed=    0.0s\n",
            "[ 100/2405] base= 20 sub= 12 gain=  8  elapsed=    0.0s\n",
            "[ 150/2405] base= 16 sub= 11 gain=  5  elapsed=    0.0s\n",
            "[ 200/2405] base= 15 sub= 11 gain=  4  elapsed=    0.0s\n",
            "[ 250/2405] base= 19 sub= 15 gain=  4  elapsed=    0.0s\n",
            "[ 300/2405] base= 20 sub= 14 gain=  6  elapsed=    0.0s\n",
            "[ 350/2405] base= 20 sub= 15 gain=  5  elapsed=    0.0s\n",
            "[ 400/2405] base= 21 sub= 14 gain=  7  elapsed=    0.0s\n",
            "[ 450/2405] base= 21 sub= 13 gain=  8  elapsed=    0.0s\n",
            "[ 500/2405] base= 25 sub= 15 gain= 10  elapsed=    0.0s\n",
            "[ 550/2405] base= 25 sub= 15 gain= 10  elapsed=    0.0s\n",
            "[ 600/2405] base= 21 sub= 12 gain=  9  elapsed=    0.0s\n",
            "[ 650/2405] base= 32 sub= 20 gain= 12  elapsed=    0.0s\n",
            "[ 700/2405] base= 34 sub= 19 gain= 15  elapsed=    0.0s\n",
            "[ 750/2405] base= 32 sub= 19 gain= 13  elapsed=    0.0s\n",
            "[ 800/2405] base= 33 sub= 19 gain= 14  elapsed=    0.0s\n",
            "[ 850/2405] base= 42 sub= 24 gain= 18  elapsed=    0.0s\n",
            "[ 900/2405] base= 38 sub= 24 gain= 14  elapsed=    0.0s\n",
            "[ 950/2405] base= 45 sub= 26 gain= 19  elapsed=    0.0s\n",
            "[1000/2405] base= 43 sub= 24 gain= 19  elapsed=    0.1s\n",
            "[1050/2405] base= 49 sub= 32 gain= 17  elapsed=    0.1s\n",
            "[1100/2405] base= 47 sub= 30 gain= 17  elapsed=    0.1s\n",
            "[1150/2405] base= 53 sub= 31 gain= 22  elapsed=    0.1s\n",
            "[1200/2405] base= 50 sub= 29 gain= 21  elapsed=    0.1s\n",
            "[1250/2405] base= 57 sub= 39 gain= 18  elapsed=    0.1s\n",
            "[1300/2405] base= 55 sub= 36 gain= 19  elapsed=    0.1s\n",
            "[1350/2405] base= 59 sub= 36 gain= 23  elapsed=    0.1s\n",
            "[1400/2405] base= 58 sub= 34 gain= 24  elapsed=    0.1s\n",
            "[1450/2405] base= 66 sub= 44 gain= 22  elapsed=    0.1s\n",
            "[1500/2405] base= 68 sub= 46 gain= 22  elapsed=    0.1s\n",
            "[1550/2405] base= 70 sub= 45 gain= 25  elapsed=    0.1s\n",
            "[1600/2405] base= 61 sub= 42 gain= 19  elapsed=    0.1s\n",
            "[1650/2405] base= 73 sub= 48 gain= 25  elapsed=    0.1s\n",
            "[1700/2405] base= 80 sub= 55 gain= 25  elapsed=    0.1s\n",
            "[1750/2405] base= 79 sub= 53 gain= 26  elapsed=    0.1s\n",
            "[1800/2405] base= 71 sub= 53 gain= 18  elapsed=    0.1s\n",
            "[1850/2405] base= 86 sub= 63 gain= 23  elapsed=    0.1s\n",
            "[1900/2405] base= 89 sub= 68 gain= 21  elapsed=    0.2s\n",
            "[1950/2405] base= 87 sub= 63 gain= 24  elapsed=    0.2s\n",
            "[2000/2405] base= 91 sub= 57 gain= 34  elapsed=    0.2s\n",
            "[2050/2405] base=134 sub=134 gain=  0  elapsed=    0.2s\n",
            "[2100/2405] base=136 sub=136 gain=  0  elapsed=    0.2s\n",
            "[2150/2405] base=128 sub=128 gain=  0  elapsed=    0.2s\n",
            "[2200/2405] base=137 sub=137 gain=  0  elapsed=    0.2s\n",
            "[2250/2405] base=187 sub=  0 gain=187  elapsed=    0.2s\n",
            "[2300/2405] base=186 sub=  0 gain=186  elapsed=    0.3s\n",
            "[2350/2405] base=185 sub=  0 gain=185  elapsed=    0.3s\n",
            "[2400/2405] base=189 sub=  0 gain=189  elapsed=    0.3s\n",
            "[2405/2405] base=188 sub=  0 gain=188  elapsed=    0.3s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'baseline_total': 158680,\n",
              " 'submission_total': 89252,\n",
              " 'total_gain': 69428,\n",
              " 'improved_cases': 2213,\n",
              " 'same_cases': 192,\n",
              " 'worse_cases': 0,\n",
              " 'avg_gain_when_improved': 31.372797107998192,\n",
              " 'max_gain': 195,\n",
              " 'max_gain_id': 2210,\n",
              " 'time_sec': 0.3336763381958008,\n",
              " 'sec_per_sample': 0.00013874276016457413,\n",
              " 'mean_baseline_len': 65.97920997920998,\n",
              " 'mean_submission_len': 37.11101871101871,\n",
              " 'improved_frac': 0.9201663201663202}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stats = evaluate_submission_vs_baseline(\n",
        "    test_df=test_df,\n",
        "    submission_df=final_df,\n",
        "    baseline_moves_fn=pancake_sort_moves,\n",
        "    log_every=50,\n",
        "    save_detailed_path=\"sub_vs_base_details.csv\",\n",
        ")\n",
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kttcbs2UH3U"
      },
      "source": [
        "Создадим функцию, объединяющую несколько сабмитов, как полных, так и частичных (где решения есть только для части id), в один финальный файл.\n",
        "\n",
        "Сначала выбираем base-файл, затем поверх него применяем partial-файлы, заменяя решение только если оно короче. В конце сохраняем merged submission и печатаем сводку, включая итоговый score (сумму длин) и распределение \"победителей\" по источникам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T00:18:35.488891Z",
          "iopub.status.busy": "2026-01-27T00:18:35.487926Z",
          "iopub.status.idle": "2026-01-27T00:18:35.509288Z",
          "shell.execute_reply": "2026-01-27T00:18:35.507697Z",
          "shell.execute_reply.started": "2026-01-27T00:18:35.488853Z"
        },
        "id": "YEYwNgUxGo8s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "\n",
        "\n",
        "def merge_submissions_with_partials(\n",
        "    *,\n",
        "    base_paths: List[str],\n",
        "    partial_paths: List[str],\n",
        "    out_path: str = \"submission_final.csv\",\n",
        "    save_source_column: bool = True,\n",
        "    tie_break: str = \"keep_base\",\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    base_subs: List[pd.DataFrame] = []\n",
        "    for p in base_paths:\n",
        "        df = pd.read_csv(p)\n",
        "        assert {\"id\", \"solution\"}.issubset(df.columns), f\"{p} must have columns: id, solution\"\n",
        "        df = df[[\"id\", \"solution\"]].copy()\n",
        "        df[\"id\"] = df[\"id\"].astype(int)\n",
        "        df = df.sort_values(\"id\").reset_index(drop=True)\n",
        "        df[\"len\"] = df[\"solution\"].map(moves_len)\n",
        "        df[\"source\"] = str(\"baseline\")\n",
        "        base_subs.append(df)\n",
        "\n",
        "    base_ids = base_subs[0][\"id\"].values\n",
        "    for i, df in enumerate(base_subs[1:], start=1):\n",
        "        if len(df) != len(base_subs[0]) or not np.array_equal(df[\"id\"].values, base_ids):\n",
        "            raise ValueError(f\"ID mismatch between {base_paths[0]} and {base_paths[i]}\")\n",
        "\n",
        "    best = base_subs[0][[\"id\", \"solution\", \"len\", \"source\"]].copy()\n",
        "    for df in base_subs[1:]:\n",
        "        better = df[\"len\"].values < best[\"len\"].values\n",
        "        best.loc[better, \"solution\"] = df.loc[better, \"solution\"].values\n",
        "        best.loc[better, \"len\"] = df.loc[better, \"len\"].values\n",
        "        best.loc[better, \"source\"] = df.loc[better, \"source\"].values\n",
        "\n",
        "    best[\"source\"] = best[\"source\"].astype(str)\n",
        "\n",
        "    id_to_idx: Dict[int, int] = {int(pid): i for i, pid in enumerate(best[\"id\"].values)}\n",
        "\n",
        "    applied_stats = []\n",
        "    for p in partial_paths:\n",
        "        if not Path(p).exists():\n",
        "            print(f\"[WARN] partial not found, skipped: {p}\")\n",
        "            continue\n",
        "\n",
        "        part = pd.read_csv(p)\n",
        "        assert {\"id\", \"solution\"}.issubset(part.columns), f\"{p} must have columns: id, solution\"\n",
        "        part = part[[\"id\", \"solution\"]].copy()\n",
        "        part[\"id\"] = part[\"id\"].astype(int)\n",
        "        part[\"len\"] = part[\"solution\"].map(moves_len)\n",
        "\n",
        "        replaced = 0\n",
        "        missing = 0\n",
        "        stem = Path(p).stem\n",
        "        src_tag = stem.replace(\"submission_\", \"\")\n",
        "\n",
        "        for pid, sol, l in part.itertuples(index=False):\n",
        "            idx = id_to_idx.get(int(pid))\n",
        "            if idx is None:\n",
        "                missing += 1\n",
        "                continue\n",
        "\n",
        "            cur_len = int(best.at[idx, \"len\"])\n",
        "            if l < cur_len or (tie_break == \"prefer_partial\" and l == cur_len and sol != best.at[idx, \"solution\"]):\n",
        "                best.at[idx, \"solution\"] = sol\n",
        "                best.at[idx, \"len\"] = int(l)\n",
        "                best.at[idx, \"source\"] = src_tag\n",
        "                replaced += 1\n",
        "\n",
        "        applied_stats.append((str(p), replaced, missing, len(part)))\n",
        "\n",
        "    out_df = best[[\"id\", \"solution\"]].copy()\n",
        "    if save_source_column:\n",
        "        out_df[\"source\"] = best[\"source\"].copy()\n",
        "\n",
        "    out_df.to_csv(out_path, index=False)\n",
        "\n",
        "    total_moves = int(best[\"len\"].sum())\n",
        "    print(\"\\n=== MERGE SUMMARY ===\")\n",
        "    print(\"Output:\", out_path)\n",
        "    print(\"Rows:\", len(out_df))\n",
        "    print(\"Total moves (score):\", total_moves)\n",
        "\n",
        "    if save_source_column:\n",
        "        print(\"\\nFinal winners by source tag (top):\")\n",
        "        display(out_df[\"source\"].value_counts().head(20))\n",
        "\n",
        "    print(\"\\nSaved:\", out_path)\n",
        "    display(out_df.head(10))\n",
        "    return out_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86Wy_SrYVpPU"
      },
      "source": [
        "В качестве главного сабмита используется один baseline-файл, и он служит опорной точкой, от которой мы будем отталкиваться при улучшениях.\n",
        "\n",
        "В качестве дополнительных используем результат beam search с gap-эвристикой и результат ML-эвристики, сохранённый по ходу прогресса. Эти файлы не обязаны покрывать весь датасет и применяются поверх baseline только там, где они действительно улучшают решение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "xUqMOkkDRY_U",
        "outputId": "d3f73243-ccc9-4d96-be41-c2719720a49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MERGE SUMMARY ===\n",
            "Output: submission_final.csv\n",
            "Rows: 2405\n",
            "Total moves (score): 91584\n",
            "\n",
            "Final winners by source tag (top):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gap</th>\n",
              "      <td>2391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>progress_ml</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "source\n",
              "gap            2391\n",
              "progress_ml      10\n",
              "baseline          4\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved: submission_final.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solution\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"R4.R7.R10.R6.R8.R6.R12.R9.R8.R4\",\n          \"R5.R4.R2.R4\",\n          \"R3.R2.R12.R5.R11.R8.R5.R9.R5.R10.R3.R7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"gap\",\n          \"baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ed5e63ac-b4e8-4664-bd8f-36031d5cc36c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>solution</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>R4.R2</td>\n",
              "      <td>baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>R5.R4.R2.R4</td>\n",
              "      <td>gap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>R4.R2.R3.R2</td>\n",
              "      <td>baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>R2.R3</td>\n",
              "      <td>baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>R3.R5.R3.R4</td>\n",
              "      <td>baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>R3.R2.R12.R5.R11.R8.R5.R9.R5.R10.R3.R7</td>\n",
              "      <td>gap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>R10.R11.R4.R7.R6.R8.R10.R3.R12.R8</td>\n",
              "      <td>gap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>R11.R6.R12.R4.R5.R3.R10.R3.R11.R5.R8</td>\n",
              "      <td>gap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>R4.R7.R10.R6.R8.R6.R12.R9.R8.R4</td>\n",
              "      <td>gap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>R10.R3.R6.R9.R8.R11.R4.R12.R7.R2.R5</td>\n",
              "      <td>gap</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed5e63ac-b4e8-4664-bd8f-36031d5cc36c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed5e63ac-b4e8-4664-bd8f-36031d5cc36c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed5e63ac-b4e8-4664-bd8f-36031d5cc36c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   id                                solution    source\n",
              "0   0                                   R4.R2  baseline\n",
              "1   1                             R5.R4.R2.R4       gap\n",
              "2   2                             R4.R2.R3.R2  baseline\n",
              "3   3                                   R2.R3  baseline\n",
              "4   4                             R3.R5.R3.R4  baseline\n",
              "5   5  R3.R2.R12.R5.R11.R8.R5.R9.R5.R10.R3.R7       gap\n",
              "6   6       R10.R11.R4.R7.R6.R8.R10.R3.R12.R8       gap\n",
              "7   7    R11.R6.R12.R4.R5.R3.R10.R3.R11.R5.R8       gap\n",
              "8   8         R4.R7.R10.R6.R8.R6.R12.R9.R8.R4       gap\n",
              "9   9     R10.R3.R6.R9.R8.R11.R4.R12.R7.R2.R5       gap"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "BASE_PATHS = [\n",
        "    \"/content/drive/MyDrive/pancake_runs/submission_baseline.csv\"\n",
        "]\n",
        "\n",
        "PARTIAL_PATHS = [\n",
        "    \"/content/drive/MyDrive/pancake_runs/submission_gap.csv\",\n",
        "    \"/content/drive/MyDrive/pancake_runs/submission_progress_ml.csv\",\n",
        "]\n",
        "\n",
        "merged_df = merge_submissions_with_partials(\n",
        "    base_paths=BASE_PATHS,\n",
        "    partial_paths=PARTIAL_PATHS,\n",
        "    out_path=\"submission_final.csv\",\n",
        "    save_source_column=True,\n",
        "    tie_break=\"keep_base\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxzmMVOFXSBt"
      },
      "source": [
        "Подавляющее большинство финальных решений (2391 из 2405) пришло из beam search с gap-эвристикой. Это подтверждает, что для основного диапазона задач именно gap-эвристика даёт наиболее стабильные и воспроизводимые улучшения.\n",
        "\n",
        "Фактически, именно она формирует \"скелет\" итогового сабмита.\n",
        "\n",
        "Хотя вклад ML-эвристики количественно небольшой (10 кейсов), он ненулевой: все замены - строгие улучшения, ML действительно находит решения, которые gap-эвристика пропускает.\n",
        "\n",
        "Финальный сабмит получен путём безопасного объединения baseline-решений с результатами двух улучшенных методов: beam search с gap-эвристикой и beam search с ML-эвристикой. Замены выполнялись только при строгом улучшении, что полностью исключает деградации.\n",
        "\n",
        "Наилучший результат достигается гибридной стратегией:\n",
        "beam search с ручной gap-эвристикой как основным методом и ML-эвристикой как дополнительным источником точечных улучшений.\n",
        "\n",
        "\n",
        "Итоговый score: **91584**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JK_sq7LYFGn"
      },
      "source": [
        "# Про ML-модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYIIRUd_TZfV"
      },
      "source": [
        "Во всех экспериментах модели класса EmbMLP значительно опережают one-hot MLP (MLPRes1) по суммарному выигрышу в длине решения. Даже при увеличении глубины и сложности one-hot архитектуры остаются заметно слабее embedding-подхода. Это указывает на то, что явное представление элементов перестановки в виде эмбеддингов является более подходящим способом кодирования состояний pancake-графа.\n",
        "\n",
        "Число residual-блоков (nrd) оказывает наибольшее влияние на итоговый результат. Модели с nrd=6 стабильно демонстрируют наилучшие показатели суммарного выигрыша, тогда как уменьшение глубины приводит к заметной деградации качества. Это говорит о том, что для построения эффективной эвристики требуется достаточно выразительная нелинейная модель, способная захватывать сложные зависимости между элементами перестановки.\n",
        "\n",
        "Внезапно, модели с размерностью эмбеддинга 32 в среднем превосходят модели с emb_dim=64. Более компактное представление элементов перестановки оказывается менее склонным к переобучению на данных случайных обходов и лучше переносится на задачу эвристического поиска. Этот результат подчёркивает, что увеличение выразительности модели не всегда приводит к улучшению её практической эффективности.\n",
        "\n",
        "Использование positional embedding даёт лишь незначительный эффект и не является критичным для достижения высоких результатов. В некоторых режимах (средние значения n) оно может слегка улучшать качество, однако в среднем влияние позиционных эмбеддингов оказывается слабым по сравнению с вкладом глубины модели и способа кодирования состояний.\n",
        "\n",
        "Хотя высокая корреляция предсказаний модели с BFS-дистанциями необходима для успешной эвристики, она не гарантирует максимального выигрыша в beam search. Некоторые модели с более высокой sanity_corr показывают меньший суммарный выигрыш, чем более «простые» архитектуры. Это подтверждает важность оценки моделей по конечному эффекту в поиске, а не только по регрессионным метрикам."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 13789744,
          "sourceId": 115576,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
